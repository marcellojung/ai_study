{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfKRCW_IWPrf"
      },
      "source": [
        "https://pkgpl.org/2023/09/12/openai-api-function_call-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl1hDBbnYjJ1"
      },
      "source": [
        "# OpenAI 어시스턴트 API 개요\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBmuxex5S8xL"
      },
      "source": [
        "Assistants API는 AI 어시스턴트를 쉽게 구축하고 통합할 수 있게 해주는 도구입니다. 이 API는 OpenAI의 모델을 활용하여 다양한 작업을 수행하며, 코드 해석, 파일 검색, 사용자 정의 기능 호출 등의 툴을 병렬로 사용할 수 있습니다. 지속적인 대화 스레드를 통해 대화 기록을 관리하고, 파일을 생성하거나 참조할 수 있어 유연한 AI 애플리케이션 개발이 가능합니다. 현재 베타 버전으로, 지속적인 기능 추가가 이루어지고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ndvAsGTAtf"
      },
      "source": [
        "사용자는 어시스턴트를 생성한 후, 대화 스레드(Thread)를 통해 특정 질문이나 요청을 보낼 수 있으며, 어시스턴트는 이에 대한 답변을 생성합니다. '런(Run)'은 어시스턴트가 스레드에서 실제로 작업을 수행하는 과정으로, 이 과정을 통해 답변이 생성되고, 최종적으로 사용자는 그 결과를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CIQs4r5RCb6"
      },
      "source": [
        ":https://platform.openai.com/playground/assistants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_W1YWOHmUTl",
        "outputId": "7a69d126-8169-446c-ee35-a85e178240a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.1\n",
            "    Uninstalling openai-1.78.1:\n",
            "      Successfully uninstalled openai-1.78.1\n",
            "Successfully installed openai-1.79.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNbd02h0_fqr"
      },
      "source": [
        "# code_interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAfiDH5TMDq_"
      },
      "source": [
        "# 🤖 GPT 어시스턴트를 활용한 수학 문제 해결 자동화: 큰 그림부터 이해하기\n",
        "\n",
        "이 코드는 **OpenAI의 GPT-4o 모델**을 사용해 **수학 문제를 자동으로 해결해주는 어시스턴트(AI 선생님)**를 만드는 전체 과정을 담고 있습니다.  \n",
        "처음 접하는 분들도 쉽게 이해할 수 있도록, **전체 흐름을 7단계로** 나눠 차근차근 설명드리겠습니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 전체 흐름 요약: 단계별 핵심 개념\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 1. 환경 준비\n",
        "- OpenAI 라이브러리를 설치하고, API 키를 설정합니다.\n",
        "- 이 API 키는 GPT와 대화를 시작하기 위한 **인증 키**입니다.\n",
        "\n",
        "📦 비유:  \n",
        "> \"AI와 연결하는 전화선을 설치하고, 통화할 수 있도록 비밀번호를 입력하는 단계입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 2. 어시스턴트 만들기\n",
        "- GPT에게 **\"넌 수학 문제를 푸는 선생님이야\"** 라는 역할을 부여합니다.\n",
        "- 파이썬 코드를 실제로 실행할 수 있는 **계산 도구(code interpreter)**를 함께 줍니다.\n",
        "\n",
        "🎓 비유:  \n",
        "> \"수학 선생님을 고용하고, 계산기와 노트북을 손에 쥐어주는 것과 같습니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 3. 대화 스레드 만들기\n",
        "- 사용자가 AI에게 질문을 던질 **대화 공간(스레드)**을 만듭니다.\n",
        "\n",
        "💬 비유:  \n",
        "> \"질문을 종이에 적어서 선생님 책상 위에 올려놓는 과정입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 4. 어시스턴트 실행 (Run 생성)\n",
        "- 만들어진 질문(스레드)을 GPT에게 **진짜로 풀어보라고 실행시키는** 단계입니다.\n",
        "\n",
        "🚀 비유:  \n",
        "> \"선생님에게 문제지를 건네고 풀기 시작하라고 지시하는 단계입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 5. 실행 상태 확인\n",
        "- AI가 문제를 **아직 푸는 중인지, 다 풀었는지, 실패했는지** 확인합니다.\n",
        "\n",
        "🔍 비유:  \n",
        "> \"선생님이 아직 문제 푸는 중인지, 다 풀었는지를 확인하는 과정입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 6. 어시스턴트의 답변 확인\n",
        "- AI가 문제를 풀고 나서 **어떤 답을 냈는지, 어떻게 설명했는지**를 확인합니다.\n",
        "\n",
        "📄 비유:  \n",
        "> \"책상 위에 놓인 선생님의 풀이 종이를 읽어보는 단계입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 단계 7. 풀이 과정 분석\n",
        "- AI가 **어떤 단계와 도구(code)**를 사용해서 문제를 풀었는지 추적합니다.\n",
        "\n",
        "🔬 비유:  \n",
        "> \"선생님이 문제를 풀면서 어떤 공식이나 도구를 썼는지 복기하는 과정입니다.\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 🔁 비유 정리표 (한눈에 보기)\n",
        "\n",
        "| 단계 | 의미 | 직관적 비유 |\n",
        "|------|------|--------------|\n",
        "| 1 | GPT 연결 | 전화선 연결 & 비밀번호 입력 |\n",
        "| 2 | 어시스턴트 생성 | 수학 선생님 고용 |\n",
        "| 3 | 질문 제출 | 질문지를 책상에 올리기 |\n",
        "| 4 | AI 실행 | 선생님에게 문제 넘기기 |\n",
        "| 5 | 상태 확인 | 문제 푸는 중인지 보기 |\n",
        "| 6 | 답변 확인 | 종이에 적힌 답 보기 |\n",
        "| 7 | 풀이 분석 | 어떤 도구 썼는지 확인 |\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 마무리 요약\n",
        "\n",
        "이 코드는 단순히 질문을 GPT에게 던지는 것이 아닙니다.  \n",
        "마치 실제 수학 선생님을 고용해서, 문제를 풀게 만들고, 그 과정을 추적하고 결과를 확인하는 전체 과정을 자동화한 것입니다.  \n",
        "GPT-4o는 파이썬 코드까지 실행하며 똑똑하게 문제를 풀 수 있기 때문에, 매우 강력한 도구입니다.\n",
        "\n",
        "이제 각 단계별로 코드를 들여다보면, 전체 구조가 명확하게 이해될 것입니다! 😊\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO8569z8UdOW"
      },
      "outputs": [],
      "source": [
        "# 1. 필수 라이브러리 설치 및 API 키 설정\n",
        "# os 환경 변수에 OpenAI API 키를 저장합니다.\n",
        "import openai\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up8cygA7YSgQ"
      },
      "outputs": [],
      "source": [
        "# 2. 어시스턴트 설정\n",
        "# 🔸포인트: openai.beta.assistants.create 함수는 '나만의 AI 어시스턴트'를 만드는 함수입니다.\n",
        "# 쉽게 말해, \"이 어시스턴트는 어떤 일을 할 거야\"라고 역할과 능력을 설정하는 단계입니다.\n",
        "# 예: 우리가 '수학 문제를 풀어주는 AI 선생님'을 만들고자 할 때, 그 역할을 구체적으로 지정합니다.\n",
        "math_assistant = openai.beta.assistants.create(\n",
        "    name=\"MathHelper\",\n",
        "    # 🔸포인트: 어시스턴트의 이름입니다.\n",
        "    # 예: 'MathHelper'는 수학 도우미라는 뜻으로, 이름만 봐도 무슨 일을 하는지 짐작할 수 있도록 설정합니다.\n",
        "    instructions=\"산수 문제를 해결하는 강사입니다. 파이썬 코드를 작성하고 실행하여 답을 찾습니다.\",\n",
        "    # 🔸포인트: 어시스턴트의 역할과 행동 방식을 명확히 알려주는 설명입니다.\n",
        "    # '산수 문제'라는 구체적인 범위와 '파이썬 코드로 답을 구한다'는 방법이 함께 정의되어 있어요.\n",
        "    # 예: \"나는 산수 선생님이고, 계산은 직접 파이썬으로 할 거야!\"라는 식의 선언이라고 보면 됩니다.\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        "    # 🔸포인트: 이 어시스턴트가 사용할 수 있는 도구(tool)를 지정합니다.\n",
        "    # 여기서 'code_interpreter'는 파이썬 코드 실행기, 즉 코드로 직접 계산하거나 결과를 낼 수 있는 능력을 줍니다.\n",
        "    # 예: 어시스턴트가 손으로 푸는 게 아니라, 컴퓨터 계산기로 문제를 푼다고 보면 됩니다.\n",
        "    model=\"gpt-4o\",\n",
        "    # 🔸포인트: 어시스턴트가 기반으로 삼을 인공지능 모델입니다.\n",
        "    temperature=0.2\n",
        "    # 🔸포인트: 생성되는 텍스트의 \"창의성\" 또는 \"무작위성\"을 조절하는 값입니다.\n",
        "    # 값이 낮을수록 더 예측 가능하고 정답에 가까운 결과를 냅니다.\n",
        "    # 수학처럼 정확성이 중요한 작업에는 낮은 값을 설정하는 게 일반적입니다.\n",
        "    # 예: 0.2는 거의 '정해진 방식으로 차분하게 대답하라'는 의미예요.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xqjeJNva9AnL",
        "outputId": "52c5b5b5-b581-40f3-8731-b693fe15fcb1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'asst_YeboaLauJ9MX0YhGep1FIZcT'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math_assistant.id  # 어시스턴트의 ID 확인용 (나중에 실행에 연결할 때 사용됨)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCQ_JOdmYVfB"
      },
      "outputs": [],
      "source": [
        "# 3. 대화 스레드 생성\n",
        "# 🔸포인트: 사용자의 질문을 담은 \"대화방(스레드)\"을 만드는 단계입니다.\n",
        "# 이 스레드를 통해 사용자와 어시스턴트가 계속 대화하게 됩니다.\n",
        "def create_thread(message):\n",
        "    thread = openai.beta.threads.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": message}]  # 🔸 사용자 메시지를 포함해서 스레드 생성\n",
        "    )\n",
        "    return thread  # 생성된 스레드를 반환 (이후 단계에서 사용)\n",
        "\n",
        "# 예시: 사용자의 질문으로 스레드 생성\n",
        "math_thread = create_thread('100보다 큰 첫 번째 소수의 제곱은 무엇인가요?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LnV4w0Sv9GX2",
        "outputId": "80dc7646-0f20-409e-bb52-5c95ebb6bf97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thread_wm6gKe3NFDQbDmGiKzoM4sgb'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math_thread.id  # 생성된 스레드의 ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQDZrps5YWys"
      },
      "outputs": [],
      "source": [
        "# 4. 실행(run) 생성\n",
        "# 🔸포인트: 어시스턴트와 스레드를 실제로 연결해서 '답변을 생성하는 실행'을 시작하는 단계입니다.\n",
        "\n",
        "def run_assistant(thread, assistant):\n",
        "    run = openai.beta.threads.runs.create(\n",
        "        thread_id=thread.id,        # 연결할 스레드 ID\n",
        "        assistant_id=assistant.id   # 연결할 어시스턴트 ID\n",
        "    )\n",
        "    return run  # 실행 객체 반환\n",
        "\n",
        "# 어시스턴트와 스레드를 연결하여 실행 생성\n",
        "math_run = run_assistant(math_thread, math_assistant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad4rINa5YYyj",
        "outputId": "603abd64-1dc5-4ce7-e8a6-3848469453ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run(id='run_FvAvcpSrGQ3sC4cEzALV14EF', assistant_id='asst_YeboaLauJ9MX0YhGep1FIZcT', cancelled_at=None, completed_at=1747815114, created_at=1747815111, expires_at=None, failed_at=None, incomplete_details=None, instructions='산수 문제를 해결하는 강사입니다. 파이썬 코드를 작성하고 실행하여 답을 찾습니다.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=1747815112, status='completed', thread_id='thread_wm6gKe3NFDQbDmGiKzoM4sgb', tool_choice='auto', tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=31, prompt_tokens=261, total_tokens=292, prompt_token_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0}), temperature=0.2, top_p=1.0, tool_resources={}, reasoning_effort=None)\n",
            "---\n",
            "completed\n"
          ]
        }
      ],
      "source": [
        "# 5. 실행 상태 확인\n",
        "# 🔸포인트: 실행 중인 run이 잘 작동하고 있는지 확인하는 함수입니다.\n",
        "# 실행의 상태 정보에는 진행 중, 완료됨, 오류 발생 등의 정보가 담깁니다.\n",
        "\n",
        "def get_run_status(thread, run):\n",
        "    run_status = openai.beta.threads.runs.retrieve(\n",
        "        thread_id=thread.id,  # 스레드 ID\n",
        "        run_id=run.id         # 실행 ID\n",
        "    )\n",
        "    return run_status  # 실행 상태 반환\n",
        "\n",
        "# 실행 상태 조회\n",
        "math_run_status = get_run_status(math_thread, math_run)\n",
        "\n",
        "# 실행 상태 출력 (전체 상태와 상태값만 따로 출력)\n",
        "print(math_run_status)          # 전체 실행 상태 출력\n",
        "print('---')                    # 구분선\n",
        "print(math_run_status.status)   # 실행 상태만 출력 (예: \"completed\", \"in_progress\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Sv9YJhYaAX",
        "outputId": "baab290a-0b4d-4022-f218-b3ca394bfcff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user\n",
            "100보다 큰 첫 번째 소수의 제곱은 무엇인가요?\n",
            "---\n",
            "assistant\n",
            "100보다 큰 첫 번째 소수는 101이며, 그 제곱은 \\(101^2 = 10201\\)입니다.\n",
            "---\n",
            "assistant\n",
            "100보다 큰 첫 번째 소수는 101이며, 그 제곱은 \\(101^2 = 10201\\)입니다.\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# 6. 스레드 메시지 확인\n",
        "# 🔸포인트: 어시스턴트가 생성한 답변 메시지를 확인하는 함수입니다.\n",
        "# 이 과정을 통해 실제로 어떤 응답이 생성되었는지 사용자 입장에서 볼 수 있습니다.\n",
        "\n",
        "def list_thread_messages(thread):\n",
        "    messages = openai.beta.threads.messages.list(\n",
        "        thread_id=thread.id  # 해당 스레드의 ID로 메시지 가져오기\n",
        "    )\n",
        "\n",
        "    # 최신 메시지부터 순서대로 출력\n",
        "    for i in range(len(messages.data), 0, -1):\n",
        "        print(messages.data[i-1].role)  # 메시지 주체 (user 또는 assistant)\n",
        "        print(messages.data[i-1].content[0].text.value)  # 메시지 내용 출력\n",
        "        print('---')  # 구분선 출력\n",
        "\n",
        "    return messages  # 전체 메시지 반환\n",
        "\n",
        "# 메시지 목록 조회 및 출력\n",
        "math_messages = list_thread_messages(math_thread)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z2RoOVDe15x",
        "outputId": "d72b7d48-c693-42b9-fb54-757716aee582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_vkd6C5WrTFW3mC7PaaiUkFCc'), type='message_creation')\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# 7. 실행 단계 확인\n",
        "# 🔸포인트: 어시스턴트가 답변을 생성하는 과정에서 어떤 단계를 거쳤는지 확인합니다.\n",
        "# 디버깅이나 동작 확인 시 매우 유용합니다. (예: 코드 실행, 텍스트 생성 등)\n",
        "\n",
        "run_steps = openai.beta.threads.runs.steps.list(\n",
        "  thread_id=math_thread.id,        # 스레드 ID\n",
        "  run_id=math_run_status.id        # 실행(run) ID\n",
        ")\n",
        "\n",
        "# 각 단계에서 어떤 작업이 수행되었는지 출력\n",
        "for i in range(len(run_steps.data), 0, -1):\n",
        "    step_detail = run_steps.data[i-1].step_details  # 단계 세부 정보 가져오기\n",
        "    print(step_detail)  # 단계 정보 출력\n",
        "    print('---')  # 구분선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jviTJ1d9Vd8Y"
      },
      "source": [
        "## OPENAI Assistant Functional Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPAWSBoVDZDo"
      },
      "source": [
        "| 포인트                  | 설명                                    |\n",
        "| -------------------- | ------------------------------------- |\n",
        "| `assistant.create()` | 챗봇의 역할과 도구를 설정하는 핵심 함수                |\n",
        "| `thread`             | 사용자와 챗봇의 대화 흐름을 담는 구조                 |\n",
        "| `function tool`      | 챗봇이 특정 작업을 외부 API로 위임하는 메커니즘          |\n",
        "| `event_handler`      | 도우미가 실행 중 함수 실행을 요청할 때 이를 감지하고 처리     |\n",
        "| `stream()`           | 실시간 응답 처리를 위한 방식 (사용자에게 자연스러운 피드백 제공) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jq5uVFJbyUA"
      },
      "outputs": [],
      "source": [
        "# 📌 필수 라이브러리 설치 및 환경 설정\n",
        "\n",
        "# OpenAI API와 통신하기 위한 핵심 라이브러리 임포트\n",
        "from openai import OpenAI  # 🔸포인트: OpenAI API 클라이언트를 사용하기 위한 클래스\n",
        "from openai import AssistantEventHandler  # 이벤트를 처리할 때 사용하는 핸들러 클래스\n",
        "from typing_extensions import override  # 🔸포인트: 부모 클래스 메서드를 덮어쓸 때 사용\n",
        "import openai  # OpenAI의 다양한 기능을 활용할 수 있는 메인 라이브러리\n",
        "import os  # OS 환경변수나 파일 경로 설정 등을 위해 사용\n",
        "\n",
        "# OpenAI 클라이언트 객체 생성\n",
        "client = openai.OpenAI()  # 이후 모든 API 호출은 이 client를 통해 이루어짐\n",
        "\n",
        "# 📌 Assistant(도우미) 정의\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
        "    # 🔸포인트: 도우미의 역할을 명시적으로 정의\n",
        "    # 🧠 \"나는 날씨를 알려주는 봇이야. 그리고 이 아래 정의된 함수들을 이용해서 대답할 거야.\"\n",
        "\n",
        "    model=\"gpt-4o\",  # 최신 GPT-4o 모델 사용\n",
        "\n",
        "    tools=[  # 도우미가 사용할 수 있는 함수(도구) 정의\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_current_temperature\",  # 온도 조회 함수\n",
        "                \"description\": \"Get the current temperature for a specific location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
        "                        },\n",
        "                        \"unit\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"Celsius\", \"Fahrenheit\"],  # 🔸섭씨 또는 화씨 중 선택\n",
        "                            \"description\": \"The temperature unit to use.\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"location\", \"unit\"],  # 필수 입력값\n",
        "                    \"additionalProperties\": False  # 그 외 속성은 허용 안 함\n",
        "                },\n",
        "                \"strict\": True\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_rain_probability\",  # 비 확률 조회 함수\n",
        "                \"description\": \"Get the probability of rain for a specific location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city and state, e.g., San Francisco, CA\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"location\"],\n",
        "                    \"additionalProperties\": False\n",
        "                },\n",
        "                \"strict\": True\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnG8bnC0fOV8"
      },
      "outputs": [],
      "source": [
        "# 📌 사용자와 대화를 위한 스레드 생성\n",
        "\n",
        "thread = client.beta.threads.create()  # 🔸포인트: 대화는 항상 스레드 안에서 이루어짐\n",
        "\n",
        "# 사용자 질문 추가\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,  # 대화 스레드 ID 지정\n",
        "    role=\"user\",  # 이 메시지가 사용자로부터 왔음을 명시\n",
        "    content=\"What's the weather in San Francisco today and the likelihood it'll rain?\"\n",
        "    # 💡예시: 오늘 샌프란시스코 날씨와 비 올 확률을 물어봄\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgfXtZqyhL6J"
      },
      "source": [
        "(참고) 사용자가 특정 질문을 입력하고, 이 질문에 대한 처리가 필요한 경우, 시스템은 \"어떤 작업이 필요하다\"는 이벤트를 발생시킵니다.\n",
        "이때 이벤트 시스템은 'thread.run.requires_action' 이벤트를 발생시킬 수 있으며, 이 이벤트가 발생하면 시스템은 EventHandler 클래스의 on_event 메서드를 호"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzN4-zTkfP3M"
      },
      "outputs": [],
      "source": [
        "# 📌 이벤트 핸들러 정의: 도우미가 기능 실행 요청할 때 처리해주는 클래스\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "    # 🔸포인트: AssistantEventHandler는 OpenAI 도우미와 상호작용할 때 발생하는 이벤트를 감지하고 처리하는 '이벤트 리스너'입니다.\n",
        "    # 이 클래스를 상속받아 우리가 원하는 방식으로 이벤트를 처리할 수 있게 됩니다.\n",
        "\n",
        "    @override\n",
        "    def on_event(self, event):\n",
        "        # 🔸포인트: 이벤트 발생 시 자동으로 호출되는 메서드입니다.\n",
        "        # 도우미가 \"나 함수 좀 실행해야 해!\"라고 요청하는 상황을 감지합니다.\n",
        "        # 예: 사용자가 날씨 질문 → 도우미가 함수 호출이 필요하다고 판단 → 이 메서드가 실행됨\n",
        "\n",
        "        if event.event == 'thread.run.requires_action':\n",
        "            # 💡특정 이벤트 타입: '추가 작업 필요' (즉, 함수 실행 요청)\n",
        "            run_id = event.data.id  # 현재 실행(run)의 ID를 가져옴\n",
        "            self.handle_requires_action(event.data, run_id)  # 작업 처리 메서드 호출\n",
        "\n",
        "    def handle_requires_action(self, data, run_id):\n",
        "        # 🔸포인트: 도우미가 요청한 실제 함수 실행을 담당하는 메서드\n",
        "        # 이 안에서 도우미가 호출한 함수 이름에 따라 우리가 직접 결과를 만들어 넘깁니다.\n",
        "\n",
        "        tool_outputs = []  # 도구의 출력값(함수 결과들)을 담을 리스트\n",
        "\n",
        "        # 요청된 함수(도구)들을 하나씩 순회하며 확인\n",
        "        for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
        "\n",
        "            if tool.function.name == \"get_current_temperature\":\n",
        "                # 💡도우미가 \"현재 온도를 알려줘!\"라고 요청한 경우\n",
        "                tool_outputs.append({\n",
        "                    \"tool_call_id\": tool.id,  # 요청된 함수 고유 ID\n",
        "                    \"output\": \"57\"  # 예시로 57도라는 결과를 직접 지정\n",
        "                    # 실제로는 날씨 API를 호출하여 받아온 값을 넣을 수 있음\n",
        "                })\n",
        "\n",
        "            elif tool.function.name == \"get_rain_probability\":\n",
        "                # 💡도우미가 \"비 올 확률이 얼마나 돼?\"라고 요청한 경우\n",
        "                tool_outputs.append({\n",
        "                    \"tool_call_id\": tool.id,\n",
        "                    \"output\": \"0.06\"  # 예시로 6%라는 확률을 리턴\n",
        "                })\n",
        "\n",
        "        # 🔸포인트: 도우미가 요청한 함수들에 대한 결과들을 정리한 뒤, 아래 메서드를 통해 서버에 제출\n",
        "        self.submit_tool_outputs(tool_outputs, run_id)\n",
        "\n",
        "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
        "        # 🔸포인트: 앞서 만든 함수 결과들을 도우미에게 제출하는 단계입니다.\n",
        "        # 제출 방식은 스트리밍을 사용하여 결과를 실시간으로 보여줄 수 있게 처리합니다.\n",
        "\n",
        "        with client.beta.threads.runs.submit_tool_outputs_stream(\n",
        "            thread_id=thread.id,      # 현재 대화의 스레드 ID\n",
        "            run_id=run_id,            # 현재 실행의 ID\n",
        "            tool_outputs=tool_outputs,  # 도구 출력값 리스트\n",
        "            event_handler=EventHandler(),  # 이 핸들러를 다시 지정해줌 (다음 이벤트도 처리 가능)\n",
        "        ) as stream:\n",
        "            # 도우미가 결과를 사용자에게 전달할 때, 그 내용을 실시간으로 받아 출력\n",
        "            for text in stream.text_deltas:\n",
        "                print(text, end=\"\", flush=True)  # 실시간 출력\n",
        "            print()  # 보기 좋게 줄바꿈\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRmy_yl_fQvN",
        "outputId": "eb8af95a-3ff0-4bfb-ae6c-44f83118bb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current temperature in San Francisco is 57°F, and there's a 6% chance of rain today.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 📌 Run 실행 및 결과 스트리밍\n",
        "\n",
        "with client.beta.threads.runs.stream(\n",
        "    thread_id=thread.id,  # 실행할 스레드 지정\n",
        "    assistant_id=assistant.id,  # 사용할 도우미 ID 지정\n",
        "    event_handler=EventHandler()  # 핸들러 지정\n",
        ") as stream:\n",
        "    stream.until_done()  # 모든 응답이 도착할 때까지 대기"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
