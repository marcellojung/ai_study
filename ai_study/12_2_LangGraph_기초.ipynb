{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dNVSrWPrDMe",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# [실습] LangGraph 기초\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UabesZokMuZ-"
      },
      "source": [
        "# 🧠 LangGraph 실습 전체 구조, 쉽게 이해하기\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 먼저, 이 실습은 무엇을 하려는 걸까요?\n",
        "\n",
        "우리는 지금 \"AI가 어떤 일을 대신 처리하도록 시키는 과정\"을 배우고 있습니다.  \n",
        "그런데 이 과정을 **일직선 코드가 아닌 ‘그래프’라는 흐름도 형식**으로 표현하고 실행하는 것이 핵심입니다.\n",
        "\n",
        "즉, **AI가 차례차례 일을 하도록 ‘점과 선’으로 된 설계도**를 만든다고 이해하면 됩니다.  \n",
        "이때 사용되는 도구가 바로 👉 **LangGraph**입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 LangGraph란 무엇인가요?\n",
        "\n",
        "LangGraph는 마치 \"AI 비서를 위한 업무 플로우 차트\"입니다.\n",
        "\n",
        "- **점(Node)**: 각각의 일처리를 담당하는 작은 AI 기능입니다. (예: 계산, 농담 생성, 검색 등)\n",
        "- **선(Edge)**: 한 단계에서 다음 단계로 연결되는 경로입니다.\n",
        "- **가방(State)**: 데이터가 들어 있는 상태 상자입니다. AI가 일할 때 주고받는 자료가 여기 담깁니다.\n",
        "\n",
        "→ 이 세 가지 요소로 **AI 작업 흐름 전체를 설계**합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## ✈️ 예를 들어, 이런 흐름이 있다고 상상해 보세요\n",
        "\n",
        "1. AI는 \"출발점(START)\"에서 시작합니다.\n",
        "2. 어떤 숫자가 들어오면 **제곱근을 계산**합니다.\n",
        "3. 그 숫자에 맞게 **짧은 농담을 생성**합니다.\n",
        "4. 어떤 질문이 주어지면 적절한 **검색어를 만들고**, 웹에서 **자료를 검색하고**, **답을 작성**합니다.\n",
        "5. 마지막으로 \"도착점(END)\"에 도달합니다.\n",
        "\n",
        "이 흐름이 모두 LangGraph로 구성됩니다!\n",
        "\n",
        "---\n",
        "\n",
        "## 🧰 이 시스템을 만들기 위한 3가지 구성요소\n",
        "\n",
        "| 구성 요소 | 역할 | 쉬운 비유 |\n",
        "|-----------|-------|-----------|\n",
        "| **State** | 지금까지의 데이터 상태 | 여행가방, 서류 가방 |\n",
        "| **Node**  | 한 가지 기능을 수행하는 단계 | 정류장, 일처리 AI |\n",
        "| **Edge**  | 다음 단계로 이어지는 경로 | 버스 노선, 연결선 |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 우리가 지금 실습에서 하는 일 요약\n",
        "\n",
        "1. **State 정의**: 어떤 정보(데이터)를 주고받을 것인지 명시합니다. 예: 숫자, 결과, 비밀 등\n",
        "2. **Node 만들기**: 각 단계에서 어떤 처리를 할지를 함수로 정의합니다.\n",
        "3. **Edge 구성**: 각 노드들이 어떤 순서로 연결될지 선을 그립니다.\n",
        "4. **Graph 실행**: 이 흐름도를 바탕으로 AI가 실제로 작동하게 만듭니다.\n",
        "5. **LLM 활용 추가**: 노드 안에서 LLM(Gemini 등)을 불러서 농담 생성, 검색 등 복잡한 작업도 가능하게 합니다.\n",
        "6. **웹 검색 추가**: 질문을 주면 검색어를 만들고, 검색 결과를 가져와 AI가 답을 씁니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 핵심 요약\n",
        "\n",
        "> LangGraph는 **AI가 일하는 과정을 그래프(흐름도)**로 설계해서 실행하는 도구입니다.  \n",
        "> 이 안에는 상태(State), 단계(Node), 연결선(Edge)이 명확히 구성되어 있으며,  \n",
        "> 각 단계를 함수로 만들어 놓고, 순서를 따라 AI가 일을 진행하게 합니다.\n",
        "\n",
        "이 개념을 이해하고 나면, 복잡한 AI 자동화도 **한눈에 파악 가능한 형태**로 만들 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0BW7qQvrDMe"
      },
      "source": [
        "기본 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQPyAAOdrDMf",
        "outputId": "3b56866a-0474-423b-c8e9-041543982719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.59)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.69)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.6.18)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.9.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langgraph langchain langchain_google_genai langchain_community\n",
        "# ✅ 필요한 라이브러리 설치\n",
        "# LangGraph, LangChain 및 관련 Google Gemini API, Community 기능을 사용하기 위해 최신 버전으로 업그레이드합니다.\n",
        "# 강의 시 포인트: LangGraph는 'AI 자동화 플로우'를 그래프 형태로 구성할 수 있는 매우 유용한 도구입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKKCoKmVrDMf"
      },
      "source": [
        "# Graph의 구성 요소: State, Node, Edge, Graph\n",
        "\n",
        "\n",
        "시작 지점과 끝 지점을 표시한 그래프를 구성하고, 전체 그래프를 `invoke()`를 통해 실행합니다.\n",
        "\n",
        "그래프는 점과 선으로 구성되는데요.  \n",
        "\n",
        "\n",
        "\n",
        "이를 노드(Node, 정점), 엣지(Edge, 간선)라고 부릅니다.    \n",
        "\n",
        "각각의 노드는 LLM 호출을 비롯한 하나의 기능을 수행하게 되며, 기능과 기능 사이의 연결을 엣지로 구성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0MQDjCOrDMf"
      },
      "source": [
        "### State\n",
        "\n",
        "LangGraph의 Workflow는 State Diagram으로 볼 수 있습니다.   \n",
        "\n",
        "전체 Workflow에서, State는 초기 State에서 시작해    \n",
        "Node와 Edge를 통과하며 그 값이 수정되거나 추가되는 과정을 거치게 됩니다.   \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYFYHW6xrDMf"
      },
      "source": [
        "State의 구조는 보통 가시성을 위해 타입 표시를 병행합니다.   \n",
        "`TypedDict`나 `Pydantic`중 편한 것을 사용하면 되는데요.   \n",
        "이번 교재에서는 공식 문서와 동일한 `TypedDict`를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaBQ0lFhrDMf"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "# ✅ TypedDict는 딕셔너리의 구조(키와 값의 타입)를 명확하게 정의할 수 있게 도와줍니다.\n",
        "# 큰 프로젝트에서 안정적인 코드 작성을 위해 유용해요.\n",
        "\n",
        "# 📌 State는 그래프에서 데이터를 전달하고 저장하는 \"중간 저장소\" 역할을 합니다.\n",
        "# 쉽게 말해 여러 노드를 거치며 정보를 담아가는 \"여행 가방\"입니다.\n",
        "class State(TypedDict):\n",
        "    result: str  # 지금까지 처리된 결과를 저장 (예: \"1번 노드를 통과했습니다\\n\")\n",
        "    secret: str  # 시스템에서만 사용하는 비밀 정보 (예: 비밀 키, 인증 코드 등)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy0OiRSOrDMg"
      },
      "source": [
        "### Node\n",
        "\n",
        "노드는 함수로 정의되는데, 주로 하나의 모듈을 하나의 노드로 구성합니다.   \n",
        "State는 노드를 지나며 새로운 정보를 추가하거나, 값을 수정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLxb0OgPrDMg"
      },
      "outputs": [],
      "source": [
        "# ✅ 첫 번째 노드 함수 정의\n",
        "# 이 노드는 상태(state) 안의 'result'에 문자열을 추가하여 반환합니다.\n",
        "\n",
        "def first(state):\n",
        "    print(\"---Node 1---\")  # 실행 시, 어떤 노드가 실행 중인지 로그로 표시됩니다.\n",
        "    return {\"result\": state['result'] +\"랭그래프 1번 노드 통과\\n\"}\n",
        "    # 기존 'result' 문자열에 1번 노드를 통과했다는 문장을 덧붙입니다.\n",
        "\n",
        "\n",
        "# ✅ 두 번째 노드 함수 정의\n",
        "# 1번 노드와 동일한 방식으로 작동하며, 2번 노드를 통과했다는 메시지를 추가합니다.\n",
        "def second(state):\n",
        "    print(\"---Node 2---\")\n",
        "    return {\"result\": state['result'] +\"랭그래프 2번 노드 통과\\n\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq9xwXDArDMg"
      },
      "source": [
        "### Edge와 Graph   \n",
        "\n",
        "위에서 설정한 State를 이용하여 Graph를 정의합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRTveKMvrDMg"
      },
      "source": [
        "그래프에 노드와 엣지를 추가합니다.    \n",
        "START와 END를 import하고, 시작점과 끝점을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmgnv9JirDMg",
        "outputId": "3b9d7610-bce5-4141-ee0d-b19e44484394"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79a928bbef10>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# ✅ LangGraph의 핵심: 그래프 객체를 만들고 흐름을 설계하는 부분입니다.\n",
        "# builder = 그래프를 구성하는 설계자 역할입니다.\n",
        "\n",
        "builder = StateGraph(State)  # 아까 만든 State 구조를 기반으로 그래프를 만듭니다.\n",
        "\n",
        "\n",
        "# ✅ 노드를 그래프에 추가\n",
        "# 'first'라는 이름의 노드를 first() 함수와 연결합니다.\n",
        "# 'second'도 마찬가지입니다.\n",
        "\n",
        "builder.add_node(\"first\", first)\n",
        "builder.add_node(\"second\", second)\n",
        "\n",
        "\n",
        " # ✅ 각 노드들을 연결하는 엣지(Edge)를 추가합니다.\n",
        "# 포인트! 각 노드가 어떤 순서로 실행될지를 설정하는 \"길\"을 만들어주는 단계입니다.\n",
        "\n",
        "builder.add_edge(START, \"first\")     # 시작 지점에서 first 노드로 이동\n",
        "builder.add_edge(\"first\", \"second\")  # first → second로 연결\n",
        "builder.add_edge(\"second\", END)      # second → 끝 지점(END)으로 이동\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNPXjlONrDMg"
      },
      "source": [
        "만든 그래프는 `compile()`을 통해 실행 가능한 Runnable 구조로 만들어집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "HM2Mh4AurDMg",
        "outputId": "513837b5-8fec-4141-b9a1-f35d8d01314f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x79a928b7e350>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "# ✅ 그래프 컴파일: 설계한 노드와 경로를 실제 실행 가능한 형태로 만듭니다.\n",
        "# 마치 레고 조각을 조립한 후, 완성품을 작동시키는 단계라고 생각하시면 됩니다.\n",
        "\n",
        "graph\n",
        "# ✅ Colab에서는 이 객체를 출력하면 Mermaid 형식의 간단한 그래프 시각화도 지원합니다.\n",
        "# (Colab 환경에서만 가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ixQ8I6rDMg"
      },
      "source": [
        "구성된 graph를 실행해 보겠습니다!   \n",
        "state의 초기 상태를 Dictionary 형태로 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuREzEh_rDMg",
        "outputId": "05201ed7-6c97-49bf-9990-81ce830e5d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Node 1---\n",
            "---Node 2---\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'result': '시작!\\n랭그래프 1번 노드 통과\\n랭그래프 2번 노드 통과\\n', 'secret': '비밀'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅ 실제로 그래프를 실행해봅니다.\n",
        "# 초기 상태(State)는 딕셔너리 형태로 제공해야 하며,\n",
        "# 여기서 'result'는 시작 메시지, 'secret'은 테스트용 비밀 값을 넣습니다.\n",
        "\n",
        "response = graph.invoke({'result':'시작!\\n', 'secret':'비밀'})\n",
        "response\n",
        "# ✅ 결과: 두 개의 노드를 차례대로 거치며, 'result'에 메시지가 순서대로 추가됩니다.\n",
        "# 출력 예시:\n",
        "# {\n",
        "#   'result': '시작!\\n랭그래프 1번 노드 통과\\n랭그래프 2번 노드 통과\\n',\n",
        "#   'secret': '비밀'\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2dxUlJprDMg"
      },
      "source": [
        "## 그래프에 LLM 포함시키기\n",
        "이번에는 값이 여러 개인 State를 구성하고, 그래프로 만들어 보겠습니다.   \n",
        "llm도 활용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGoAhLcArDMg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.environ['GOOGLE_API_KEY'] = \n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# ✅ Gemini API는 분당 10개 요청 제한이 있기 때문에, 속도 제한을 걸어야 합니다.\n",
        "\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # 초당 약 0.167회 → 분당 10회 (10/60)\n",
        "    check_every_n_seconds=0.1,  # 0.1초마다 체크\n",
        "    max_bucket_size=10,         # 짧은 시간에 몰아 보낼 수 있는 최대 개수\n",
        ")\n",
        "# ✅ 이제 제한을 건 상태로 Gemini 모델을 초기화합니다.\n",
        "# 📌 포인트! 'gemini-2.0-flash-exp' 모델은 빠르고 저렴한 응답용 모델입니다.\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",  # 사용할 Gemini 모델 이름\n",
        "    rate_limiter=rate_limiter     # 위에서 만든 요청 제한 장치 적용\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVNjKtUrDMg"
      },
      "source": [
        "3개의 요소가 포함된 State를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NexQyV2prDMh"
      },
      "outputs": [],
      "source": [
        "# ✅ 이번 예제의 State 정의\n",
        "# 📌 포인트! LangGraph는 State 안에 어떤 데이터가 들어오고 나가는지를 정확히 정의해야 합니다.\n",
        "\n",
        "class State(TypedDict):\n",
        "    integer: int  # 사용자로부터 입력받은 정수값 (예: 16)\n",
        "    root: int     # 위 정수의 제곱근 결과\n",
        "    joke: str     # 제곱근 숫자에 기반해 생성된 짧은 농담\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGJfcojyrDMh"
      },
      "source": [
        "2개의 노드를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLK5UYLlrDMh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ✅ 첫 번째 노드 함수: 정수의 제곱근을 계산\n",
        "def get_root(state):\n",
        "    return {\"root\": int(state[\"integer\"] ** 0.5)}\n",
        "    # 📌 예시: 16이 들어오면 → 4로 변환되어 'root'에 저장\n",
        "    # int()로 소수점 없이 정수만 저장합니다.\n",
        "\n",
        "# ✅ 두 번째 노드 함수: 제곱근 길이에 맞는 영어 농담 생성\n",
        "def get_joke(state):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '당신은 언어 유희의 달인입니다.'),  # AI에게 역할을 부여하는 시스템 메시지\n",
        "        ('user','{length} 문장 길이의 짧은 영어 유머를 만들어주세요. 각 문장마다 숫자를 붙이세요.')  # 실제 사용자 요청\n",
        "    ])\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"joke\": chain.invoke({'length': state['root']})}\n",
        "    # 📌 포인트!\n",
        "    # 예: root가 4면, \"4문장으로 된 영어 유머\"를 생성하게 됩니다.\n",
        "    # '|' 연산자는 LangChain에서 프롬프트 → LLM → 출력 파서를 연결하는 파이프라인 역할을 합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzvSGtVkrDMh"
      },
      "source": [
        "그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jSfnN95rDMh",
        "outputId": "a22e2002-0e7b-4036-a9d3-aae942b27a38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79a928be4690>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅ 그래프 구성 시작\n",
        "# 📌 LangGraph에서는 builder라는 설계자를 만들어 그래프 흐름을 그립니다.\n",
        "# 주의! 이미 만들어진 그래프에 노드를 다시 추가하면 에러가 날 수 있으니, builder는 새로 시작해야 합니다.\n",
        "\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# ✅ 각 노드를 그래프에 등록합니다.\n",
        "builder.add_node(\"get_root\", get_root)   # 입력된 숫자 → 제곱근 계산 노드\n",
        "builder.add_node(\"get_joke\", get_joke)   # 제곱근 → 영어 농담 생성 노드\n",
        "\n",
        "# ✅ 노드 간의 연결 경로 정의 (엣지 설정)\n",
        "builder.add_edge(START, \"get_root\")      # 시작점 → 제곱근 계산 노드\n",
        "builder.add_edge(\"get_root\", \"get_joke\") # 제곱근 → 농담 생성\n",
        "builder.add_edge(\"get_joke\", END)        # 농담 생성 후 → 끝\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xANgxFgVrDMh"
      },
      "source": [
        "그래프를 컴파일하고 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "y--knEeLrDMh",
        "outputId": "eb3018c7-c0dd-45c6-94f1-faba398f35c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x79a928be4c90>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "# ✅ 모든 구성 완료 후, 그래프를 실행 가능한 상태로 컴파일\n",
        "# 📌 컴파일은 '설계한 그래프를 실제로 작동하게 만드는 단계'입니다.\n",
        "graph\n",
        "# ✅ Colab에서는 이 graph 객체를 출력하면 시각적인 그래프가 Mermaid 형식으로 나타납니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrBsmHcHrDMh",
        "outputId": "86841556-e252-4e24-efdd-aed5b86d1c10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'integer': 16,\n",
              " 'root': 4,\n",
              " 'joke': \"알겠습니다. 다음은 제가 만든 유머입니다.\\n\\n1. Why did the scarecrow win an award?\\n2. Because he was outstanding in his field!\\n3. I'm not saying I'm lazy, but I once had a dream that I was drowning in an ocean of orange soda.\\n4. Turns out it was just a Fanta sea.\"}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅ 그래프 실행 예제\n",
        "initial_state = {'integer': 16}  # 입력 숫자는 16\n",
        "\n",
        "response = graph.invoke(initial_state)\n",
        "# ✅ invoke는 그래프를 실제로 실행시키는 함수입니다.\n",
        "# 결과적으로 'root'와 'joke'가 채워진 상태를 반환합니다.\n",
        "\n",
        "response\n",
        "# 예시 출력:\n",
        "# {\n",
        "#   'integer': 16,\n",
        "#   'root': 4,\n",
        "#   'joke': '1. Why did four chickens cross the road?\\n2. To get to the punchline...\\n...'\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbboFf3nrDMh"
      },
      "source": [
        "### 웹 검색 노드 만들기   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCTsYQR-rDMh"
      },
      "source": [
        "이번 실습에서는 웹 검색 툴 결과를 바탕으로, 실제 URL을 크롤링하여 문서의 내용을 가져오겠습니다.   \n",
        "\n",
        "랭체인에서 웹 페이지를 크롤링하기 위해서는 대표적으로 아래 3개의 방법을 사용할 수 있습니다.\n",
        "\n",
        "1. `WebBaseLoader` : BeautifulSoup4 기반의 기본 크롤러로, HTML 코드를 그대로 가져옵니다.\n",
        "2. `Docling` : 다양한 포맷의 문서를 텍스트 포맷으로 변환하는 오픈 소스 프로젝트로, 유용하나 빠른 실행을 위해 GPU 성능이 다소 요구됩니다.\n",
        "3. `FireCrawl`: API 기반의 유료 서비스로, 무료 라이센스는 총 500회 무료 사용이 가능합니다.   \n",
        "\n",
        "이후의 프로젝트에서는 고성능 파서를 활용하지만, 이번 실습은 WebBaseLoader를 사용하겠습니다 :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PUi6xqWrDMh",
        "outputId": "8fcd0574-ea88-4fc1-ace7-8f998e9e2e94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={'source': 'https://ko.wikipedia.org/wiki/%EB%8B%A4%EC%A4%91_%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8_%EC%8B%9C%EC%8A%A4%ED%85%9C', 'title': '다중 에이전트 시스템 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='\\n\\n\\n\\n다중 에이전트 시스템 - 위키백과, 우리 모두의 백과사전\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n본문으로 이동\\n\\n\\n\\n\\n\\n\\n\\n주 메뉴\\n\\n\\n\\n\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로특수 문서 목록\\n\\n\\n\\n\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\n\\n\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n기부\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n\\n\\n\\n\\n\\n\\n개인 도구\\n\\n\\n\\n\\n\\n기부 계정 만들기 로그인\\n\\n\\n\\n\\n\\n\\t\\t로그아웃한 편집자를 위한 문서 더 알아보기\\n\\n\\n\\n기여토론\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n처음 위치\\n\\n\\n\\n\\n\\n1\\n같이 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\n각주\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\n참고 문헌\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n다중 에이전트 시스템\\n\\n\\n\\n21개 언어\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaCatalàČeštinaDeutschΕλληνικάEnglishEspañolفارسیFrançaisItaliano日本語NederlandsPolskiPortuguêsRomânăРусскийУкраїнська中文粵語\\n\\n링크 편집\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n문서토론\\n\\n\\n\\n\\n\\n한국어\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\n\\n도구\\n\\n\\n\\n\\n\\n도구\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t동작\\n\\t\\n\\n\\n읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\t\\t일반\\n\\t\\n\\n\\n여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\\n\\n\\n\\n\\n\\n\\t\\t인쇄/내보내기\\n\\t\\n\\n\\n책 만들기PDF로 다운로드인쇄용 판\\n\\n\\n\\n\\n\\n\\t\\t다른 프로젝트\\n\\t\\n\\n\\n위키미디어 공용위키데이터 항목\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n위키백과, 우리 모두의 백과사전.\\n\\n\\n다중 에이전트 시스템 또는 멀티 에이전트 시스템(multi-agent system, MAS, \"자체 구성 시스템\", self-organized system)은 상호 작용하는 여러 지능형 에이전트로 구성된 컴퓨터 시스템이다.[1] 다중 에이전트 시스템은 개별 에이전트나 단일 시스템으로는 해결하기 어렵거나 불가능한 문제를 해결할 수 있다.[2] 지능에는 체계적, 기능적, 절차적 접근 방식, 알고리즘 검색 또는 강화 학습이 포함될 수 있다.[3]\\n상당한 중복에도 불구하고 다중 에이전트 시스템은 행위자 기반 모델(ABM)과 항상 동일하지는 않다. ABM의 목표는 특정 실제적 또는 공학적 문제를 해결하는 것이 아니라 일반적으로 자연 시스템에서 간단한 규칙을 준수하는 에이전트(반드시 \"지능적\"일 필요는 없음)의 집단적 행동에 대한 설명적인 통찰력을 검색하는 것이다. ABM이라는 용어는 과학 분야에서 더 자주 사용되는 경향이 있고, MAS는 엔지니어링 및 기술 분야에서 더 자주 사용되는 경향이 있다.[4] 다중 에이전트 시스템 연구가 적절한 접근 방식을 제공할 수 있는 응용 프로그램에는 온라인 거래[5], 재난 대응[6][7], 표적 감시[8] 및 사회 구조 모델링이 포함된다.[9]\\n\\n같이 보기[편집]\\n인공지능\\n인공생명\\n블랙박스\\n복잡계\\n창발\\n진화 연산\\n게임 이론\\n환각 (인공지능)\\n강화 학습\\n각주[편집]\\n\\n\\n↑ Yoav Shoham, Kevin Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations. Cambridge University Press, 2009. http://www.masfoundations.org/\\n\\n↑ Hu, J.; Turgut, A.; Lennox, B.; Arvin, F., \"Robust Formation Coordination of Robot Swarms with Nonlinear Dynamics and Unknown Disturbances: Design and Experiments\" IEEE Transactions on Circuits and Systems II: Express Briefs, 2021.\\n\\n↑ Stefano V. Albrecht, Filippos Christianos, Lukas Schäfer. Multi-Agent Reinforcement Learning: Foundations and Modern Approaches. MIT Press, 2024. https://www.marl-book.com/\\n\\n↑ Niazi, Muaz; Hussain, Amir (2011). “Agent-based Computing from Multi-agent Systems to Agent-Based Models: A Visual Survey” (PDF). 《Scientometrics》 89 (2): 479–499. arXiv:1708.05872. doi:10.1007/s11192-011-0468-9. S2CID\\xa017934527.\\xa0\\n\\n↑ Rogers, Alex; David, E.; Schiff, J.; Jennings, N.R. (2007). “The Effects of Proxy Bidding and Minimum Bid Increments within eBay Auctions”. 《ACM Transactions on the Web》 1 (2): 9–es. CiteSeerX\\xa010.1.1.65.4539. doi:10.1145/1255438.1255441. S2CID\\xa0207163424. 2010년 4월 2일에 원본 문서에서 보존된 문서. 2008년 3월 18일에 확인함.\\xa0\\n\\n↑ Schurr, Nathan; Marecki, Janusz; Tambe, Milind; Scerri, Paul; Kasinadhuni, Nikhil; Lewis, J.P. (2005). “The Future of Disaster Response: Humans Working with Multiagent Teams using DEFACTO” (PDF). 2013년 6월 3일에 원본 문서에서 보존된 문서. 2024년 1월 8일에 확인함.\\xa0\\n\\n↑ Genc, Zulkuf;  외. (2013). 〈Agent-Based Information Infrastructure for Disaster Management〉 (PDF). 《Intelligent Systems for Crisis Management》. Lecture Notes in Geoinformation and Cartography. 349–355쪽. doi:10.1007/978-3-642-33218-0_26. ISBN\\xa0978-3-642-33217-3.\\xa0\\n\\n↑ Hu, Junyan; Bhowmick, Parijat; Lanzon, Alexander (2020). “Distributed Adaptive Time-Varying Group Formation Tracking for Multiagent Systems With Multiple Leaders on Directed Graphs”. 《IEEE Transactions on Control of Network Systems》 7: 140–150. doi:10.1109/TCNS.2019.2913619. S2CID\\xa0149609966.\\xa0\\n\\n↑ Sun, Ron; Naveh, Isaac (2004년 6월 30일). “Simulating Organizational Decision-Making Using a Cognitively Realistic Agent Model”. 《Journal of Artificial Societies and Social Simulation》.\\xa0\\n\\n\\n참고 문헌[편집]\\nWooldridge, Michael (2002). 《An Introduction to MultiAgent Systems》. John Wiley & Sons. 366쪽. ISBN\\xa0978-0-471-49691-5.\\xa0\\nShoham, Yoav; Leyton-Brown, Kevin (2008). 《Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations》. Cambridge University Press. 496쪽. ISBN\\xa0978-0-521-89943-7.\\xa0\\nMamadou, Tadiou Koné; Shimazu, A.; Nakajima, T. (August 2000). “The State of the Art in Agent Communication Languages (ACL)”. 《Knowledge and Information Systems》 2 (2): 1–26.\\xa0\\nHewitt, Carl; Inman, Jeff (Nov–Dec 1991). “DAI Betwixt and Between: From \"Intelligent Agents\" to Open Systems Science” (PDF). 《IEEE Transactions on Systems, Man, and Cybernetics》 21 (6): 1409–1419. doi:10.1109/21.135685. S2CID\\xa039080989. 2017년 8월 31일에 원본 문서 (PDF)에서 보존된 문서.\\xa0\\nAutonomous Agents and Multi-Agent Systems|The Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS)\\nWeiss, Gerhard, 편집. (1999). 《Multiagent Systems, A Modern Approach to Distributed Artificial Intelligence》. MIT Press. ISBN\\xa0978-0-262-23203-6.\\xa0\\nFerber, Jacques (1999). 《Multi-Agent Systems: An Introduction to Artificial Intelligence》. Addison-Wesley. ISBN\\xa0978-0-201-36048-6.\\xa0\\nWeyns, Danny (2010). 《Architecture-Based Design of Multi-Agent Systems》. Springer. ISBN\\xa0978-3-642-01063-7.\\xa0\\nSun, Ron (2006). 《Cognition and Multi-Agent Interaction》. Cambridge University Press. ISBN\\xa0978-0-521-83964-8.\\xa0\\nKeil, David; Goldin, Dina (2006).  Weyns, Danny; Parunak, Van; Michel, Fabien, 편집. 《Indirect Interaction in Environments for Multiagent Systems》. 《Environments for Multiagent Systems II》. LNCS 3830 3830 (Springer). 68–87쪽. doi:10.1007/11678809_5. ISBN\\xa0978-3-540-32614-4.\\xa0\\nWhitestein Series in Software Agent Technologies and Autonomic Computing, published by Springer Science+Business Media Group\\nSalamon, Tomas (2011). 《Design of Agent-Based Models\\xa0: Developing Computer Simulations for a Better Understanding of Social Processes》. Bruckner Publishing. ISBN\\xa0978-80-904661-1-1.\\xa0\\nRussell, Stuart J.; Norvig, Peter (2003), 《Artificial Intelligence: A Modern Approach》 2판, Upper Saddle River, New Jersey: Prentice Hall, ISBN\\xa00-13-790395-2\\xa0\\nFasli, Maria (2007). 《Agent-technology for E-commerce》. John Wiley & Sons. 480쪽. ISBN\\xa0978-0-470-03030-1.\\xa0\\nCao, Longbing, Gorodetsky, Vladimir, Mitkas, Pericles A. (2009). Agent Mining: The Synergy of Agents and Data Mining, IEEE Intelligent Systems, vol. 24, no. 3, 64-72.\\nvte시스템 과학시스템의 유형\\n해부학\\n예술\\n생물학\\n복잡계\\n복잡적응계\\n개념체계\\n연결된 인간-환경계\\n데이터베이스\\n동역학계\\n생태계\\n경제\\n에너지계\\n형식체계\\n전체(홀론)\\n정보\\n법체계\\n단위\\n미터법\\n다중에이전트\\n신경계\\n비선형계\\n운영 체제\\n물리계\\n행성계\\n정치 체제\\n감각계\\n사회체제\\n항성계\\n문자체제\\n이론적 영역\\n테크톨로지\\n혼돈 이론\\n복잡계\\n제어이론\\n사이버네틱스\\n지구시스템과학\\n생명계\\n사회기술 시스템\\n시스템학\\n도시물질대사\\n세계체제론\\n\\n시스템 분석\\n시스템 생물학\\n시스템 동역학\\n시스템 생태학\\n시스템 공학\\n시스템 신경과학\\n시스템 약학\\n시스템 심리학\\n시스템 이론\\n시스템과학자\\n알렉산드르 보그다노프\\n러셀 L. 애코프\\n윌리엄 로스 애슈비\\n루제나 바이츠시\\n벨러 H. 바나티\\n그레고리 베이트슨\\n앤서니 스태퍼드 비어\\n리처드 E. 벨먼\\n루트비히 폰 베르탈란피\\n마거릿 보든\\n케네스 E. 볼딩\\n머리 보언\\n캐슬린 칼리\\n메리 카트라이트\\nC. 웨스트 처치먼\\n조지 댄치그\\n에츠허르 데이크스트라\\n하인츠 폰 푀르스터\\n스테퍼니 포리스트\\n제이 라이트 포레스터\\n바버라 그로스\\n찰스 A S 홀\\n리디아 카브라키\\n제임스 J. 케이\\n파이나 키릴로바\\n조지 클리어\\n알레나 레너드\\n에드워드 노턴 로렌즈\\n니클라스 루만\\n움베르토 마투라나\\n마거릿 미드\\n도넬라 메도스\\n미하일로 메사로비치\\n제임스 그리어 밀러\\n라디카 나그팔\\n하워드 T. 오덤\\n탤컷 파슨스\\n일리야 프리고진\\n첸쉐썬\\n아나톨 래퍼포트\\n피터 센게\\n클로드 섀넌\\n카티아 시카라\\n프란시스코 바렐라\\n마누엘라 M. 벨로소\\n케빈 워릭\\n노버트 위너\\n제니퍼 윌비\\n앤서니 윌든\\n응용\\n인류학에서의 시스템 이론\\n고고학에서의 시스템 이론\\n정치학에서의 시스템 이론\\n단체\\n시스템과학 단체 목록\\n프린키피아 사이버네티카\\n\\n\\n\\n전거 통제 국제\\nFAST\\n국가\\n독일\\n미국\\n체코\\n\\n\\n\\n\\n\\n원본 주소 \"https://ko.wikipedia.org/w/index.php?title=다중_에이전트_시스템&oldid=39781879\"\\n분류: 다중 에이전트 시스템숨은 분류: 해결되지 않은 속성이 있는 문서FAST 식별자를 포함한 위키백과 문서GND 식별자를 포함한 위키백과 문서LCCN 식별자를 포함한 위키백과 문서NKC 식별자를 포함한 위키백과 문서위키데이터 속성 P227을 사용하는 문서위키데이터 속성 P244를 사용하는 문서위키데이터 속성 P691을 사용하는 문서위키데이터 속성 P2163을 사용하는 문서위키데이터 속성 P7859를 사용하는 문서\\n\\n\\n\\n\\n\\n\\n 이 문서는 2025년 5월 11일 (일) 03:21에 마지막으로 편집되었습니다.\\n모든 문서는 크리에이티브 커먼즈 저작자표시-동일조건변경허락 4.0에 따라 사용할 수 있으며, 추가적인 조건이 적용될 수 있습니다. 자세한 내용은 이용 약관을 참고하십시오.Wikipedia®는 미국 및 다른 국가에 등록되어 있는 Wikimedia Foundation, Inc. 소유의 등록 상표입니다.\\n\\n\\n개인정보처리방침\\n위키백과 소개\\n면책 조항\\n행동 강령\\n개발자\\n통계\\n쿠키 정책\\n모바일 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n다중 에이전트 시스템\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n21개 언어\\n\\n\\n새 주제\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://gscampus.net/trends/?idx=164098468&bmode=view', 'title': '[25/05/20] AI 기술 패러다임의 변화, 멀티 에이전트 구조 본격화 : 글로벌소프트웨어캠퍼스 | IT트렌드', 'description': 'AI가 단일 모델 중심의 생성형 기술에서 벗어나, 복수의 에이전트가 협업하는 멀티 에이전트 구조로 빠르게 전환되고 있다. 최근 개최된 ‘Build 2025’ 컨퍼런스에서는 이러한 흐름에 맞춰, AI 에이전트 설계·배포·운영을 위한 통합 개발 환경과 오픈 플랫폼 기반 생태계 확장 전략이 대거 공개됐다.주요 발표 중 하나는 다양한 AI 에이전트를 조율하고 자동화할 수 있는 개발 플랫폼의 고도화다. 하나의 플랫폼 내에서 모델 선택 자동화, 성능 모니터링, 보안 관리, 로컬 실행 환경까지 통합적으로 제공되며, 업무 목적에 따른 에이전트 맞춤 설계와 배포가 가능해졌다. 특히 멀티 에이전트 오케스트레이션, 시맨틱 커널 기반의 실행 환경, 에이전트 간 상호작용(A2A) 기능 등이 추가되면서, 복잡한 업무의 유연한 자동화가 현실화되고 있다.개발 생애주기를 전반적으로 재구성하는 기술적 흐름도 뚜렷하게 나타났다. 프롬프트 관리, 경량평가, 코드 자동화 도구 등 AI 코딩 도구 전반이 비동기 방식으로 전환되며, 대규모 개발 환경에 최적화된 형태로 재설계됐다. 로컬 환경에서도 대형 언어 모델을 실행할 수 있는 기능이 추가되며, 클라우드 의존도를 줄이는 방향의 분산형 AI 운영도 가능해지고 있다.한편, 개방형 표준을 중심으로 한 에이전틱 웹 기반 생태계 확대도 주목받았다. HTML처럼 웹 상에서 AI 에이전트를 통합·활용할 수 있도록 설계된 ‘NLWeb’ 프로젝트와, 인증·보안·프로토콜 호환성 강화를 위한 MCP 생태계도 함께 공개되며, 향후 다양한 웹 콘텐츠와 AI 에이전트 간 상호작용 구조가 본격적으로 확장될 것으로 전망된다.Designed by @freepik', 'language': 'ko'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n[25/05/20] AI 기술 패러다임의 변화, 멀티 에이전트 구조 본격화 : 글로벌소프트웨어캠퍼스 | IT트렌드\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n알림\\n뒤로\\n\\n\\n알림 설정\\n뒤로\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t더보기\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n게시물 알림\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t내 글 반응\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t내가 작성한 게시물이나 댓글에 다른 사람이 댓글이나 답글을 작성하면 알려줍니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t공지사항\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t사이트에서 보내는 중요한 공지를 실시간으로 알려줍니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlarm\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n마이페이지\\n로그아웃\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n로그인이 필요합니다.\\n로그인\\n\\n\\n\\n\\n\\n\\n\\nAbout GSC\\n\\n\\n\\n\\n\\n브랜드\\n\\n\\n\\n\\n\\n인재채용\\n\\n\\n\\n\\n\\n교육센터\\n\\n\\n\\n\\n\\n\\n\\n기업교육 솔루션\\n\\n\\n\\n\\n\\n부트캠프\\n\\n\\n\\n\\n\\nGSC 트렌드\\n\\n\\n\\n\\n\\n언론보도\\n\\n\\n\\n\\n\\nIT트렌드\\n\\n\\n\\n\\n\\n\\n\\n사람업\\n\\n\\n\\n\\n\\n취업 정보\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n닫기\\n\\n\\n\\n\\n글로벌소프트웨어캠퍼스 | 맞춤형 ICT 교육 및 IT 실무 교육 프로그램 \\n\\n\\n\\n\\n \\n\\n\\n\\nAbout GSC\\n\\n\\n\\n브랜드\\n\\n\\n인재채용\\n\\n\\n교육센터\\n\\n\\n\\n\\n\\n기업교육 솔루션\\n\\n\\n\\n\\n부트캠프\\n\\n\\n\\n\\nGSC 트렌드\\n\\n\\n\\n언론보도\\n\\n\\nIT트렌드\\n\\n\\n\\n\\n\\n사람업\\n\\n\\n\\n취업 정보\\n\\n\\n\\n\\n\\n\\n\\n \\n로그인 \\n\\n\\n\\n\\n \\nicon\\n\\n \\nicon\\n\\n \\nicon\\n\\n \\n\\n\\nMENU\\n\\n\\n\\n\\n\\n글로벌소프트웨어캠퍼스 | 맞춤형 ICT 교육 및 IT 실무 교육 프로그램 \\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n글로벌소프트웨어캠퍼스\\n\\n\\n\\n\\n\\n\\n최신 IT 트랜드를 전합니다.\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n글로벌소프트웨어캠퍼스최신 IT 트렌드를 전합니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nI T - T R E N D S\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[25/05/20] AI 기술 패러다임의 변화, 멀티 에이전트 구조 본격화\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tIT 트렌드\\n\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\nAI가 단일 모델 중심의 생성형 기술에서 벗어나, 복수의 에이전트가 협업하는 멀티 에이전트 구조로 빠르게 전환되고 있다. 최근 개최된 ‘Build 2025’ 컨퍼런스에서는 이러한 흐름에 맞춰, AI 에이전트 설계·배포·운영을 위한 통합 개발 환경과 오픈 플랫폼 기반 생태계 확장 전략이 대거 공개됐다.주요 발표 중 하나는 다양한 AI 에이전트를 조율하고 자동화할 수 있는 개발 플랫폼의 고도화다. 하나의 플랫폼 내에서 모델 선택 자동화, 성능 모니터링, 보안 관리, 로컬 실행 환경까지 통합적으로 제공되며, 업무 목적에 따른 에이전트 맞춤 설계와 배포가 가능해졌다. 특히 멀티 에이전트 오케스트레이션, 시맨틱 커널 기반의 실행 환경, 에이전트 간 상호작용(A2A) 기능 등이 추가되면서, 복잡한 업무의 유연한 자동화가 현실화되고 있다.개발 생애주기를 전반적으로 재구성하는 기술적 흐름도 뚜렷하게 나타났다. 프롬프트 관리, 경량평가, 코드 자동화 도구 등 AI 코딩 도구 전반이 비동기 방식으로 전환되며, 대규모 개발 환경에 최적화된 형태로 재설계됐다. 로컬 환경에서도 대형 언어 모델을 실행할 수 있는 기능이 추가되며, 클라우드 의존도를 줄이는 방향의 분산형 AI 운영도 가능해지고 있다.한편, 개방형 표준을 중심으로 한 에이전틱 웹 기반 생태계 확대도 주목받았다. HTML처럼 웹 상에서 AI 에이전트를 통합·활용할 수 있도록 설계된 ‘NLWeb’ 프로젝트와, 인증·보안·프로토콜 호환성 강화를 위한 MCP 생태계도 함께 공개되며, 향후 다양한 웹 콘텐츠와 AI 에이전트 간 상호작용 구조가 본격적으로 확장될 것으로 전망된다.Designed by @freepik\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[25/05/21] 키워드가 아닌 대화로 검색 - 검색 구조의 변화, AI 모드\\n[25/05/19] UAI 데이터 센터 건설, AI 인프라 확장 가속화\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t목록\\n\\t\\t\\t\\t\\t\\t\\n글쓰기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n사업자 정보\\n\\n\\n\\n\\n\\n\\n글로벌소프트웨어캠퍼스(주)주소: 서울시 강남구 도곡로 111, 10층(역삼동, 미진빌딩)사업자등록번호: 220-88-63489 | 대표이사: 김성우전화번호: 070-4231-0811 | 팩스: 02-546-6789 | 이메일: help@gscampus.net강남 교육센터: 서울시 강남구 도곡로 112, 서한빌딩 3층상암 교육센터: 서울시 마포구 월드컵북로 434, 상암IT타워 6층신촌 교육센터: 서울시 서대문구 연세로 8-1, 버티고빌딩 11층\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n 제휴/제안marketing@gscampus.net메일 보내기\\n\\n\\n\\n\\n\\n\\n@2024 글로벌소프트웨어캠퍼스(주). All rights reserved.\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n사업자 정보\\n\\n\\n\\n글로벌소프트웨어캠퍼스(주)주소: 서울시 강남구 도곡로 111, 10층(역삼동, 미진빌딩)사업자등록번호: 220-88-63489 | 대표이사: 김성우유료직업소개사업등록증 : 제 2025-3220250-14-5-00020호통신판매업신고번호: 제 2023-서울강남-06459 호전화번호: 070-4231-0811 | 팩스: 02-546-6789강남 교육센터: 서울시 강남구 도곡로 112, 서한빌딩 3층상암 교육센터: 서울시 마포구 월드컵북로 434, 상암IT타워 6층신촌 교육센터: 서울시 서대문구 연세로 8-1, 버티고빌딩 11층\\n\\n\\n\\n제휴 및 제안\\n\\n\\n \\nE-mail: marketing@gscampus.net\\n\\n\\n\\n\\n\\n\\n브랜드 채널 바로가기\\n\\n\\n\\nBlog↖︎Youtube↖︎Instagram↖︎\\n\\n\\n\\n이용약관 |\\xa0개인정보처리방침 |\\xa0사업자정보확인 \\xa0\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n@2024 GLOBAL SOFTWARE CAMPUS. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tCopyright ⓒ 2025 글로벌소프트웨어캠퍼스 | 맞춤형 ICT 교육 및 IT 실무 교육 프로그램 All rights reserved.\\n\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAndroid app on\\nGOOGLE PLAY\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDownload on the\\nAPP STORE\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://www.ibm.com/kr-ko/think/topics/multiagent-system', 'title': '다중 에이전트 시스템이란 무엇인가요? | IBM', 'description': '다중 에이전트 시스템(MAS)은 사용자 또는 다른 시스템을 대신하여 작업을 수행하기 위해 공동으로 작동하는 여러 인공 지능(AI) 에이전트로 구성됩니다.', 'language': 'ko'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n다중 에이전트 시스템이란 무엇인가요? | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    멀티에이전트 시스템이란 무엇인가요?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2024년 8월 6일\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    작성자\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnna Gutowska\\n\\nAI Engineer, Developer Advocate\\nIBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n다중 에이전트 시스템(MAS)은 사용자 또는 다른 시스템을 대신하여 작업을 수행하기 위해 공동으로 작동하는 여러 인공 지능(AI) 에이전트로 구성됩니다.\\n\\n\\nMAS 내의 각 에이전트는 개별 속성을 가지지만 모든 에이전트는 원하는 글로벌 속성을 이끌어내기 위해 협업적으로 작동합니다.1\\xa0다중 에이전트 시스템은 수천 명은 아니더라도 수백 명의 에이전트를 포괄하는 대규모의 복잡한 작업을 완료하는 데 유용합니다.2\\n이 아이디어의 핵심은 인공 지능(AI)\\xa0에이전트입니다. AI 에이전트는 워크플로우를 설계하고 사용 가능한 도구를 사용하여 사용자나 다른 시스템을 대신하여 자율적으로 작업을 수행할 수 있는 시스템 또는 프로그램을 말합니다. AI 에이전트의 핵심은\\xa0대규모 언어 모델(LLM)입니다. 이러한 지능형 에이전트는 LLM의 고급 자연어 처리 기술을 활용하여 사용자 입력을 이해하고 이에 응답합니다. 에이전트는 문제를 단계별로 해결하고 언제 외부 도구를 호출할지 결정합니다. AI 에이전트가 기존 LLM과 차별화되는 점은 도구 사용과 실행 계획을 설계할 수 있다는 점입니다. 에이전트가 사용할 수 있는 도구에는 외부 데이터 세트, 웹 검색 및 API(애플리케이션 프로그래밍 인터페이스)가 포함될 수 있습니다. 사람의 의사 결정과 마찬가지로 AI 에이전트도 새로운 정보를 습득하면서 메모리를 업데이트할 수 있습니다. 정보 공유, 도구 사용 및 적응형 학습을 통해 AI 에이전트는 기존 LLM보다 더 범용적으로 사용할 수 있습니다.\\n단일 에이전트 시스템에 대한 자세한 내용은 자세한 AI 에이전트 콘텐츠를 참조하십시오.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                최신 AI 뉴스 + 인사이트\\n\\n            \\n\\n                주간 Think 뉴스레터에서 전문가들이 선별한 AI, 클라우드 등에 관한 인사이트와 소식을 살펴보세요.\\xa0\\n\\n            \\n\\n\\n\\n지금 구독하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        단일 에이전트와 다중 에이전트 시스템 비교\\r\\n    \\n\\n\\n\\n단일 상담원 지능형 시스템은 환경과 연동하여 자율적으로 계획하고, 도구를 호출하고, 응답을 생성합니다. 상담원이 사용할 수 있는 도구는 다른 방법으로는 사용할 수 없는 정보를 제공합니다. 앞서 설명한 대로 이 정보는 API나 다른 에이전트를 통해 획득한 데이터베이스일 수 있습니다. 여기에는 단일 상담원 시스템과 다중 상담원 시스템의 차이점이 있습니다. 다른 에이전트를 도구로 호출할 때 보조 에이전트는 원래 에이전트의 환경 자극의 일부가 됩니다. 해당 정보만 획득하고 더 이상의 협력은 이루어지지 않습니다. 반면 멀티 에이전트 시스템은 환경 내의 모든 에이전트가 참여하여 서로의 목표, 기억, 행동 계획을 모델링한다는 점에서 다릅니다.4 에이전트 간의 커뮤니케이션은 공유 환경을 변경하여 직접 또는 간접적으로 이루어질 수 있습니다.\\n다중 에이전트 시스템 내의 각 엔터티는 어느 정도 자율적인 에이전트입니다. 이러한 자율성은 일반적으로 에이전트의 계획, 도구 호출 및 일반적인 추론에서 볼 수 있습니다. 다중 에이전트 시스템에서 에이전트는 자율성을 유지하지만 에이전트 구조에서 협력하고 조정합니다.3 복잡한 문제를 해결하기 위해서는 에이전트 커뮤니케이션과 분산된 문제 해결이 핵심입니다. 이러한 유형의 에이전트 상호 작용은 다중 에이전트\\xa0강화 학습으로 설명할 수 있습니다. 이러한 형태의 학습을 통해 공유하는 정보에는 센서나 행동을 통해 획득한 즉각적인 정보가 포함될 수 있습니다. 또한 상담원의 경험을 에피소드 정보 형태로 공유할 수 있습니다. 이러한 에피소드는 감각, 행동 및 학습된 정책의 순서일 수 있습니다. 마지막으로, 상담원은 자신의 경험을 실시간으로 공유하여 다른 상담원이 동일한 정책을 반복적으로 학습하는 것을 방지할 수 있습니다.5\\n개별 에이전트는 스스로 강력합니다. 그들은 하위 작업을 만들고, 도구를 사용하고, 상호 작용을 통해 학습할 수 있습니다. 멀티 에이전트 시스템의 집단적 행동은 정확성, 적응성 및 확장성의 잠재력을 높입니다. 멀티 에이전트 시스템은 공유 리소스 풀, 최적화 및 자동화를 통해 단일 에이전트 시스템보다 성능이 뛰어난 경향이 있습니다. 여러 에이전트가 동일한 정책을 학습하는 대신, 학습한 경험을 공유하여 시간 복잡도와 효율성을 최적화할 수 있습니다.5\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      Mixture of Experts | 4월 25일, 에피소드 52\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    AI 디코딩: 주간 뉴스 요약\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n세계적인 수준의 엔지니어, 연구원, 제품 리더 등으로 구성된 패널과 함께 불필요한 AI 잡음을 차단하고 실질적인 AI 최신 소식과 인사이트를 확인해 보세요.\\n\\n\\n\\n\\n\\n최신 팟캐스트 에피소드 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        멀티 에이전트 시스템의 아키텍처\\r\\n    \\n\\n\\n\\n중앙 집중식 네트워크\\n\\n\\n다중 에이전트 시스템은 다양한 아키텍처에서 작동할 수 있습니다. 중앙 집중식 네트워크에서는 중앙 장치가 글로벌 지식 기반을 포함하고, 에이전트를 연결하며, 에이전트의 정보를 감독합니다. 이 구조의 장점은 에이전트 간의 커뮤니케이션이 용이하고 지식이 통일된다는 점입니다. 중앙 집중식의 약점은 중앙 유닛에 대한 의존성이며, 중앙 유닛이 실패하면 전체 에이전트 시스템이 실패한다는 것입니다.6\\n\\n\\n분산형 네트워크\\n\\n\\n에이전트는 글로벌 지식 베이스 대신 인접 에이전트와 정보를 공유합니다. 탈중앙화 네트워크의 몇 가지 이점은 견고성과 모듈성입니다. 한 에이전트에 장애가 발생해도 중앙 장치가 없기 때문에 전체 시스템에 장애가 발생하지 않습니다. 탈중앙화 에이전트의 한 가지 과제는 다른 협력 에이전트에게 이익이 되도록 자신의 행동을 조정하는 것입니다.7\\n\\n\\n\\r\\n        멀티에이전트 시스템의 구조\\r\\n    \\n\\n\\n\\n또한 다중 에이전트 시스템 내에서 에이전트를 구성하는 방법에는 여러 가지가 있습니다.\\n\\n\\n계층적 구조(Hierarchical structure)\\n\\n\\n계층 구조는 트리 구조와 유사하며 다양한 수준의 자율성을 가진 에이전트를 포함합니다. 단순 계층 구조에서는 한 명의 에이전트가 의사 결정 권한을 가질 수 있습니다. 단일 계층 구조에서는 여러 에이전트에게 책임이 분산될 수 있습니다.8\\n\\n\\nHolonic 구조\\n\\n\\n이 아키텍처 유형 내에서 에이전트는 홀라키로 그룹화됩니다. 홀론은 구성 요소 없이는 작동할 수 없는 개체입니다. 예를 들어, 인체는 일하는 기관 없이는 기능할 수 없기 때문에 홀론입니다.9\\xa0마찬가지로, 홀로닉 다중 에이전트 시스템에서는 선행 에이전트가 단일 개체처럼 보이지만 여러 하위 에이전트를 가질 수 있습니다.8\\xa0이 하위 에이전트는 다른 홀론에서도 역할을 할 수 있습니다. 이러한 계층적 구조는 자체 조직화되며 하위 에이전트의 협업을 통해 목표를 달성하기 위해 생성됩니다.\\n\\n\\n연합 구조\\n\\n\\n연합은 그룹 내 단일 에이전트의 성능이 저조한 경우에 유용합니다. 이러한 상황에서는 에이전트가 일시적으로 연합하여 활용도나 성능을 높일 수 있습니다. 원하는 성능에 도달하면 연합은 해체됩니다. 역동적인 환경에서는 이러한 연합을 유지하기가 어려울 수 있습니다. 성능을 향상시키기 위해 종종 재그룹화가 필요합니다.9\\n\\n\\n팀\\n\\n\\n팀은 연합과 구조가 비슷합니다. 팀에서는 상담원들이 협력하여 그룹의 성능을 개선합니다. 팀의 상담원은 연합과 달리 독립적으로 작업하지 않습니다. 팀의 상담원들은 서로에게 훨씬 더 많이 의존하며 그 구조는 연합보다 더 계층적입니다.8\\n\\n\\n\\r\\n        멀티에이전트 시스템의 동작\\r\\n    \\n\\n\\n\\n다중 에이전트 시스템 내에서 에이전트의 동작은 종종 자연에서 발생하는 동작을 반영합니다. 다음 에이전트 동작은 다중 소프트웨어 및 다중 로봇 에이전트 모두에 적용될 수 있습니다.\\n\\n\\n플로킹\\n\\n\\n다중 에이전트 시스템에서 볼 수 있는 집단 행동은 새, 물고기, 인간의 행동과 유사할 수 있습니다. 이러한 시스템에서 에이전트는 목표를 공유하며 행동을 조율하기 위해 일부 조직이 필요합니다. 군집은 방향 동기화와 관련이 있으며 이러한 군집의 구조는 다음과 같은 경험적 방법으로 설명할 수 있습니다.\\xa010\\n분리: 근처 에이전트와의 충돌을 피하려고 시도합니다.정렬: 주변 에이전트의 속도를 맞춥니다.응집력: 다른 에이전트들과 친밀감을 유지하려고 노력합니다.\\n소프트웨어 에이전트의 맥락에서 이러한 조정은 철도 시스템과 같은 운송 네트워크를 관리하는 다중 에이전트 시스템에 매우 중요합니다.\\n\\n\\n스워밍\\n\\n\\n다중 에이전트 시스템에서 에이전트의 공간 위치는 자연에서 발생하는 스워밍(swarming)과 비교할 수 있습니다. 예를 들어, 새들은 이웃 새들에게 적응함으로써 조화를 이루며 날아갑니다. 기술적 관점에서 볼 때, 스워밍(swarming)은 분산형 제어를 가진 소프트웨어 에이전트 간의 창발적인 자기 조직화 및 집계입니다.11\\xa0스워밍의 이점은 한 명의 운영자가 에이전트 스웜을 관리하도록 훈련받을 수 있다는 것입니다. 이 방법은 각 에이전트에 대해 운영자를 훈련시키는 것보다 계산 비용이 적게 들고 더 안정적입니다.12\\n\\n\\n다중 에이전트 시스템의 사용 사례\\n\\n\\n멀티에이전트 시스템은 많은 복잡한 실제 작업을 해결할 수 있습니다. 적용 가능한 도메인의 몇 가지 예는 다음과 같습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    운송\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n다중 에이전트 시스템은 운송 시스템을 관리하는 데 사용할 수 있습니다. 복잡한 운송 시스템을 조정할 수 있는 다중 에이전트 시스템의 특성은 커뮤니케이션, 협업, 계획 및 실시간 정보 액세스입니다. MAS의 이점을 누릴 수 있는 분산 시스템의 예로는 철도 시스템, 트럭 배정, 같은 항구를 방문하는 해상 선박 등이 있습니다.13\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    의료 및 공중 보건\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n다중 에이전트 시스템은 의료 분야의 다양한 특정 작업에 사용될 수 있습니다. 이러한 에이전트 기반 시스템은 유전자 분석을 통해 질병 예측 및 예방에 도움을 줄 수 있습니다. 암에 대한 의학 연구가 한 가지 예가 될 수 있습니다.14\\xa0또한 다중 에이전트 시스템은 전염병 확산을 예방하고 시뮬레이션하는 툴로 사용될 수 있습니다. 이러한 예측은 역학 정보에 기반한 신경망과\\xa0머신 러닝(ML)\\xa0기술을 사용하여 대규모 데이터 세트를 관리함으로써 가능합니다. 이러한 결과는 공공 보건과 공공 정책에 영향을 미칠 수 있습니다.15\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    공급망 관리\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n수많은 요인이 공급망에 영향을 미칩니다. 이러한 요인은 상품 생성에서 소비자 구매에 이르기까지 다양합니다. 멀티에이전트 시스템은 방대한 정보 리소스, 다양성 및 확장성을 사용하여\\xa0공급망 관리의 구성 요소를 연결할 수 있습니다. 이\\xa0지능형 자동화를 가장 잘 탐색하려면 가상 에이전트\\xa0가 서로 협상해야 합니다. 이 협상은 목표가 상충되는 다른 상담원과 협업하는 상담원에게 중요합니다.16\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    방위 시스템\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n다중 에이전트 시스템은 방어 시스템을 강화하는 데 도움이 될 수 있습니다. 잠재적 위협에는 물리적 국가 안보 문제와 사이버 공격이 모두 포함될 수 있습니다. 다중 에이전트 시스템은 도구를 사용하여 잠재적인 공격을 시뮬레이션할 수 있습니다. 한 가지 예는 해상 공격 시뮬레이션입니다. 이 시나리오에는 에이전트들이 팀을 이루어 침입하는 테러리스트 보트와 방어 선박 간의 상호 작용을 포착하는 것이 포함됩니다.17\\xa0또한 에이전트는 협업 팀으로 작업하여 네트워크의 여러 영역을 모니터링하여\\xa0DDoS(분산 서비스 거부)\\xa0플러딩 공격과 같은 들어오는 위협을 탐지할 수 있습니다.18\\n\\n\\n\\n\\n\\n\\r\\n        멀티에이전트 시스템의 장점\\r\\n    \\n\\n\\n\\n다중 에이전트 시스템에는 다음과 같은 이점을 제공하는 몇 가지 특성이 있습니다.\\n\\n\\n유연성\\n\\n\\n다중 에이전트 시스템은 에이전트를 추가, 제거 또는 조정하여 다양한 환경에 맞게 조정할 수 있습니다.\\n\\n\\n확장성\\n\\n\\n여러 에이전트가 협력하면 더 많은 정보를 공유할 수 있습니다. 이러한 협업을 통해 다중 에이전트 시스템은 단일 에이전트 시스템보다 더 복잡한 문제와 작업을 해결할 수 있습니다.\\n\\n\\n도메인 전문화\\n\\n\\n단일 에이전트 시스템에서는 다양한 도메인에서 작업을 수행하기 위해 하나의 에이전트가 필요하지만 다중 에이전트 시스템의 각 에이전트는 특정 도메인 전문성을 보유할 수 있습니다.\\n\\n\\n성능 향상\\n\\n\\n다중 에이전트 프레임워크는 단일 에이전트보다 성능이 뛰어난 경향이 있습니다.19\\xa0이는 에이전트가 사용할 수 있는 실행 계획이 많을수록 더 많은 학습과 성찰이 일어나기 때문입니다. 관련 분야의 전문 지식을 가진 다른 AI 에이전트의 지식과 피드백을 통합하는 AI 에이전트는 정보 합성에 유용할 수 있습니다. AI 에이전트의 이러한 백엔드 협업과 정보 격차를 메우는 능력은 에이전트 프레임워크의 고유한 특성으로, 강력한 도구이자 인공 지능의 의미 있는 발전입니다.\\n\\n\\n\\r\\n        다중 에이전트 시스템의 과제\\r\\n    \\n\\n\\n\\n다중 에이전트 시스템을 설계하고 구현하는 데에는 다음과 같은 몇 가지 과제가 있습니다.\\n\\n\\n에이전트 오작동\\n\\n\\n동일한\\xa0파운데이션 모델에\\xa0구축된 다중 에이전트 시스템은 공유된 함정을 경험할 수 있습니다. 이러한 약점은 관련된 모든 에이전트의 시스템 전체에 장애를 일으키거나 악의적인 공격에 취약성을 노출시킬 수 있습니다.20\\xa0이는 기반 모델 구축에 있어 데이터 거버넌스의 중요성과 철저한 교육 및 테스트 프로세스의 필요성을 강조합니다.\\n\\n\\n조정 복잡성\\n\\n\\n멀티 에이전트 시스템을 구축할 때 가장 큰 어려움 중 하나는 서로 조율하고 협상할 수 있는 에이전트를 개발하는 것입니다. 이러한 협력은 멀티 에이전트 시스템이 제대로 작동하기 위해 필수적입니다.\\n\\n\\n예측할 수 없는 행동\\n\\n\\n탈중앙화 네트워크에서 자율적이고 독립적으로 활동하는 에이전트는 충돌하거나 예측할 수 없는 행동을 경험할 수 있습니다. 이러한 조건에서는 더 큰 시스템 내에서 문제를 감지하고 관리하는 것이 어려울 수 있습니다.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                보고서\\n            \\n\\n                 2025년 주요 전략 기술 트렌드: 에이전틱 AI\\n            \\n이 Gartner 연구를 다운로드하여 IT 리더를 위한 에이전틱 AI의 잠재적 기회와 위험을 알아보고, AI 혁신의 다음 물결에 대비하는 방법을 배워보세요.\\n\\n보고서 읽기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    리소스\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                보고서\\n            \\n\\n                2024년 AI 활용 현황\\n            \\nIBM은 2,000개 조직을 대상으로 AI 이니셔티브에 대한 설문조사를 실시하여 효과적인 전략과 효과적이지 못한 전략, 그리고 앞서나갈 수 있는 방법을 알아보았습니다.\\n\\n보고서 읽기\\n\\n\\n\\n\\n\\n\\n\\n\\n                AI 모델\\n            \\n\\n                IBM Granite 살펴보기\\n            \\nIBM Granite는 비즈니스에 맞게 맞춤화되고 AI 애플리케이션 확장에 최적화되었으며 개방적이고 성능이 뛰어나며 신뢰할 수 있는 AI 모델 제품군입니다. 언어, 코드, 시계열 및 가드레일 옵션을 살펴보세요.\\n\\nGranite 소개\\n\\n\\n\\n\\n\\n\\n\\n\\n                교육\\n            \\n\\n                AI 전문성 업그레이드\\n            \\n지금 개인 또는 여러 사용자 구독을 구매하여 100개가 넘는 온라인 과정에 액세스하세요. 저렴한 가격으로 다양한 제품에 걸쳐 기술을 확장할 수 있습니다.\\n\\n학습 시작하기\\n\\n\\n\\n\\n\\n\\n\\n\\n                동영상\\n            \\n\\n                IBM AI Academy\\n            \\nIBM 사고 리더들이 이끄는 이 커리큘럼은 비즈니스 리더들에게 성장을 촉진하는 AI 투자의 우선순위를 정하는 데 필요한 지식을 제공합니다.\\n\\n시리즈 살펴보기\\n\\n\\n\\n\\n\\n\\n\\n\\n                안내서\\n            \\n\\n                업무에 AI 활용: 생성형 AI로 ROI 향상\\n            \\nAI 투자에 대해 더 나은 수익을 얻고 싶으신가요? 주요 영역에서 차세대 AI를 확장하여 최고의 인재들이 혁신적인 새 솔루션을 구축하고 제공하도록 지원함으로써 변화를 주도하는 방법을 알아보세요.\\n\\n안내서 읽기\\n\\n\\n\\n\\n\\n\\n\\n\\n                eBook\\n            \\n\\n                생성형 AI + ML의 힘 활용하기\\n            \\n생성형 AI와 머신 러닝을 비즈니스에 자신 있게 통합하는 방법 알아보기\\n\\neBook 읽기\\n\\n\\n\\n\\n\\n\\n\\n\\n                안내서\\n            \\n\\n                신뢰와 확신을 바탕으로 새로운 AI 시대에 성공하는 방법\\n            \\n강력한 AI 전략의 3가지 핵심 요소인 경쟁 우위 확보, 비즈니스 전반의 AI 확장, 신뢰할 수 있는 AI 발전에 대해 자세히 알아보세요.\\n\\n안내서 읽기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    관련 솔루션\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    IBM watsonx.ai\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nAI 빌더를 위한 차세대 엔터프라이즈 스튜디오인 IBM watsonx.ai로 생성형 AI, 파운데이션 모델 및 머신 러닝 기능을 학습, 검증, 조정 및 배포하세요. 적은 데이터로 짧은 시간 내에 AI 애플리케이션을 구축하세요.\\n\\n\\n\\n\\nwatsonx.ai에 대해 알아보기\\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    인공 지능 솔루션\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n업계 최고의 AI 전문성과 솔루션 포트폴리오를 보유한 IBM과 함께 AI를 비즈니스에 활용하세요.\\n\\n\\n\\n\\nAI 솔루션 살펴보기\\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI 컨설팅 및 서비스\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nAI 추가를 통해 중요한 워크플로와 운영을 혁신함으로써 경험, 실시간 의사 결정 및 비즈니스 가치를 극대화합니다.\\n\\n\\n\\n\\nAI 서비스 살펴보기\\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n다음 단계 안내\\n\\n\\n\\n\\nAI 개발 라이프사이클 전반에 걸친 기능에 원스톱으로 액세스하세요. 사용자 친화적인 인터페이스, 워크플로, 업계 표준 API 및 SDK에 대한 액세스를 통해 강력한 AI 솔루션을 제작할 수 있습니다.\\n\\n\\n\\n\\n\\n\\nwatsonx.ai 살펴보기\\n\\n\\n\\n\\n\\n라이브 데모 예약하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            \\n\\n\\n\\n  \\n    각주\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                        \\n\\n\\n\\n\\n\\n1\\xa0Edmund H. Durfee 및 Jeffrey S. Rosenschein, \"Distributed problem solving and multi-agent systems: Comparisons and examples.\" In\\xa0Proceedings of the Thirteenth International Distributed Artificial Intelligence Workshop, 1994,\\xa0https://aaai.org/papers/000-ws94-02-004/\\xa0(link resides outside ibm.com)\\n\\n² David Kinny 및 Michael Georgeff, \"Modelling and design of multi-agent systems,\"\\xa0International Workshop on Agent Theories, Architectures, and Languages, 1996년,\\xa0https://link.springer.com/chapter/10.1007/BFb0013569\\xa0(ibm.com 외부 링크)\\n³ Michael Wooldridge,\\xa0An introduction to multiagent systems. John Wiley & Sons, 2009년,\\xa0https://dl.acm.org/doi/10.5555/1695886\\xa0(ibm.com 외부 링크)\\n⁴ Peter Stone 및 Manuela Veloso, “Multiagent Systems: A Survey from a Machine Learning Perspective,” Autonomous Robotics, 2000년,\\xa0https://link.springer.com/article/10.1023/A:1008942012299\\xa0(ibm.com 외부 링크)\\n⁵\\xa0Ming Tan, “Multi-Agent Reinforcement Learning: Independent versus Cooperative Agent,”\\xa0Proceedings of the tenth international conference on machine learning, 1993년,\\xa0https://web.media.mit.edu/~cynthiab/Readings/tan-MAS-reinfLearn.pdf\\xa0(ibm.com 외부 링크)\\n⁶\\xa0Jianan Wang, Chunyan Wang, Ming Xin, Zhengtao Ding 및 Jiayuan Shan,\\xa0Cooperative Control of Multi-Agent Systems: An Optimal and Robust Perspective, Academic Press, 2020년,\\xa0https://www.sciencedirect.com/book/9780128201183/cooperative-control-of-multi-agent-systems?via=ihub=\\xa0(ibm.com 외부 링크)\\n⁷\\xa0Lucian Busoniu, Bart De Schutter 및 Robert Babuska, “Decentralized reinforcement learning control of a robotic manipulator,”\\xa0Proceedings of the 9th International Conference on Control, Automation, Robotics and Vision, 2006년,\\xa0https://ieeexplore.ieee.org/document/4150192\\xa0(ibm.com 외부 링크)\\n⁸\\xa0Parasumanna Gokulan Balaji 및 Dipti Srinivasan, \"An Introduction to Multi-Agent Systems,”\\xa0Innovations in Multi-Agent Systems and Applications - 1, 2010년,\\xa0https://link.springer.com/chapter/10.1007/978-3-642-14435-6_1\\xa0(ibm.com 외부 링크)\\n⁹\\xa0Vincent Hilaire, Abder Koukam 및 Sebastian Rodriguez, \"An adaptative agent architecture for holonic multi-agent systems,\"\\xa0ACM Transactions on Autonomous and Adaptive Systems (TAAS), 2008년,\\xa0https://dl.acm.org/doi/10.1145/1342171.1342173\\xa0(ibm.com 외부 링크)\\n¹⁰\\xa0Reza Olfati-Saber, “Flocking for Multi-Agent Dynamic Systems: Algorithms and Theory,”\\xa0EEE Transactions on automatic control\\xa051, no. 3, 2006년,\\xa0https://ieeexplore.ieee.org/document/1605401\\xa0(ibm.com 외부 링크)\\n¹¹\\xa0H. Van Dyke Parunak 및 Sven A. Brueckner, \"Engineering swarming systems,\"\\xa0Methodologies and software engineering for agent systems, 2004년,\\xa0https://link.springer.com/chapter/10.1007/1-4020-8058-1_21\\xa0(ibm.com 외부 링크)\\n¹²\\xa0Ross Arnold, Kevin Carey, Benjamin Abruzzo 및 Christopher Korpela, \"What is a robot swarm: a definition for swarming robotics,\"\\xa0IEEE 10th annual ubiquitous computing, electronics & mobile communication conference (uemcon), 2019년,\\xa0https://ieeexplore.ieee.org/document/8993024\\xa0(ibm.com 외부 링크)\\n¹³\\xa0Hans Moonen,\\xa0Multi-agent systems for transportation planning and coordination,\\xa02009년.\\n¹⁴\\xa0Elhadi Shakshuki and Malcolm Reid, “Multi-Agent System Applications in Healthcare: Current Technology and Future Roadmap,”\\xa0Procedia Comput Sci,\\xa02015년,\\xa0https://www.sciencedirect.com/science/article/pii/S1877050915008716?via%3Dihub\\xa0(ibm.com 외부 링크)\\n¹⁵\\xa0Alexander Rodríguez, \"AI & Multi-agent Systems for Data-centric Epidemic Forecasting,\"\\xa0AAMAS, 2023년,\\xa0https://dl.acm.org/doi/10.5555/3545946.3599132\\xa0(ibm.com 외부 링크)\\n¹⁶ Ksenija Mandic 및 Boris Delibašić, “Application Of Multi-Agent Systems In Supply Chain Management,”\\xa0Management Journal of Sustainable Business and Management Solutions in Emerging Economies, 2012년,\\xa0https://scindeks.ceon.rs/article.aspx?artid=0354-86351263075M\\xa0(ibm.com 외부 링크)\\n¹⁷\\xa0Thomas W. Lucas, Susan M. Sanchez, Lisa R. Sickinger, Felix Martinez and Jonathan W. Roginski,\\xa02007 Winter Simulation Conference, 2007년,\\xa0https://ieeexplore.ieee.org/document/4419596\\xa0(ibm.com 외부 링크)\\n¹⁸\\xa0Igor Kotenko, Multi-agent Modelling and Simulation of Cyber-Attacks and Cyber-Defense for Homeland Security,\\xa0IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, 2007년,\\xa0https://ieeexplore.ieee.org/document/4488494(ibm.com 외부 링크)\\n¹⁹\\xa0Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu 및 Deheng Ye. \"More agents is all you need.\"\\xa0arXiv preprint, 2024년,\\xa0https://arxiv.org/abs/2402.05120\\xa0(ibm.com 외부 링크)\\n²⁰\\xa0Alan Chan, Carson Ezell, Max Kaufmann, Kevin Wei, Lewis Hammond, Herbie Bradley, Emma Bluemke, Nitarshan Rajkumar, David Krueger, Noam Kolt, Lennart Heim 및 Markus Anderljung, “Visibility into\\xa0AI Agents,”\\xa0The 2024 ACM Conference on Fairness, Accountability, and Transparency, 2024년,\\xa0https://arxiv.org/abs/2401.13138\\xa0(ibm.com 외부 링크)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://velog.io/@dutch-tulip/ai-agent', 'title': '[Survey] Deep dive into AI Agent & Multi-Agent System (MAS)', 'description': 'AI Agent는 LLM의 출력 퀄리티를 높이기 위해 최종 출력물을 내기 전 내부적으로 작업을 여러번하도록 할 수 있다.', 'language': 'No language found.'}, page_content='\\n[Survey] Deep dive into AI Agent & Multi-Agent System (MAS)tu11p로그인tu11p로그인[Survey] Deep dive into AI Agent & Multi-Agent System (MAS)tu11p·2024년 11월 25일팔로우0AILLMMulti-Agentagentmas0LLM목록 보기2/2AI Agent\\n\\n언어 모델을 기반으로 인간을 대신해 특정 목적을 달성하기 위해 설계된 지능형 시스템\\n주어진 입력(텍스트, 명령어, 대화 등)을 처리해 원하는 출력(정보, 결정, 행동 등)을 생성\\n특정 작업 및 특정 사례에 특화되어 사용 가능 \\nLangChain에서는 AI Agent를, ‘LLM을 사용해 애플리케이션의 제어 흐름을 결정하는 시스템’이라고 정의\\n\\n그럼 우리는 왜 AI Agent를 사용할까, 아니 왜 사용해야 할까?\\n\\n일반적인 LLM 기반 서비스 사용자들(ChatGPT and so on…)은 zero-shot mode로 최종 결과물을 출력하게 사용한다.\\n이는 누군가에게 처음부터 끝까지 에세이를 써달라고 하면서도, backspace없이 정확히 typing하고 higy quality의 result를 기대하는 것과 비슷하다.\\n그러나 LLM은 이러한 어려움을 이겨내고 잘 해낸다.\\n\\nAI Agent를 사용하면, LLM에게 최종 출력물을 내기 전에 내부적으로 작업을 여러번 반복하도록 할 수 있다(출력 퀄리티를 높이기 위해).\\n\\n\\n\\n실제로 GPT-3.5와 GPT-4에서 zero-shot과 agent workflow로 HumanEval(코드 생성 벤치마크) 퍼포먼스를 비교한 결과, agent를 사용했을 때 월등한 성능 향상을 보였다.\\nGPT-3.5 with agent는 GPT-4 Vanilla 보다 성능이 좋다..\\n\\n\\nAI Agent의 구조\\n\\nAI Agent의 구조는 크게 5개로 나눌 수 있다.\\n코어가 되는 LLM, 그리고 Planning/Action/Profile/Memory\\n\\n\\nLLM\\n사람으로 치면 두뇌다. 텍스트를 처리하고 의사결정을 한다.\\n\\nPlanning\\nAI Agent는 복잡한 objective를 작은 task로 나눌 줄 아는 능력이 중요하다.\\n이는 planning module을 통해 수행되며, 다음과 같은 동작들을 수행한다\\n주어진 objective 분석\\n목표 달성 위해 필요한 단계 파악\\n단계들의 우선 순위 선정\\n새 정보들이 들어오면 계획을 수정하기\\n\\n\\nAction\\nAi agent가 task를 수행하기 위해 tool과 interact하는 component.\\n웹 검색, 코드 실행, DB 접근, API 사용, 다른 SW와 interact 등\\n이런 tool들을 얼마나 잘 쓰는지가 AI agent가 얼마나 넓은 범위의 작업을 할 수 있는지를 결정한다.\\ntool의 사용으로 generative execution에서 deterministic execution으로 바뀌기 때문\\nllm이 생성하는 단순 언어적 응답이 아닌 tool을 사용한 구체적인 출력으로 인해 정확하고 신뢰성 있는 응답, 확장성과 유연성\\n\\n\\nProfile\\nAI Agent의 행동, 성격, 기능을 정의한다. chat_template에서 role system과 비슷한 역할\\nAgent의 전문 분야, tone & communication style 등\\n\\n\\nMemory\\nMemory를 통해 agent는 과거 정보를 저장하고 불러오는 것은 아래 상황에서 중요함:\\n진행 중인 대화에서 context 유지하기\\n과거 경험으로부터 학습하기\\n점진적으로 성능을 향상시킴\\nuser history에 따라 personalized된 응답 제공\\n\\n\\n\\nMulti-Agent System(MAS)\\n\\nMulti-Agent System은 앞서 말했듯 여러 에이전트가 결합된 하나의 시스템으로, 한 분야에 특화된 에이전트가 각 역할을 맡아 양질의 출력을 낸다.\\nMAS에도 Reflection, Tool Use, Planning이 당연히 사용된다.\\n\\nAI Agent Detailed\\n\\nAgentic pattern은 AI agent들이 어떻게 동작하고 interact 하는지 가이드하는 프레임워크다. 최근 연구에서 확인된 주요 패턴은 다음과 같다.\\nReflection\\nTool Use\\nPlanning\\nMulti-Agent Collaboration\\n\\n\\n\\nReflection\\n\\n\\n\\n이 글에서 reflection은 반성, 반영 정도로 해석가능할 것 같다.\\n\\n\\nReflection은 AI Agent가 자신의 출력을 분석하고 평가하는 능력을 의미한다.\\n\\n\\nAgent의 출력을 스스로 평가하여 개선을 위한 피드백을 제공할 수 있다.\\n  1-1. MAS에서의 Reflection\\n\\nMAS에서 reflection은 두 에이전트가 서로 피드백을 주고 받는 방식으로 구현할 수 있다.\\nA 에이전트는 high quality의 output을 생성하도록 prompt를 받고,\\nB 에이전트는 A 에이전트의 output을 critic하게 평가하고 constructive한 피드백을 준다.\\n\\n이런 방식으로 더욱 개선된 response가 생성될 수 있다.\\n\\n\\n\\n\\nTool Use\\n\\n\\nLLM의 사전 학습된 지식만으로는 출력을 생성하는 데 한계가 있다는 것을 깨닫게 되었다..\\nAgent는 아래와 예시와 같은 tool들을 사용해 역량을 확장한다\\nWeb Search: Agent가 Web Search와 결합되면 학습 데이터 범위를 넘어선 정보를 얻을 수 있으며, 이를 통해 knowledge base를 크게 확장한다.\\nCode Execution: 단순히 코드를 추론하는데 그치지 않고, 코드를 작성한 뒤 실행해보며 출력물을 실제로 testing & application 해볼 수 있다.\\nPython을 실행하는 것도 tool use이다.\\n\\nLLM이 {tool: web-search, query: \"coffee maker reviews\"}같은 문자열을 생성하도록 fine tuning되거나, few shot 프롬프팅을 사용한다.\\n이후 post processing에서 문자열을 검색해 tool을 호출해 그 결과를 다시 llm에 전달한다.\\n\\n\\n\\nPlanning(+Reasoning)\\n\\n\\nPlanning과 Reasoning을 함께 묶어서 LLM이 어떤 행동을 취할지 생각하는 능력이라고 보는 경우도 있다.\\nLLM은 복잡한 task를 다루기 위해 task를 manageable한 step들로 나누는 능력을 갖고 있다.\\n이는 agent가 목표를 달성하기 위해 필요한 행동들의 순서를 고려한뒤 체계적으로 문제를 해결할 수 있게 한다.\\nPlanning을 이해하기 위해, HuggingGPT 논문에서의 예시를 단순화해보면 아래와 같다.\\n“소년의 사진을 보고, 동일한 자세를 취한 소녀의 그림을 그려줘”라고 요청할 경우, task는 두 단계로 나뉜다.\\n소년 사진에서 pose detect\\ndetected pose를 기반으로 소녀의 그림을 랜더링\\n\\nLLM은 {tool: pose-detection, input: image.jpg, output: temp1 } 과 같은 구조화된 문자열을 생성하도록 fine tuning되거나, few shot 프롬프팅으로 plan을 설정할 수 있는 것이다.\\n\\nPlanning은 언제 필요할까?\\nplanning이 항상 필요하진 않다. 고정된 횟수만큼의 reflection을 통해 생성물을 개선하면 이 agent는 fixed하며 deterministic하다.\\n그러나 task를 사전에 단계별로 쪼갤 수 없는 경우에는, planning을 통해 agent가 동적으로 단계별 실행을 결정할 수 있다.\\n\\nPlanning은 복잡한 작업을 agent가 독립적으로 적절하게 나누어 수행한다는 장점이 있지만, 그 step과 최종 output에 대한 예측 가능성이 떨어진다는 단점이 있다.\\n복잡한 작업을 잘 planning & reasoning하여 수행하는 것은 쉽지 않은데, 왜냐하면\\nLLM으로 하여금 큰 그림을 본 다음에 다시 단기적인 action을 하도록 해야 하고, \\nagent가 많은 작업을 하면 할수록 그 결과들이 llm에 피드백되므로 context window가 커지고, 결국 모델은 ‘distracted(산만해짐)’되어 성능이 낮아질 수 있다.\\n\\nPlanning의 성능을 개선하기 위한 가장 낮은 단계의 해결책은 plan과 reason을 위한 모든 정보를 확보하는 것이다.\\n종종 prompt에는 정보가 충분하지 않은 경우가 많다.\\n\\n또한 retrieval step을 추가하거나 prompt instruction을 명확히 하면 성능이 개선될 수 있다.\\n이후에는 애플리케이션의 cognitive architecture를 변경해보는 것이 좋다.\\ncognitive architecture: 애플리케이션이 추론하는 데 사용하는 data engineering logic\\ngereral cognitive arch.(AlphaCodium 등) 와 domain specific cognitive arch. (커스텀 구현) 로 나뉜다.\\n\\n\\n\\nMulti-Agent Collaboration\\n\\n\\n\\n하나에 특화된 agent들이 여러 개 모여서 Multi-Agent System(MAS)를 이룰 수 있다.\\n일반적인 개발 회사에서와 같이 기획, 디자인, 개발, QA 등의 전문적인 역할을 나누어 수행할 수 있다고 볼 수 있다.\\nMAS는 하나 혹은 여러 LLM을 프롬프트하여 서로 다른 task를 수행하도록 설정함으로써 구현할 수 있다.\\nEX) 당신은 명확하고 효율적인 코드를 작성하는 전문가입니다. 다음 작업을 수행하기 위한 코드를 작성하세요. …\\n\\n한 LLM을 여러번 호출하면서도 여러 agent를 사용하는 programming abstraction을 적용하는 것은 직관에 반대되는 것처럼 보일 수도 있다. 하지만 이런 방식에는 몇가지 이유가 있다.\\n먼저 결과가 좋다(ㅋㅋㅋ).\\n좋은 성능이 실제로 가장 설득력 있는 이유가 된다. AutoGen 논문 등에서 수행한 ablation study에서도 multiple agents가 single agent보다 뛰어난 성능을 보이는 것을 나타낸다.\\n\\nLLM의 input context limitation을 보완한다.\\n일부 최신 LLM은 100만 토큰의 긴 input context를 지원하지만, 길면서도 complex한 input을 truly understand하는 능력은 제한적이다.\\n한 번에 하나의 세부 작업에 집중하도록 LLM을 프롬프트하는 agent workflow는 더 좋은 성능을 제공한다.\\n\\n복잡한 작업을 잘 나눌 수 있게 한다.\\nMAS가 복잡한 task를 세부 작업으로 분해하는 기능은 단일 CPU에서 프로그램을 실행할 때 여러 프로세스나 스레드로 나누는 방식과 유사하다.\\n\\n\\nMAS는 AutoGen, CrewAI, LangGraph 등의 프레임워크로 구현가능하다.\\nMAS는 planning과 마찬가지로 output의 quality를 미리 예측하기 어렵다.\\n\\nPaper:\\nReflection\\n\\n“Self-Refine: Iterative Refinement with Self-Feedback,” Madaan et al. (2023)\\n“Reflexion: Language Agents with Verbal Reinforcement Learning,” Shinn et al. (2023)\\n“CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing,” Gou et al. (2024)\\n\\nTool Use\\n\\n“Gorilla: Large Language Model Connected with Massive APIs,” Patil et al. (2023)\\n“MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,” Yang et al. (2023)\\n“Efficient Tool Use with Chain-of-Abstraction Reasoning,” Gao et al. (2024)\\n\\nPlanning\\n\\n“Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,” Wei et al. (2022)\\n“HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face,” Shen et al. (2023)\\n“Understanding the planning of LLM agents: A survey,” by Huang et al. (2024)\\n\\nMulti-Agent Collaboration\\n\\n“Communicative Agents for Software Development,” Qian et al. (2023) (the ChatDev paper)\\n“AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,” Wu et al. (2023)\\n“MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework,” Hong et al. (2023)\\n\\n출처:\\n\\nMastering AI Agents: From Basics to Multi-Agent Systems\\nAgentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\\nAgentic Design Patterns Part 2, Reflection\\nAgentic Design Patterns Part 3, Tool Use\\nAgentic Design Patterns Part 4, Planning\\nAgentic Design Patterns Part 5, Multi-Agent Collaboration\\nWhat is an AI agent?\\nPlanning for Agents\\ntu11pAnyone can be anything ... with agent!팔로우이전 포스트[Survey] RAG(Retrieval Augmented Generation) 핵심 개념0개의 댓글댓글 작성'),\n",
              "  Document(metadata={'source': 'https://tech.ktcloud.com/entry/2025-03-ktcloud-ai-agent-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8-%ED%98%91%EC%97%85%EC%8B%9C%EC%8A%A4%ED%85%9C', 'title': '[Tech Series] kt cloud AI 에이전트 #4 : 에이전트의 협업 시스템 — kt cloud [Tech blog]', 'description': '[kt cloud 마케팅커뮤니케이션팀 김지웅 님 ] Intro안녕하세요, kt cloud 마케터 김지웅 입니다. 🙋\\u200d♂️“혼자 가면 빨리 가지만, 함께 가면 더 멀리 간다”는 말처럼, AI 기술도 이제 ‘협업’의 시대로 접어들고 있어요. 과거에는 하나의 AI가 독립적으로 작동하며 주어진 작업만 수행했다면, 이제는 여러 AI 에이전트들이 팀처럼 협력하며 더 복잡하고 다양한 문제를 해결하고 있죠. ✨ 예를 들어, 한 AI는 전략을 수립하고, 다른 AI는 실행을 맡고, 또 다른 AI는 결과를 분석해요. 마치 기업에서 기획팀, 운영팀, 분석팀이 각자 역할을 나누어 일하는 것처럼요. 이러한 협업 구조는 자율주행, 스마트 시티, 금융 트레이딩 같은 복잡한 환경에서 효율성과 정확성을 동시에 달성하는 데 꼭 필요한 ..', 'language': 'ko'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #4 : 에이전트의 협업 시스템 — kt cloud [Tech blog]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n홈\\nkt cloud Story\\nTech Story\\nNews\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTech Story/Tech Inside\\n[Tech Series] kt cloud AI 에이전트 #4 : 에이전트의 협업 시스템\\n\\nkt cloud 테크블로그\\n2025. 3. 26. 10:17\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xa0[kt cloud 마케팅커뮤니케이션팀 김지웅 님 ]\\xa0\\nIntro\\n안녕하세요, kt cloud 마케터 김지웅 입니다. 🙋\\u200d♂️\\n“혼자 가면 빨리 가지만, 함께 가면 더 멀리 간다”는 말처럼, AI 기술도 이제 ‘협업’의 시대로 접어들고 있어요. 과거에는 하나의 AI가 독립적으로 작동하며 주어진 작업만 수행했다면, 이제는 여러 AI 에이전트들이 팀처럼 협력하며 더 복잡하고 다양한 문제를 해결하고 있죠. ✨\\n\\xa0\\n예를 들어, 한 AI는 전략을 수립하고, 다른 AI는 실행을 맡고, 또 다른 AI는 결과를 분석해요. 마치 기업에서 기획팀, 운영팀, 분석팀이 각자 역할을 나누어 일하는 것처럼요. 이러한 협업 구조는 자율주행, 스마트 시티, 금융 트레이딩 같은 복잡한 환경에서 효율성과 정확성을 동시에 달성하는 데 꼭 필요한 조건이 되었어요.\\n\\xa0\\n그렇다면 AI 에이전트는 왜 '혼자'가 아니라 '함께'여야만 했을까요? 그리고 이 협업은 어떤 구조로 설계되고, 실제로 어떻게 작동하고 있을까요? 이번 글에서는 전통적인 다중 에이전트 시스템(MAS)부터 최근 주목받고 있는 LLM 기반 협업 구조까지, AI 협업 시스템의 흐름과 설계 전략을 하나씩 살펴보려고 해요. 최근에는 이런 구조를 설명할 때 ‘MALM(Multi-Agent with Large Models)’이라는 용어도 종종 사용되고 있어요. 이는 아직 공식 용어는 아니지만, 여러 에이전트가 LLM을 기반으로 역할을 나눠 협업하는 시스템을 가리키는 표현으로 점차 쓰임이 늘고 있답니다. 👥\\n\\xa0\\n이제 본격적으로 AI 협업의 세계로 들어가 볼까요? 🎯\\n\\nAI 협업 시스템이 주목받는 이유 🏗️\\n\\n\\nAI 에이전트가 혼자서 작업을 처리하던 시대는 이제 지나가고 있어요. 오늘날의 비즈니스 환경은 복잡해지고, 처리해야 할 데이터와 상황도 점점 다양해지고 있죠. 이런 환경에서는 하나의 에이전트가 모든 걸 책임지기보다, 여러 에이전트가 역할을 나누고 협력하는 구조가 훨씬 효과적이에요. 각 에이전트가 자신만의 기능을 수행하면서도 전체 목표를 위해 조화를 이루는, 마치 조직 내 여러 팀이 협력하는 방식과 비슷하죠.\\n\\xa0\\n그렇다면 AI 협업 구조는 실제로 어떤 장점을 갖고 있을까요?\\n🌟 AI 협업의 핵심 장점\\n🔄 복잡한 문제 해결을 위한 분업 가능서로 다른 AI가 전략 수립, 실행, 분석 등 전문적인 역할을 분담함으로써 더 빠르고 정확한 문제 해결이 가능해요.\\n\\xa0\\n💪 개별 에이전트의 한계 극복하나의 AI가 감당하기 어려운 연산이나 상황도 여러 에이전트가 나눠서 처리하며 성능의 한계를 넘어설 수 있어요. 이 과정에서 서로의 결과를 보완하며 시너지 효과도 만들어지죠.\\n\\xa0\\n🛡️ 시스템의 안정성과 신뢰성 향상하나의 에이전트가 실패하더라도 다른 에이전트가 백업을 수행하거나 보완할 수 있어요. 결과적으로 전체 시스템의 안정성과 신뢰도가 높아져요.\\n\\xa0\\n🔋 확장성과 유연성 확보필요에 따라 새로운 기능을 가진 에이전트를 추가하거나 기존 에이전트를 교체하는 것이 비교적 쉬워요. 환경 변화나 요구사항에 빠르게 대응할 수 있는 구조죠.\\n\\nMAS에서 LLM 기반의 다중 에이전트 시스템(MALM)으로: AI 협업의 진화 🔄\\n\\n\\nAI 협업의 기본, 다중 에이전트 시스템(Multi-Agent Systems, MAS)란? 👥\\n다중 에이전트 시스템(Multi-Agent System, MAS)은 여러 자율적인 에이전트들이 상호 작용하며 공동의 문제를 해결하거나 특정 목표를 달성하기 위해 협력하는 시스템이에요. 각 에이전트는 특정 역할이나 전문 분야를 담당하며, 서로 통신하고 조율하면서 문제를 해결해요. 🤝\\n✨ MAS의 주요 특징\\n\\n역할 기반 분업: 각 에이전트는 특정 역할이나 전문성을 가지고 있어요. 예를 들어 하나는 탐색, 다른 하나는 분석 같은 식으로 역할을 나눠요.\\n메시지 기반 통신: 에이전트 간에는 표준화된 메시지 프로토콜을 통해 정보를 주고받아요. 이를 통해 의사결정이나 협업 요청이 가능해져요.\\n조정 메커니즘: 충돌 방지, 자원 배분, 우선순위 조정을 위한 내부 규칙이나 협상 방식이 포함돼요.\\n\\n🛠️ MAS의 작동 방식\\nMAS는 보통 다음과 같은 흐름으로 작동해요.먼저, 복잡한 문제를 여러 개의 하위 작업으로 분해한 뒤, 각 작업을 적절한 에이전트에게 할당해요. 이후 에이전트들은 병렬적으로 작업을 수행하며, 중간 결과를 공유하고 조율하면서 전체 결과를 만들어내요. 이때 개별 에이전트의 능력보다 협업 구조 자체가 시스템의 효율성과 확장성을 좌우하게 돼요.\\n\\n작업 분해: 전체 문제를 여러 개의 하위 과제로 나눠요.\\n역할 할당: 각 에이전트가 자신에게 맞는 작업을 맡아요.\\n협업 실행: 동시에 또는 순차적으로 작업을 수행해요.\\n결과 통합: 각자의 결과를 모아 하나의 최종 결과를 도출해요.\\n\\n🔀 협업 방식의 두 가지 큰 흐름 : 중앙 집중형 vs 분산형\\n\\n\\n✅ 중앙 집중형 시스템 (Centralized MAS)\\n마치 PM이 프로젝트를 총괄하듯이, 하나의 메인 AI가 다른 AI들을 지휘해요. 효율적이지만, 메인 AI에 문제가 생기면 전체 시스템이 마비될 수 있죠. 😅\\n\\n중앙 컨트롤러(예: 클라우드 서버, 메인 AI)가 전체 시스템을 조율\\n\\n개별 AI 에이전트들은 수동적인 역할을 수행\\n장점: 빠른 의사 결정, 높은 통제력\\n단점: 중앙 서버 장애 발생 시 전체 시스템이 중단될 위험\\n\\n\\n\\n\\xa0\\n\\xa0\\n\\n\\n✅ 분산형 시스템 (Decentralized MAS)\\n각 AI가 자율적으로 움직이면서 서로 협력해요. 마이크로서비스 아키텍처와 비슷하다고 보면 됩니다! 유연하고 안정적이지만, 관리가 좀 더 복잡할 수 있어요. 🤣\\n\\n에이전트들이 자율적으로 판단하고 협력하여 목표를 달성\\n\\n시스템 내 개별 AI들이 독립적으로 데이터 처리 및 의사결정 수행\\n장점: 확장성이 뛰어나고, 특정 노드 장애에도 강건함\\n단점: 개별 에이전트 간 통신 비용 증가, 조율 어려움\\n\\n\\n\\n\\xa0\\n\\xa0\\n💡 MAS의 핵심 기술: 자연에서 배우는 AI 협업의 지혜\\nMAS(Multi-Agent Systems)는 여러 개의 AI 에이전트가 협력하여 복잡한 문제를 해결하는 시스템이에요. MAS가 효과적으로 작동하려면 AI들이 어떻게 협력할지, 어떻게 학습할지를 결정하는 핵심 기술이 필요해요.\\n대표적인 MAS 협업 기술로는 스웜 인텔리전스(Swarm Intelligence), 군집 지능(Collective Intelligence), 멀티 에이전트 강화학습(MARL) 등이 있어요!\\n🐝 스웜 인텔리전스 (Swarm Intelligence)\\n\\n\\n스웜 인텔리전스(Swarm Intelligence)는 개미나 벌처럼 단순한 개체들이 협력하여 복잡한 문제를 해결하는 방식이에요. 이 개념을 AI에 적용하면 여러 AI가 자율적으로 협력하여 최적의 해결책을 찾을 수 있어요.\\n\\xa0\\n💡 핵심 특징\\n\\n분산 문제 해결: 복잡한 문제를 작은 단위로 나누고, 여러 AI가 역할을 분담해 해결해요.\\n자기 조직화: 중앙에서 통제하지 않아도, AI들이 서로 협력해 자동으로 구조를 형성해요.\\n창발적 행동: 개별 AI는 단순한 규칙만 따르지만, 전체적으로는 예측할 수 없는 복잡한 패턴이 나타나요.\\n견고성: 일부 AI가 오류를 내도 시스템 전체는 계속 작동할 수 있어요.\\n\\n🌍 자연에서 배운 지혜 & AI 적용 사례\\n\\n🐜 개미 군집 행동 → 네트워크 최적화\\n\\n개미들이 가장 효율적인 먹이 경로를 찾듯이, 인터넷 패킷 전송 경로를 최적화하는 데 활용돼요.\\n적용 사례: 개미 군집 최적화(Ant Colony Optimization, ACO) 알고리즘\\n\\n\\n🍯 꿀벌의 의사결정 → 자율 분산 AI 협업\\n\\n꿀벌들이 새로운 둥지를 찾는 방식을 활용해, AI가 분산된 의사결정을 더 효율적으로 수행할 수 있도록 도와줘요.\\n적용 사례: 분산 AI 알고리즘에서 다중 경로 탐색\\n\\n\\n🦅 새 떼의 비행 → 군집 로봇 제어(Swarm Robotics)\\n\\n새 떼가 충돌하지 않고 협력해서 비행하는 원리를 이용해, 드론이나 자율 로봇이 협력해서 움직이는 기술이 개발됐어요.\\n적용 사례: 재난 구조용 드론 군집 비행 시스템\\n\\n\\n\\n🎮 강화학습 기반 협업 (Collaborative Reinforcement Learning)\\n스웜 인텔리전스가 자연의 규칙에서 출발한 협업 방식이라면, 최근에는 멀티 에이전트 강화학습(MARL, Multi-Agent Reinforcement Learning)이 그 자리를 빠르게 채우고 있어요. MARL은 여러 AI가 같은 환경에서 상호작용하면서 협력하거나 경쟁하며 스스로 전략을 학습하는 방식이에요. 멀티 에이전트 강화학습(MARL)은 협력적(Collaborative) 방식과 경쟁적(Competitive) 방식으로 나뉘어요.\\n\\xa0\\n1️⃣ 협력적 MARL (Collaborative MARL)\\n\\n여러 AI가 함께 목표를 달성하기 위해 협력하는 방식이에요.\\n\\n예제: 자율주행 차량 간 협력 (V2X 통신 기반)\\n예제: 산업용 로봇 협업 (공장에서 로봇들이 조립 과정에서 서로 협력하는 방식)\\n\\n\\n\\n2️⃣ 경쟁적 MARL (Competitive MARL)\\n\\n각 AI가 서로 경쟁하면서 최적의 전략을 학습하는 방식이에요.\\n\\n예제: 게임 AI (스타크래프트 AI - AlphaStar, OpenAI Five)\\n예제: 금융 AI (고빈도 매매 알고리즘 트레이딩)\\n\\n\\n\\nMARL은 단순한 학습을 넘어서 다음과 같은 특징을 갖고 있어요.\\n\\n경험 공유: 하나의 에이전트가 얻은 지식을 다른 에이전트와 공유해요.\\n협력적 보상: 팀 전체의 성공을 기준으로 보상을 주기 때문에 개별 성과보다 공동 목표에 집중해요.\\n적응형 학습: 환경 변화에 맞춰 스스로 전략을 바꾸고 진화할 수 있어요.\\n\\n\\n\\n\\n🌟 MAS의 확장: Multi-Agent with Large Models (MALM)\\n최근에는 GPT 같은 대형 언어 모델(LLM)을 기반으로 한 새로운 협업 구조가 주목받고 있어요. 기존 MAS처럼 여러 에이전트가 함께 일하는 구조지만, 이제는 각 에이전트가 LLM의 유연한 언어 처리 능력을 활용해 훨씬 더 유연하고 똑똑하게 협력할 수 있죠. 기술 커뮤니티에서는 이를 MALM(Multi-Agent with Large Models)이라는 표현으로 부르기도 해요. 아직 공식 용어는 아니지만, LLM 기반 다중 에이전트 시스템을 간단히 설명하는 개념으로 점점 더 널리 쓰이고 있어요.\\n기존 MAS는 보통 정해진 규칙과 제한된 의사결정 범위 내에서 움직였어요. 반면, MALM은 자연어로 상황을 이해하고 유연하게 대응하며, 때로는 역할도 동적으로 나누는 구조를 갖고 있어요. 특히 자연어 기반 상호작용이 가능하다는 점에서, 인간과의 협업은 물론, AI들 간의 협업에도 큰 전환점을 만들고 있어요.\\n🤔 MAS vs MALM: 무엇이 다를까?\\n기존 MAS는 특정한 규칙을 따르는 에이전트들이 협력하는 방식이었는데, MALM은 LLM을 활용해서 AI가 더 유연하게 협력할 수 있도록 만든 시스템이에요.\\n\\n\\n\\n\\n\\n\\n전통적\\xa0MAS의\\xa0특징\\nMALM의 혁신적 특징\\n\\n\\n\\n\\n규칙 기반의 의사결정\\n미리 정의된 행동 패턴\\n제한된 적응성\\n개별 에이전트의 독립적 판단\\n\\n\\n\\n\\n언어 모델 기반의 유연한 의사결정\\n상황 맥락 이해 및 적응\\n자연어 기반 상호작용\\n동적인 역할 분담과 협업\\n\\n\\n\\n\\n\\n😎 최근 연구 동향\\n최근 연구에서는 LLM 기반 AI 에이전트들이 협력하여 문제를 해결하는 사례가 늘어나고 있어요.\\n\\n디지털 환경 시뮬레이션 🏙️: 다중 AI 에이전트가 가상의 소도시에서 상호작용하며 복잡한 환경을 생성해요\\n역할 기반 협업 👨\\u200d🏫👩\\u200d🎓: 한 에이전트가 학생 역할을, 다른 에이전트가 교사 역할을 맡아 교육적 문제를 해결해요\\nMicrosoft AutoGen 🤖🔄: 여러 개의 LLM 기반 에이전트가 상호작용하도록 설계된 프레임워크로, 복잡한 작업을 여러 전문 에이전트가 나누어 처리해요\\n\\n\\nAI 협업 시스템의 새로운 흐름: 하이브리드(Hybrid) 접근 방식 🤝\\n지금까지 살펴본 MAS(Multi-Agent System)와 MALM(Multi-Agent with Large Models)처럼, 분산된 AI 에이전트들이 각자의 역할을 수행하면서 협력하는 구조들이 발전해 왔어요. 하지만 실제 환경은 그렇게 단순하지 않아요. 완전히 중앙 집중형이거나, 완전히 분산형인 시스템은 현실적인 한계가 명확해요. 그래서 최근에는 이 두 방식을 조합한 하이브리드 협업 구조가 점점 더 주목받고 있어요.\\n\\n\\n이러한 하이브리드 접근 방식이 필요한 이유는 다양해요. 대규모 연산 효율, 실시간 응답 속도, 신뢰성과 정밀도의 균형, 텍스트·이미지·음성 등 멀티모달 데이터 처리, 검색 기반 정보 활용과 생성형 응답 결합, 그리고 클라우드와 엣지 AI 간의 협업처럼 복합적인 요구들이 동시에 존재하거든요. 단일한 방식으로는 이 모든 요소를 만족시키기 어렵기 때문에, 기능과 구조의 융합이 중요해지고 있어요.\\n\\xa0\\n그럼 대표적인 하이브리드 방식들을 하나씩 살펴볼게요.\\n🧠 외부 지식과 시스템을 활용한 LLM 보완 방식\\n대형 언어 모델(LLM)은 뛰어난 언어 생성 능력을 가지고 있지만, 최신 정보 반영, 논리적 추론, 결과 해석 가능성 같은 측면에서는 여전히 한계를 갖고 있어요. 그래서 최근에는 LLM을 외부 지식이나 시스템과 연결해 보완하는 구조가 AI 협업 시스템에서 핵심 요소로 주목받고 있어요.\\n\\xa0\\n대표적인 방식이 신경기호 AI(Neuro-Symbolic AI)와 RAG(Retrieval-Augmented Generation)이에요. 신경기호 AI는 지식 그래프, 규칙 기반 시스템 등과 연결해 생성 결과의 신뢰성과 해석 가능성을 높이고, 최근에는 Stanford의 Graph-RAG처럼 symbolic 구조와 검색 기반 응답 생성 방식을 결합하거나, MIT의 SymbL, OpenAI의 Autoformalization 프로젝트처럼 LLM의 출력을 수학적 또는 논리적 구조로 해석하고 검증하는 방식이 활발히 연구되고 있어요. 이런 흐름은 단순한 응답 생성에서 벗어나, LLM이 ‘왜 그런 결론을 내렸는지’를 설명 가능하게 만드는 방향으로 확장되고 있죠.\\n\\xa0\\n한편, RAG는 외부 문서나 데이터베이스에서 관련 정보를 검색해와, LLM이 그 정보를 바탕으로 응답을 생성하는 구조예요. 단순한 문서 검색을 넘어서, 최근에는 ReAct-RAG, Fusion-in-Decoder, Multi-hop RAG, AgentRAG 같은 구조들이 등장하며 reasoning, 도구 사용, 협업까지 결합하고 있어요. 이 과정에서 LangChain, LlamaIndex, Haystack 같은 프레임워크들이 다양한 구현 방식과 최적화를 지원하고 있죠.\\n\\xa0\\n결과적으로 LLM은 이제 더 이상 혼자 일하지 않아요. 정확성, 신뢰성, 최신성이라는 과제를 해결하기 위해, 외부의 정보 시스템이나 도구들과 협력하는 구조가 점점 더 정교해지고 있어요. 이런 통합적 설계는 단순한 생성형 AI를 넘어, 실제 업무를 수행할 수 있는 실행 가능한 AI 에이전트로의 진화를 가능하게 만들어주고 있어요.\\n🧩 멀티모달 AI 모델의 협업\\nAI 시스템이 외부 지식이나 정보와 협력하는 구조가 발전하고 있는 동시에, 입력되는 데이터 자체도 텍스트뿐 아니라 이미지, 음성, 영상 등으로 다양해지고 있어요. 그 결과 서로 다른 종류의 AI 모델들이 함께 협력하는 멀티모달 협업 구조 역시 중요성이 커지고 있죠.\\n\\xa0\\n텍스트, 이미지, 음성 등 다양한 데이터를 함께 처리하려면, 각기 다른 AI 모델들이 역할을 나누고 협력해야 해요. 과거에는 음성 인식, 이미지 분류, 텍스트 요약 같은 기능이 별도의 시스템에서 개별적으로 작동했지만, 이제는 하나의 워크플로우 안에서 멀티모달 모델들이 자연스럽게 연결되는 구조가 일반화되고 있어요.\\n\\xa0\\n예를 들어, GPT-4V는 시각 정보와 언어 정보를 동시에 이해하고, OpenAI의 CLIP은 이미지와 텍스트 사이의 의미를 연결해 검색과 분류를 도와주며, DALL·E는 텍스트 설명을 바탕으로 이미지를 생성할 수 있어요. 최근에는 Google의 Gemini나 Meta의 MM1처럼 멀티모달 reasoning에 최적화된 모델들이 등장하면서, 텍스트, 이미지, 음성뿐 아니라 영상까지 동시에 처리하는 기술로 확장되고 있어요.\\n\\xa0\\n이런 모델들이 함께 작동할 때는, ‘누가 언제 어떤 방식으로 개입할 것인가’를 설계하고 조율하는 에이전트 기반 오케스트레이션 구조가 중요해져요. 단순히 데이터를 넘기는 것이 아니라, 모델 간 협업 흐름을 설계하는 일이 핵심이 되는 거죠. 예를 들어, 시각 정보를 해석한 결과를 텍스트 생성 모델로 넘기거나, 음성 인식 모델과 자연어 이해 모델이 함께 작동하도록 연결하는 식이에요.\\n\\xa0\\n이처럼 AI 협업 시스템은 점점 더 정교해지고 있고, 단일한 모델이나 단순한 구조만으로는 원하는 수준의 정밀도와 유연성을 확보하기 어려워지고 있어요. 결국 중요한 건 목적에 따라 적절한 기술들을 조합하고, 그 안에서 에이전트 간의 역할과 협력이 어떻게 설계되느냐예요. 그리고 이러한 구조를 안정적으로 뒷받침해주는 클라우드 인프라 역시 점점 더 중요해지고 있어요.\\n\\n4부 마무리: AI 에이전트 협업 시스템, 미래를 여는 열쇠 ✨\\n지금까지 우리는 AI 에이전트들이 어떻게 협력하며, 복잡한 문제를 함께 해결해 나가는지를 살펴봤어요. 전통적인 다중 에이전트 시스템(MAS)부터 시작해, LLM 기반의 협업 시스템, 그리고 중앙 집중형과 분산형을 융합한 하이브리드 아키텍처까지 AI 협업의 흐름은 점점 더 정교하고 유연한 방향으로 진화하고 있죠.\\n\\xa0\\n이러한 협업 구조는 단순한 기술 발전을 넘어서, 실제 업무 수행을 위한 전략이 되고 있어요. 어떤 에이전트는 계획을 수립하고, 다른 에이전트는 실행을 맡으며, 또 다른 에이전트는 외부 지식이나 실시간 데이터를 활용해 판단을 보완하죠. 그리고 이 모든 흐름의 중심에는 ‘함께 작동하도록 설계된 구조’가 자리하고 있어요.\\n\\xa0\\n이번 시리즈를 통해 우리는 AI 에이전트의 전반적인 개념을 체계적으로 이해할 수 있었어요. 1부에서는 AI 에이전트의 기본 개념과 핵심 구성 요소를, 2부에서는 다양한 유형과 그 특성을, 3부에서는 실제 비즈니스에서의 활용 패턴과 아키텍처를, 4부에서는 여러 에이전트가 협업하는 시스템 구조를 깊이 있게 살펴봤죠.\\n\\xa0\\n이제는 단일 모델의 한계를 넘어, 여러 에이전트가 유기적으로 협력하는 지능형 생태계로 AI가 진화하고 있음을 이해할 수 있게 되었을 거예요. 여러분도 시리즈를 읽으며 느끼셨겠지만, 이런 복잡하고 정교한 협업 시스템이 원활히 작동하려면 그 기반이 매우 중요해요. 특히 여러 에이전트가 실시간으로 협업하고, 방대한 데이터를 주고받으며, 지속적으로 학습해야 하는 구조에서는 강력한 클라우드 인프라가 필수예요.\\n\\xa0\\nAI 에이전트 시스템의 성공은 결국 그 위에 구축된 기술 기반의 품질에 크게 좌우돼요. 고성능 연산, 확장성 있는 구조, 유연한 자원 할당, 안정적인 연결성. 이 모든 요소를 충족시킬 수 있는 인프라 환경에서만 에이전트는 그 가능성을 온전히 펼칠 수 있어요. 특히 클라우드 환경은 AI 시스템의 진화 속도를 따라갈 수 있는 유일한 기술 기반이기도 해요. ☁️\\n\\xa0\\n여러분의 비즈니스에는 어떤 AI 에이전트 협업 시스템이 가치를 창출할 수 있을까요? AI 기술의 발전과 함께하는 여정에 kt cloud가 함께할게요! 🌟\\n\\xa0\\n감사합니다! 🙏\\n\\n [관련/출처] \\n\\n\\n\\nhttps://velog.io/@dutch-tulip/ai-agent https://langfuse.com/blog/2024-07-ai-agent-observability-with-langfuse https://www.teachfloor.com/blog/ai-agents-in-education https://www.microsoft.com/en-us/research/publication/autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation-framework/ https://www.mdpi.com/2076-3417/10/21/7552 https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-simulation/ https://www.datacamp.com/tutorial/swarm-intelligence https://www.linkedin.com/pulse/harnessing-ai-swarm-intelligence-combat-wildfires-sarvex-jatasra/ https://tilnote.io/pages/642ce7f346b81350e02b47b4 https://www.superannotate.com/blog/multi-agent-llms https://microsoft.github.io/graphrag/ \\n\\n\\n\\n\\n\\n\\n\\n공유하기\\n\\n게시글 관리\\n\\n\\nkt cloud [Tech blog]\\n\\n\\n저작자표시 비영리 변경금지\\n\\n(새창열림)\\n\\n\\n \\n\\n\\n\\n'Tech Story > Tech Inside' 카테고리의 다른 글\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #3 : 에이전트의 활용 패턴과 아키텍처\\xa0\\xa0(0)\\n2025.03.25\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성\\xa0\\xa0(0)\\n2025.03.24\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #1 : 에이전트의 이해와 구성 요소\\xa0\\xa0(5)\\n2025.03.11\\n\\n\\n기업은 AX기술을 어떻게 도입하면 될까요? 기업들의 AX기술 도입 전략 소개\\xa0\\xa0(6)\\n2024.11.18\\n\\n\\n데이터센터에 활용되는 산업용 배터리의 특징과 강화되는 규제에 따른 대응\\xa0\\xa0(3)\\n2024.11.13\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTag\\nai에이전트, ai협업시스템, KTCloud, llm기반ai, Rag, 다중에이전트, 멀티모달Ai, 지능형오케스트레이션, 클라우드인프라, 하이브리드ai\\n\\n\\n\\n'Tech Story/Tech Inside'의 다른글\\n\\n\\n이전글[Tech Series] kt cloud AI 에이전트 #3 : 에이전트의 활용 패턴과 아키텍처\\n\\n현재글[Tech Series] kt cloud AI 에이전트 #4 : 에이전트의 협업 시스템\\n\\n\\n\\n\\n\\n\\n관련글\\n\\n\\n\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #3 : 에이전트의 활용 패턴과 아키텍처\\n2025.03.25\\n\\n\\n\\n\\n\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #2 : 에이전트의 유형과 특성\\n2025.03.24\\n\\n\\n\\n\\n\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #1 : 에이전트의 이해와 구성 요소\\n2025.03.11\\n\\n\\n\\n\\n\\n\\n\\n기업은 AX기술을 어떻게 도입하면 될까요? 기업들의 AX기술 도입 전략 소개\\n2024.11.18\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nkt cloud [Tech blog]\\nTech Innovation, With Customer!\\n\\n\\nkt cloud [Tech blog]구독하기\\n\\n\\n글쓰기\\n블로그 관리\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n 분류 전체보기 (259) \\n Tech Story (134) \\n Tech Inside (8) \\n Data Center & Security (12) \\n Cloud Architecture (58) \\n AI Cloud (10) \\n DevOps & Container (41) \\n etc. (5) \\n\\n\\n kt cloud Story (42) \\n Tech Events (1) \\n Team Culture (1) \\n Service Updates (2) \\n Newsletter (24) \\n Webinar (13) \\n Customer Spotlight (1) \\n\\n\\n News (82) \\n Press Release (77) \\n Promotion (4) \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTag\\n\\nKubernetes,\\nDR,\\nNPU,\\nsaas,\\nIDC,\\nKT클라우드,\\ngpu,\\n케이티클라우드,\\n데이터센터,\\n리벨리온,\\nAI,\\n쿠버네티스,\\ncontainer,\\ncloud,\\n컨테이너,\\n클라우드,\\nKTCloud,\\nCSAP,\\nKT Cloud,\\nDaaS,\\n\\n\\n\\n\\n최근글과 인기글\\n\\n최근글\\n인기글\\n\\n\\n\\n\\n\\n\\n[트렌드 리포트] “쿠버네티스, 써보니 어땠나요?” – 실무자들이 직접 밝힌 운영 현실\\n2025.05.21 09:31\\n\\n\\n\\n\\n\\n\\n\\n[웨비나 후기] 쿠버네티스 A to Z 웨비나\\n2025.05.20 11:38\\n\\n\\n\\n\\n\\n\\n\\n[기술가이드] Kubernetes 환경에서 App of Apps로 구현하는 GitOps 실⋯\\n2025.05.15 19:09\\n\\n\\n\\n\\n\\n\\n\\n케클s피드 4월호｜진화하는 기술 환경 속, 지금 주목할 이야기\\n2025.05.12 09:15\\n\\n\\n\\n\\n\\n\\n\\n[News Digest] kt cloud, 알테어와 산업 맞춤형 클라우드 솔루션 제공을 위⋯\\n2025.05.08 15:05\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Tech Series] kt cloud AI 에이전트 #1 : 에이전트의 이해와 구성 요⋯\\n2025.03.11 18:19\\n\\n\\n\\n\\n\\n\\n\\nDNS 네임 서버를 직접 구축해보자! (feat. BIND9)\\n2021.09.06 09:06\\n\\n\\n\\n\\n\\n\\n\\n[기술리포트] AI 시대 데이터센터의 게임체인저, 액침냉각 기술의 모든 것 - kt clo⋯\\n2025.02.06 17:21\\n\\n\\n\\n\\n\\n\\n\\ngRPC의 내부 구조 파헤치기: HTTP/2, Protobuf 그리고 스트리밍\\n2024.10.29 09:33\\n\\n\\n\\n\\n\\n\\n\\nGPU 1,000장 모니터링 하기: NVIDIA DCGM 활용 전략\\n2024.11.07 15:00\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n블로그 내 검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n기업 홈페이지\\nCloud 홈\\nDater Center 홈\\n\\n\\n주식회사 케이티클라우드\\n\\n\\n\\n관련사이트\\n\\n기업 홈페이지\\nCloud 홈\\nG-Cloud 홈\\nDater Center 홈\\nYouTube\\n\\n\\n\\n\\n\\n\\n\\n\\n티스토리툴바\\nkt cloud [Tech blog]구독하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")]}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# API 키와 사용자 에이전트 설정 (환경 변수에 저장)\n",
        "# os.environ['TAVILY_API_KEY'] = \n",
        "os.environ['USER_AGENT'] = 'MyAgent'\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "def tavily_search(State):\n",
        "    # Tavily 검색 도구 객체 생성 (검색 결과 최대 5개)\n",
        "    tavily_search = TavilySearchResults(max_results=5)\n",
        "\n",
        "    # 검색 실행 (State 딕셔너리의 'query' 키에 있는 검색어 사용)\n",
        "    search_results = tavily_search.invoke({'query': State['query']})\n",
        "    # 반환값: {'url': ..., 'content': ...} 형식의 딕셔너리 리스트\n",
        "\n",
        "    # PDF 파일은 제외하고 URL만 추출\n",
        "    urls = [result['url'] for result in search_results if 'pdf' not in result['url']]\n",
        "\n",
        "    # 웹 페이지 로더 생성\n",
        "    # (SSL 인증 문제를 방지하기 위해 예외 처리 추가)\n",
        "    try:\n",
        "        loader = WebBaseLoader(urls)\n",
        "    except:\n",
        "        loader = WebBaseLoader(urls, requests_kwargs={'verify': False})\n",
        "\n",
        "    # 문서 로드 (각 URL에서 텍스트 데이터 수집)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # 수집된 문서를 context로 반환\n",
        "    return {'context': documents}\n",
        "\n",
        "# 함수 테스트 실행 (예: '멀티 에이전트 구조' 검색)\n",
        "result = tavily_search({'query': '멀티 에이전트 구조'})\n",
        "result  # 결과 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2BswHqhrDMh"
      },
      "outputs": [],
      "source": [
        "def get_query(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "         ('user','''{question}에 답변하기 위해\n",
        "인터넷 검색을 사용하려고 합니다.\n",
        "적절한 검색어 쿼리를 하나만 출력하세요.\n",
        "쿼리만 출력하세요.''')\n",
        "    ])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"query\": chain.invoke(State)}\n",
        "    # State를 모두 입력해도, Prompt Template에 포함된 입력변수만 전달\n",
        "\n",
        "\n",
        "def answer_question(State):\n",
        "    prompt = ChatPromptTemplate([\n",
        "        ('system', '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 답변하세요.\n",
        "정확한 답변을 제공하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
        "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.'''),\n",
        "\n",
        "        ('user', '''Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "    return {\"answer\": chain.invoke(State)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scIrzxLMrDMi"
      },
      "source": [
        "State를 만들고, 그래프를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUzOx5WrrDMi"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    question : str # 유저의 질문\n",
        "    query: str # 질문에서 파생된 검색어\n",
        "    answer: str # 답변\n",
        "    context: str # 검색 결과\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-taG6FMMrDMi",
        "outputId": "8fddc1c0-142d-4ae4-fb90-f05aed35d7b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79a9281cfe50>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 그래프 구성\n",
        "builder = StateGraph(State)\n",
        "\n",
        "builder.add_node(\"get_query\", get_query)\n",
        "builder.add_node(\"tavily_search\", tavily_search)\n",
        "builder.add_node(\"answer_question\", answer_question)\n",
        "\n",
        "builder.add_edge(START, \"get_query\")\n",
        "builder.add_edge(\"get_query\", \"tavily_search\")\n",
        "builder.add_edge(\"tavily_search\", \"answer_question\")\n",
        "builder.add_edge(\"answer_question\", END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "xUUJS6x9rDMi",
        "outputId": "c8dffe96-a144-4abf-dc1b-d86e9a22431b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x79a9281e1a90>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u2IrFvkrDMi",
        "outputId": "e031f986-4c88-4876-beca-23fa142037a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': '',\n",
              " 'query': '메타버스 뜻',\n",
              " 'answer': '메타버스의 의미는 무엇인가요?',\n",
              " 'context': [Document(metadata={'source': 'https://ko.wikipedia.org/wiki/%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4', 'title': '메타버스 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='\\n\\n\\n\\n메타버스 - 위키백과, 우리 모두의 백과사전\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n본문으로 이동\\n\\n\\n\\n\\n\\n\\n\\n주 메뉴\\n\\n\\n\\n\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로\\n\\n\\n\\n\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\n\\n\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n기부\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n\\n\\n\\n\\n\\n\\n개인 도구\\n\\n\\n\\n\\n\\n기부 계정 만들기 로그인\\n\\n\\n\\n\\n\\n\\t\\t로그아웃한 편집자를 위한 문서 더 알아보기\\n\\n\\n\\n기여토론\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n처음 위치\\n\\n\\n\\n\\n\\n1\\n정의\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\n유래\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\n메타버스의 네 가지 유형\\n\\n\\n\\n\\n메타버스의 네 가지 유형 하위섹션 토글하기\\n\\n\\n\\n\\n\\n3.1\\n증강현실(Augmented Reality)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\n일상기록(Lifelogging)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\n거울세계(Mirror Worlds)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\n가상세계(Virtual Worlds)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\n발전방향과 문제점\\n\\n\\n\\n\\n발전방향과 문제점 하위섹션 토글하기\\n\\n\\n\\n\\n\\n4.1\\n현황 및 발전방향\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2\\n문제점\\n\\n\\n\\n\\n\\n\\n4.2.1\\n메타버스 내의 불법행위와 사법권\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2.2\\n아바타의 인격권\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2.3\\n가상화폐의 현금화\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2.4\\n가상세계 과몰입\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\n같이 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\n각주\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n메타버스\\n\\n\\n\\n47개 언어\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaবাংলাCatalàکوردیČeštinaDeutschΕλληνικάEnglishEsperantoEspañolEuskaraفارسیSuomiFrançaisעבריתHrvatskiBahasa IndonesiaItaliano日本語JawaქართულიМакедонскиമലയാളംBahasa Melayuမြန်မာဘာသာNederlandsNorsk bokmålଓଡ଼ିଆPolskiPortuguêsRuna SimiRomânăРусскийSimple EnglishSlovenčinaShqipСрпски / srpskiไทยTürkçeئۇيغۇرچە / UyghurcheУкраїнськаاردوTiếng Việt中文粵語\\n\\n링크 편집\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n문서토론\\n\\n\\n\\n\\n\\n한국어\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\n\\n도구\\n\\n\\n\\n\\n\\n도구\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t동작\\n\\t\\n\\n\\n읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\t\\t일반\\n\\t\\n\\n\\n여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\\n\\n\\n\\n\\n\\n\\t\\t인쇄/내보내기\\n\\t\\n\\n\\n책 만들기PDF로 다운로드인쇄용 판\\n\\n\\n\\n\\n\\n\\t\\t다른 프로젝트\\n\\t\\n\\n\\n위키미디어 공용위키데이터 항목\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n위키백과, 우리 모두의 백과사전.\\n\\n\\n\\n메타버스(metaverse) 또는 확장 가상 세계는 가상, 초월을 의미하는 \\'메타\\'(meta)와 세계, 우주를 의미하는 \\'유니버스\\'(universe)를 합성한 신조어다.[1][2] \\'가상 우주\\'라고 번역하기도 했다. 1992년 출간한 닐 스티븐슨의 소설 \\'스노 크래시\\'에서 가장 먼저 사용했다.[3] 이는 실제 생활과 법적으로 인정한 활동인 직업, 금융, 학습 등이 연결된 3차원 가상 세계 또는 현실감 있는 4차원 가상 시공간을 뜻한다. 가상현실, 증강현실을 결합한 상위 개념으로서 현실을 디지털 기반의 가상 세계로 확장해 가상 공간에서 모든 활동을 할 수 있게 만드는 시스템이다. 구체적으로 정치와 경제, 사회, 문화 전반적 측면에서 현실과 비현실이 공존하는 생활형, 게임형 가상 세계라는 의미로 폭넓게 사용한다.[4]\\n\\n\\n정의[편집]\\n메타버스라는 개념의 뚜렷한 정의는 아직까지 확립되지 않았다. 일반적으로는 \\'현실 세계와 같은 사회적·경제적 활동이 통용되는 3차원 가상공간\\' 정도의 의미로 사용되고 있으나,[5] 학자나 기관마다 나름 정의를 내리고 있어 넓은 의미로 통용되고 있다.\\n대한민국의 경우, 심임보 교수는 \\'대한민국 4차 산업혁명 페스티벌\\'에서 메타버스를 \"가상 자아인 아바타를 통해 경제, 사회, 문화, 정치 활동 등을 이어가는 4차원 가상 시공간\"으로 정의하였다.[6] 이외에 손강민 등은 메타버스를 \"모든 사람들이 아바타를 이용하여 사회, 경제, 문화적 활동을 하게 되는 가상의 세계\"라고 정의했으며,[7] 류철균 등은 메타버스를 \"생활형 가상세계\", \"실생활과 같이 사회, 경제적 기회가 주어지는 가상현실공간\"이라 정의했다.[8] 또한 서성은은 메타버스를 \"단순한 3차원 가상공간이 아니라, 가상공간과 현실이 적극적으로 상호작용하는 공간이며 방식 그 자체\", \"현실과 가상세계의 교차점이 3d 기술로 구현된 또 하나의 세계\"라고 정의했다.[5] 김국현의 경우, 메타버스의 현실의 재구성이라는 측면에 주목했다.[9] 「메타버스 내 게임형 가상세계와 생활형 가상세계에 대한 연구」에 따르면 그는 『웹 2.0의 경제학』에서 메타버스를 \"기존의 현실 공간이었던 현실계(도구로서의 가상공간)와 현실의 것을 가상세계로 흡수한 것이었던 이상계(현실의 모사공간), 그리고 현실과 다른 상상력에 의한 대안의 가상현실인 환상계(인간의 환상과 욕망이 표출되는 공간)가 융합된 공간\"이라 정의했다.[10]\\n미국전기전자학회의 표준에 따르면 메타버스는 \"지각되는 가상세계와 연결된 영구적인 3차원 가상 공간들로 구성된 진보된 인터넷\"이라는 의미를 지닌다.[11] 비영리 기술 연구 단체인 ASF(Acceleration Studies Foundation)은 메타버스를 \"가상적으로 향상된 물리적 현실과 물리적으로 영구적인 가상공간의 융합\"이라고 정의했다.[12]\\n메타버스를 사람들이 왜 접근하는가에 대해 논리적으로 접근해야 한다는 의견도 존재한다. 예를들어 현실과 메타버스가 완전히 같다면 사람들은 굳이 메타버스를 이용할 필요가 없고 매력을 느낄 수 없다. 따라서 메타버스는 현실에서 충족할 수 없는 것을 충족할 수 있는 무언가를 고려해야 한다.\\n[13]\\n\\n유래[편집]\\n가상 공간으로서의 메타버스는 1992년 닐 스티븐슨(Neal Stephenson)의 소설 《스노우 크래쉬》에서 처음 등장한 개념과 용어이다.[14] 다음은 작품 속 메타버스 묘사를 인용하였다.\\n\\n 양쪽 눈에 서로 조금씩 다른 이미지를 보여 줌으로써, 3차원적 영상이 만들어졌다. 그리고 그 영상을 일초에 일흔두 번 바뀌게 함으로써 그것을 동화상으로 나타낼 수 있었다. 이 삼차원적 동화상을 한 면당 이 킬로픽셀의 해상도로 나타나게 하면, 시각의 한계 내에서는 가장 선명한 그림이 되었다. 게다가 그 작은 이어폰을 통해 디지털 스테레오 음향을 집어넣게 되면, 이 움직이는 삼차원 동화상은 완벽하게 현실적인 사운드 트랙까지 갖추게 되는 셈이었다.\\n그렇게 되면 히로는 이 자리에 있는 것이 아니었다. 그는 컴퓨터가 만들어내서 그의 고글과 이어폰\\n\\n 계속 공급해주는 가상의 세계에 들어가게 되는 것이었다. 컴퓨터 용어로는 《메타버스》라는 이름으로 불리는 세상이었다.[15] \\n이처럼 작품 속에서 메타버스의 기술적 근간을 상세히 설명한다. 메타버스는 고글과 이어폰, 즉 시청각 출력장치를 이용해 접근하는 가상세계로 규정한다.\\n\\n 그들은 빌딩들을 짓고, 공원을 만들고, 광고판들을 세웠다. 그뿐 아니라 현실 속에서는 불가능한 것들도 만들어냈다. 가령 공중에 여기저기 흩어져 떠다니는 조명쇼, 삼차원 시공간 법칙들이 무시되는 특수 지역, 서로를 수색해서 쏘아죽이는 자유 전투 지구 등.\\n단 한 가지 다른 점이 있다면, 이것들은 물리적으로 지어진 것들이 아니라는 점이었다. 더 스트리트 자체가 실재하는 것이 아니기 때문에, 더 스트리트는 다만 종이에 적힌 컴퓨터 그래픽 규약일 뿐이었다. 아니, 그것들은 광섬유 네트워크를 통해 전세계에 공개된 소프트웨어 조각들일 뿐이었다.[16] \\n 이런 것들을 건설하기 위해서는, <세계 멀티미디어 규약 단체 협의회>의 허락을 받아야했다. 더 스트리트의 빈터를 사들이고, 지역 개발 승인을 받고, 각종 허가 사항을 득하고, 검사원들을 매수하고 하는 따위의 일들을 해야 했다. 기업들이 더 스트리트에 건물을 짓기 위해 내는 돈은 <규약 단체 협의회>의 신탁 기금으로 들어갔다. 그 기금은 다시 더 스리트를 유지하고 확장하는 비용으로 사용되었다.[17] \\n위 인용문처럼, 메타버스는 소프트웨어 조각들을 통해 표현한 실존하지 않는 그래픽일 뿐이므로 현실세계와 달리 물리 법칙에 제약받지 않는다. 이런 차이에도 메타버스 속에서 경제사회 활동은 현실세계와 흡사한 형태로 나타난다.\\n\\n메타버스의 네 가지 유형[편집]\\n비영리 기술 연구 단체 ASF(Acceleration Studies Foundation)은 메타버스를 \\'증강과 시뮬레이션\\', \\'내적인 것과 외적인 것\\'이라는 두 축을 가지고 우측 그림과 같이 네 가지 범주로 분류했다.\\n\\n증강현실(Augmented Reality)[편집]\\n증강현실은 현실공간에 2D 또는 3D로 표현한 가상의 겹쳐 보이는 물체를 통해 상호작용하는 환경을 의미한다. 사람들에게서 가상세계에 거부감을 줄이고, 몰입감을 높이는 특징을 지닌다.[4] 사용자가 단말기 카메라로 현재는 유적만 남은 흔적을 촬영하면 디지털로 구축된 과거의 건물이 사용자 단말기에 중첩해 보이는 장면이 증강현실 일례이다.[4] 증강현실의 또 다른 예시로는 부동산(Property)과 디지털 기술(Technology)의 융합을 일컫는 ‘프롭테크(Proptech)’ 산업에서도  활용되고 있다는 점이다.[18]\\n\\n일상기록(Lifelogging)[편집]\\n일상기록 또는 라이프로깅(Lifelogging)은 사물과 사람에 대한 일상적인 경험과 정보를 캡처하고 저장하고 묘사하는 기술이다.[19] 사용자는 일상생활에서 일어나는 모든 순간을 텍스트, 영상, 사운드 등으로 캡처하고 그 내용을 서버에 저장하여 이를 정리하고, 다른 사용자들과 공유가 가능하다.[20] 센서가 부착된 스포츠 웨어를 네트워크 연결이 가능한 MP3 플레이어와 연동하여 사용해서 달린 거리, 소비 칼로리, 선곡 음악 등의 정보를 저장하고 공유하는 등의 행위가 일상기록 예시이다.[20]\\n\\n거울세계(Mirror Worlds)[편집]\\n거울세계는 실제 세계를 가능한 사실적으로, 있는 그대로 반영하되 \"정보적으로 확장된\"[21] 가상세계를 말한다. 대표적인 예로 구글 어스(Google Earth)를 들 수 있다. 구글 어스는 세계 전역의 위성사진을 모조리 수집하여 일정 주기로 사진을 업데이트하면서 시시각각 변화하는 현실세계의 모습을 그대로 반영하고 있다.[22] 기술의 발전이 계속될수록 현실이 반영된 거울세계는 점점 현실세계에 근접해갈 것이며, 이는 향후 가상현실의 커다란 몰입적 요소가 된다.[23] 이같은 거울세계 사용자는 가상세계를 열람함으로써 현실세계에 대한 정보를 얻게 된다.[23]\\n\\n가상세계(Virtual Worlds)[편집]\\n가상세계(Virtual World)는 현실과 유사하거나 혹은 완전히 다른 대안적 세계를 디지털 데이터로 구축한 것이다.[24] 가상 세계에서 사용자들은 아바타를 통해 현실세계의 경제적, 사회적인 활동과 유사한 활동을 한다는 특징이 있다.[25] 가상세계는 우리에게 가장 친숙한 형태의 메타버스로서, 리니지와 같은 온라인 롤플레잉게임에서부터 린든 랩에서 개발된 세컨드 라이프와 같은 생활형 가상세계에 이르기까지 3차원 컴퓨터그래픽환경에서 구현되는 커뮤니티를 총칭하는 개념이다.[5]\\n\\n발전방향과 문제점[편집]\\n현황 및 발전방향[편집]\\n현재 메타버스 관심이 증가하면서 메타버스 발전을 기대한다. 메타버스를 구현한 플랫폼은 대표적으로 포트나이트, 마인크래프트, 로블록스, 동물의 숲 등이 있고, 대한민국에서는 제페토, 이프랜드 등이 있다.[26][27] 대체불가능토큰의 디지털 지갑과 연동되어 메타버스 내에서 자신의 NFT 디지털아트를 전시하거나 타인의 디지털 아트를 감상할 수 있는 플랫폼들이 있다. 이러한 플랫폼에서는 NFT 거래도 가능하다. 대표적인 플랫폼으로 Spatial.io 가 있다.\\n이러한 상황에 린든 랩의 세컨드 라이프 인기가 큰 역할을 했다.[28] 이를 계기로 메타버스는 웹 2.0 시대의 새로운 비즈니스 모델이자 3D 기반 인터넷 플랫폼으로 주목받는다.[29] 또한 세컨드라이프의 성공 후, 데어닷컴, 웹킨즈 등 다수의 가상세계 서비스를 출시했다. 이로 인해 다양한 메타버스가 출현하고 상호 연결되는 거대한 가상세계인 \\'다중가상세계\\' 또는 \\'멀티버스\\'(Multiverse)의 시대의 도래가 가까워졌다.[30]\\n특히 이러한 움직임은 가상세계 오픈소스 소프트웨어 개발, 가상세계 플랫폼 공급기업의 등장으로 가속화 상황이다.[30] 린든 랩은 최근 세컨드 라이프 아바타를 다른 회사의 가상세계로 이동시키는 데에 성공해, 서로 다른 메타버스 간 상호운용성의 증진이 기대된다.[31] 또한 가상세계와 기존 웹 2.0 서비스가 융합하는 추세다. 구글의 \\'라이블리\\'(Lively)가 대표적 사례로, 이러한 서비스들은 통상 2.5D라 불리며 가벼운 소통 도구로서 가상공간을 제공한다.[32]\\n또한, 최근 코로나19 범유행 이후 비대면 추세 확산으로 인해 외부 활동이 제한되는 사회적 환경 요인은 메타버스의 확산을 매우 빠르게 하였고, 일상으로 급속도로 확장중이다.[33][34] 지자체에서는 \\'메타버스 관광지\\'를 유치하여 메타버스 내에서 관광산업을 실시하고 있기도 하다. 그러나 하루 방문객이 1명에 그치는 등 무용론도 대두되고 있다.[35]\\n\\n뿐만아니라 \\'메타버스 개발자 경진대회\\'를 개최하여 개발자 양성과 더불어 산업 생태계 확장을 위한 노력도 지속하고 있다.\\n\\n문제점[편집]\\n메타버스의 발전에는 몇 가지 문제점이 발생한다\\n\\n메타버스 내의 불법행위와 사법권[편집]\\n세컨드 라이프와 같은 가상세계에서 도박, 사기, 매춘 등 범죄가 발생하며 새로운 사회적 문제로 떠올랐다. 이런 일련의 사건에서 사이버상에서까지 현실의 법을 가혹하게 적용해야 하는 것을 반대하는 입장과 사이버상에서도 엄격한 윤리관을 적용해 통제헤야 한다는 의견이 존재한다.\\n통제하기 어려운 이유도 있다. 예를 들어, 사이버 마약의 사례처럼, 현행법이 규정하지 않아서 법률에 없는 새로운 유해물 혹은 범죄가 발생할 경우 이를 통제할 수 없다.\\n\\n아바타의 인격권[편집]\\n가상세계 내에서 현실의 자아를 대변하는 존재인 \\'아바타\\'가 모여서 커뮤니티를 형성한다는 점에서 대한민국 정부는 \\'메타버스\\'가 기존의 게임과는 다른 성격을 가지고 있다고 보았다. 코로나 19로 인한 사회적 상황으로 메타버스의 커뮤니티가 활성화 되었고 이에 성범죄가 발생하였으나 \\'사람\\'이 아니기에 처벌 규정이 없는 실정이었다.  이에 2022년 6월 29일 여성가족부가 발표한 \\'제4차 청소년보호종합대책\\'에서는 메타버스 내 아바타 성범죄에 대응해 인격권 인정 여부를 연구해 처벌 실효성을 확보하고자 하고있다.[36]\\n\\n가상화폐의 현금화[편집]\\n가상세계의 경제 규모가 커지면서, 가상화폐의 현금화에 관한 논쟁이 발생한다. (국내의 경우 \"게임산업진흥법\"에 의해 가상화폐 환전은 불법으로 취급되지만, 미국에서는 린든 달러 등의 가상화폐가 미화로 환전 가능한 상태이다.[37])\\n첫번째는 가상화폐를 정당한 노동의 대가로 얻은 부가가치로 인정할 수 있느냐 하는 점이다. 현실세계에서 옷과 같은 물건을 팔아 번 돈과 장물을 팔아서 번 돈은 구분된다. 합법적 자금과 불법적 자금으로 구분하여 불법 자금은 환수하거나 이를 근거로 체포도 가능하다. 하지만, 가상세계 가입자가 아바타 의상을 디자인하여 판매해 얻은 가상화폐와 사행성 게임을 통해 발생된 가상화폐를 동일한 가치로 여긴다. 가상세계에서 이 둘을 명확히 구분하지 못하므로 문제가 발생한다.[38]\\n두번째는 가상화폐를 새로운 거래수단으로 인정할지에 관련한 문제다. 인정 여부에 따라 가상경제 활성화라는 긍정적 효과 기대가 가능한 반면, 게임 과몰입 및 불법 거래, 탈세에 대한 우려가 교차하는 상황이다.[38]\\n\\n가상세계 과몰입[편집]\\n가상세계, 특히 현실과 사회경제적 활동 양상이 닮은 메타버스에서는 기존 온라인 게임과 달리 일상 생활로 인식하며 과몰입 심화 가능성이 높다.[39] 가상세계에 지나치게 몰입해 현실의 일상은 황폐해지고, 정체성 장애가 발생할 수도 있다는 점이 문제로 대두된다.\\n\\n같이 보기[편집]\\n클로즈드 플랫폼\\n가상 공간\\n대규모 다중 사용자 온라인 롤플레잉 게임\\n각주[편집]\\n\\n↑ “메타버스 뉴스 빅데이터 분석: 토픽 모델링 분석을 중심으로”. 한국디지털콘텐츠학회 논문지. 2021년 7월.\\xa0\\n\\n↑ “The fairyland of Second Life: Virtual social worlds and how to use them”. 안드레아스 카플란.\\xa0\\n\\n↑ “\\'메타버스·아바타\\' 개념 낳은 소설 \\'스노 크래시\\'”. 2021년 6월 15일. 2022년 2월 6일에 확인함.\\xa0\\n\\n↑ 가 나 다 김한철 외, 「메타버스에 기반한 차세대 U-Biz 고찰」, Samsung SDS Journal of IT Services, 6권 1호, p.180\\n\\n↑ 가 나 다 서성은, 「메타버스 개발동향과 발전전망 연구」, 한국 HCI 학술대회, 2008, p. 1451\\n\\n↑ 2021년 대한민국 4차 산업혁명 페스티벌 & 블록체인 서울 심임보 교수 기조강연\\n\\n↑ 손강민·이범렬·심광현·양광호, 「웹 2.0과 온라인 게임이 만드는 매트릭스 월드 메타버스」, ETRI CEO Information 제47호, 2006, p. 4\\n\\n↑ 류철균·안진경, 「가상세계의 디지털 스토리텔링 연구」, 게임산업저널 2007년 1호, 2007, p. 33\\n\\n↑ 김국현 (2007년 10월 15일). “\\'가상공간=현실\\'이 된다”. 시사IN. 2014년 9월 7일에 원본 문서에서 보존된 문서. 2014년 6월 22일에 확인함.\\xa0\\n\\n↑ 권오현, 「메타버스 내 게임형 가상세계와 생활형 가상세계에 대한 연구」, 건국대학교디자인대학원 2011, p,12, 재인용\\n\\n↑ IEEE VW Standard Working Group. “Metaverse Standards”. 2014년 6월 8일에 원본 문서에서 보존된 문서. 2016년 1월 29일에 확인함.\\xa0\\n\\n↑ John S·Jamais C·Jerry P,「Metaverse Roadmap」, A Cross-Industry Public Foresight Project, 2007, p.4\\n\\n↑ 논문,Israa Darkazanli,The Metaverse and its implications on humanity and digital future, 2022, p.13,14\\n\\n↑ “메타버스 뉴스 빅데이터 분석: 토픽 모델링 분석을 중심으로”. 한국디지털콘텐츠학회 논문지. 2021년 7월.\\xa0\\n\\n↑ 닐 스테픈슨, 김장환 역, 『스노우 크래쉬』, 새와 물고기, 1996, pp. 48-49\\n\\n↑ 닐 스테픈슨, 김장환 역, 『스노우 크래쉬』, 새와 물고기, 1996, p.50\\n\\n↑ 닐 스테픈슨, 김장환 역, 『스노우 크래쉬』, 새와 물고기, 1996, p51\\n\\n↑ 김동호 (2021년 12월 6일). “프롭테크의 미래, 가상과 현실 잇는 ‘메타버스 아파트’”. 《서울경제》. 2021년 12월 6일에 확인함.\\xa0\\n\\n↑ 서성은, 「메타버스 개발동향과 발전전망 연구」, 한국 HCI 학술대회, 2008, p. 1452\\n\\n↑ 가 나 배경우, 「모바일을 매개로 한 미러월드, 현실공간 연동 서비스 디자인」,아주대학교대학원, 2010, p.3\\n\\n↑ John, S., Jamais, C., Jerry, P. \\'Metaverse Roadmap\\' , A Cross-Industry Public Foresight Project, 2007, p.7\\n\\n↑ 배경우, 「모바일을 매개로 한 미러월드, 현실공간 연동 서비스 디자인」,아주대학교대학원, 2010, p.5\\n\\n↑ 가 나 권오현, 「메타버스 내 게임형 가상세계와 생활형 가상세계에 대한 연구」, 건국대학교디자인대학원 2011, p.18\\n\\n↑ 배경우, 「모바일을 매개로 한 미러월드, 현실공간 연동 서비스 디자인」,아주대학교대학원, 2010, p.2\\n\\n↑ 배경우, 「모바일을 매개로 한 미러월드, 현실공간 연동 서비스 디자인」,아주대학교대학원, 2010, p.2\\n\\n↑ “메타버스 뉴스 빅데이터 분석: 토픽 모델링 분석을 중심으로”. 한국디지털콘텐츠학회 논문지. 2021년 7월.\\xa0\\n\\n↑ 김양혁 (2021년 12월 4일). “아시아 대표 메타버스 된 네이버 ‘제페토’… 추격하는 SKT ‘이프랜드’”. 《조선비즈》. 2021년 12월 12일에 확인함.\\xa0\\n\\n↑ “메타버스 뉴스 빅데이터 분석: 토픽 모델링 분석을 중심으로”. 한국디지털콘텐츠학회 논문지. 2021년 7월. . 메타버스는 1992년 닐 스테프슨(Neal Stephenson)의 SF 소설 스노우 크래쉬(Snow Crash)에서 처음 등장하였고, 미국의 세컨드라이프(SecondLife)를 필두로 사이버스페이스 상에서 발전을 해왔다.\\xa0\\n\\n↑ 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, pp.3-5\\n\\n↑ 가 나 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.11\\n\\n↑ 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.19\\n\\n↑ 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.13\\n\\n↑ “메타버스 뉴스 빅데이터 분석: 토픽 모델링 분석을 중심으로”. 한국디지털콘텐츠학회 논문지. 2021년 7월.\\xa0\\n\\n↑ “요즘 대세는 메타버스.. 서학개미도 올라탔다”. MoneyS. 2021년 8월 7일.\\xa0\\n\\n↑ “위기의 지역명소 메타버스, 내러티브와 융복합 기술이 필요하다.”.\\xa0\\n\\n↑ “제4차 청소년보호종합대책발표”. 《제4차 청소년보호종합대책발표》. 2022년 6월 29일.\\xa0 이름 목록에서 |이름1=이(가) 있지만 |성1=이(가) 없음 (도움말)\\n\\n↑ 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.23\\n\\n↑ 가 나 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.24\\n\\n↑ 박상현,「가상세계의 진화와 10대 이슈 전망」, IT& Future Strategy, 2009, p.26\\n\\n\\nvte혼합 및 가상현실개념\\n가상현실\\n버추얼 시네마토그래피\\n증강현실\\n증강 현실\\n리얼 라이프\\n프로젝션 증강 모델\\n현실-가상 연속성\\n인공 현실\\n모의 현실\\n유비쿼터스 컴퓨팅\\n가상 세계\\n퍼시스턴트\\n멀티모덜 인터페이스\\n원격현장감\\n몰입\\n공간 컴퓨팅\\n기술\\n합성\\n카메라 리섹셔닝\\n햅틱 수트\\n헤드 마운티드 디스플레이\\n광학\\n전방 시현기\\n이미지 기반 모델링 및 렌더링\\n실시간 컴퓨터 그래픽스\\n가상 망막 디스플레이\\n착용 컴퓨터\\n크로마키\\n비주얼 헐\\n자유 시점 텔레비전\\n전방위 트레드밀\\n은면 결정\\n가상 현실 헤드셋\\n스테레오스코피\\n컴퓨터 비전\\n스테레오\\n\\n추적\\n모션 캡처\\n트래킹 시스템\\n종류\\n광학\\n관성\\n자기\\n장치\\n와이어드 글러브\\n게임트렉\\n구글 글래스\\n마이크로소프트 홀로렌즈\\n플레이스테이션 무브\\n립 모션\\n키넥트\\n레이저 히드라\\n\\n몰입형 장치개인\\n데이드림\\n구글 카드보드\\nHTC 바이브\\n오큘러스 리프트\\n삼성 기어 VR\\n플레이스테이션 VR\\nOSVR\\n방\\nAlloSphere\\nCave\\nTreadPort\\n역사\\n센소라마\\n버추얼 보이\\n패미컴 3D 시스템\\n다모클레스의 검\\n세가 VR\\n버추얼리티\\n응용\\n퍼베이시브 게임\\nARToolKit\\n대화형 아트\\n버추얼 그래피티\\n\\n가공의 모의 현실\\n\\n전거 통제: 국가 \\n스페인\\n미국\\n일본\\n\\n\\n\\n\\n\\n원본 주소 \"https://ko.wikipedia.org/w/index.php?title=메타버스&oldid=39336289\"\\n분류: 메타버스가상 공간1990년대 신조어SF 소재가상 현실을 배경으로 한 작품미래주의숨은 분류: 인용 오류 - 저자 또는 편집자 없음해결되지 않은 속성이 있는 문서BNE 식별자를 포함한 위키백과 문서LCCN 식별자를 포함한 위키백과 문서NDL 식별자를 포함한 위키백과 문서위키데이터 속성 P18을 사용하는 문서위키데이터 속성 P373을 사용하는 문서위키데이터 속성 P244를 사용하는 문서위키데이터 속성 P349를 사용하는 문서위키데이터 속성 P950을 사용하는 문서위키데이터 속성 P7859를 사용하는 문서\\n\\n\\n\\n\\n\\n\\n 이 문서는 2025년 4월 19일 (토) 14:02에 마지막으로 편집되었습니다.\\n모든 문서는 크리에이티브 커먼즈 저작자표시-동일조건변경허락 4.0에 따라 사용할 수 있으며, 추가적인 조건이 적용될 수 있습니다. 자세한 내용은 이용 약관을 참고하십시오.Wikipedia®는 미국 및 다른 국가에 등록되어 있는 Wikimedia Foundation, Inc. 소유의 등록 상표입니다.\\n\\n\\n개인정보처리방침\\n위키백과 소개\\n면책 조항\\n행동 강령\\n개발자\\n통계\\n쿠키 정책\\n모바일 보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n목차 토글\\n\\n\\n\\n\\n\\n\\n\\n메타버스\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n47개 언어\\n\\n\\n새 주제\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://blog.naver.com/hyper_cloud/223023188600', 'title': '하이퍼클라우드 : 네이버 블로그', 'language': 'ko'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n하이퍼클라우드 : 네이버 블로그\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://engoo.co.kr/blog/3%EB%B6%84-%EC%98%81%EC%96%B4%ED%9A%8C%ED%99%94/%EB%A9%94%ED%83%80%EB%B2%84%EC%8A%A4-%EB%9C%BB-%EC%A0%84-%EC%84%B8%EA%B3%84%EA%B0%80-%EC%A3%BC%EB%AA%A9%ED%95%98%EB%8A%94-metaverse%EB%9E%80/', 'title': '메타버스 뜻? 전 세계가 주목하는 ‘Metaverse’란? | Engoo 블로그', 'description': \"전 세계가 주목하는 '메타버스(Metaverse)'란? 메타버스의 뜻과 다양한 종류를 엔구와 함께 알아볼까요?? 1:1 원어민화상영어, 엔구!!\", 'language': 'ko-KR'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n메타버스 뜻? 전 세계가 주목하는 ‘Metaverse’란? | Engoo 블로그\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\nEngoo 블로그\\n\\n\\n로그인\\n무료 체험하기\\n \\n\\n\\n\\n홈\\n카테고리\\n\\n엔구 소식\\n영어공부 TIP\\n3분 영어회화\\n리얼 여행영어\\n직장 영어백서\\n키즈 영어\\n헷갈리는 문법\\n\\n\\n \\n\\n\\n\\nSearch for:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEngoo ► 블로그 ► 3분 영어회화\\n\\n메타버스 뜻? 전 세계가 주목하는 ‘Metaverse’란? \\n\\n\\n\\n \\n\\n\\nEngoo Korea \\n (업데이트됨 ) \\n\\n \\n\\n\\n\\n \\n\\n\\n안녕하세요. 엔구 화상영어입니다.\\n요즘 전세계적으로 가장 주목받는 단어 중 ‘메타버스(Metaverse)’라는 말이 있는데요!‘메타버스(Metaverse)’가 무슨 뜻인지 알고 계신가요?\\n\\n\\nMetaverse(meta+universe)가상의 세계(초월+우주/세계)\\n먼저, 메타버스는 ‘가상의 세계’라는 의미를 가진 단어입니다.좀 더 구체적으로 경제, 사회, 문화 등 우리 삶의 전반적인 부분에서 현실과 비현실(가상)이 모두 공존할 수 있는 3차원의 가상공간을 의미합니다.\\n\\nThe Internet is 2D, words, and pictures on screens whereas metaverse is 3D, texts, and images on screens along with touching.인터넷이 글자랑 사진을 화면으로 보는 2차원이라면 메타버스는 글이랑 그림을 화면으로 보고 만질 수도 있는 3차원이다.\\n개념적인 부분으로만 이해하기에는 조금 어려운데요!\\n\\nSimply said, VR and AR we’re familiar with are included in the metaverse.쉽게 말해, 우리가 잘 알고 있는 VR, AR이 메타버스에 포함됩니다.\\nVR(Virtual Reality)와 AR(Augmented Reality)는 꽤 익숙한 단어들이죠?가상 현실, 증강 현실도 메타버스의 한 종류입니다.\\n\\nThe domain of metaverse is expanding especially as untact is getting spotlight due to COVID19.\\xa0\\xa0특히, 코로바 19로 인하여 언택트가 주목받으며, 메타버스의 영역이 점차 확대되고 있습니다.\\n게임 콘텐츠는 물론 최근에는 교육, 비즈니스 분야에서도 꽤 활용되고 있습니다.\\n\\nEducation institutions applied metaverse to proceed entrance ceremonies, classes, and more via virtual reality.교육기관은 메타버스를 도입하여 가상현실을 통해 입학식, 수업 등을 진행합니다.\\n코로나로 인해 비대면 입학(졸업)식, 수업 등이 당연시되고 있죠.이러한 부분을 메타버스를 활용해 좀 더 현실성 있는 온라인 플랫폼으로 만들고 있습니다.\\n\\nOne can communicate and have meetings in the office with characters that have similar personalities.\\xa0유사한 성격을 가진 캐릭터를 통해 사무실 내에서 소통 및 회의를 합니다.\\n‘메타버스 오피스’ 공간을 활용하여 자신의 캐릭터로 업무를 수행하고, 각종 미팅 등에 참여하는 활동을 할 수 있습니다.특히, 사무실을 현실과 같이 구현하거나 거리에 따른 목소리 조절 등 현실성을 더욱 반영하고 있다고 하네요!\\n\\nLifelogging is also a type of metaverse.\\xa0라이프로깅 역시, 메타버스의 일종입니다.\\n‘라이프로깅(Lifelogging)’이라는 단어가 조금 생소하실 수 있습니다.하지만 우리는 이미 ‘라이프로깅’을 실천하고 있답니다.\\n‘라이프로깅’이란, 개인의 일상을 각종 SNS에 기록하고 다른 사람과 공유하는 활동을 말합니다.자신의 일상생활에서 일어나는 모든 순간을 사진, 영상, 소리 등으로 저장하여 이를 서버에 저장하는 것을 의미합니다.\\n하지만 메타버스에 대한 우려의 목소리도 나오고 있습니다.\\n\\nMisconduct such as deception, gambling etc are occurring in the metaverse.메타버스 내의 불법행위와 사기, 도박 등의 문제가 발생하고 있습니다.\\n기술의 발전에 따라 불법적인 행위도 함께 커지고 있는 현실입니다.\\n\\nCould the laws of the real world/ reality be applied?\\xa0현실세계에서의 법을 적용할 수 있을까요?\\n현재까지도 많은 논쟁이 있는 부분입니다.메타버스에서 발생한 불법행위를 과연 현실세계의 법과 동일하게 적용하는 것이 좋은지, 결국 통제가 되지 않을 부분인지에 대한 의문점이 많이 남습니다.\\n\\nHow much is virtual currency worth?가상화폐의 가치는 과연 어느정도인가?\\n메타버스의 또 다른 문제점이 바로, ‘가상화폐’입니다!현재, 국내에서는 ‘게임산업진흥법’에 따라 가상화폐를 환전하는 것이 불법이지만 미국에서는 가상화폐가 미화로 환전이 가능합니다.이러한 가상화폐에 대한 화폐적 가치를 어느 선까지 인정해주어야 적합한 걸까요?\\n\\n오늘은 화제의 ‘메타버스(Metaverse)’에 대해 알아보았습니다.\\n페이스북의 CEO인 ‘마크 저커버스’는 회사를 소셜 미디어 업체에서 메타버스 기업으로 전환하겠다고 밝힌 바 있죠.그만큼 현재 ‘메타버스(Metaverse)’에 대한 관심도가 커지고 있는 것이라 여겨집니다.\\n\\n다음에도 유익한 포스팅으로 찾아오겠습니다!상단의 이미지를 클릭하면 1:1 원어민화상영어, 엔구를 바로 체험하실 수 있습니다.\\n\\n다람쥐는 영어로 'squirrel'가 아니다?\\n\\n\\n4차산업4차산업혁명5차산업혁명armetaversevr기초영어회화대학생영어회화디지털시대라이프로깅메타버스메타버스뜻메타버스란메타버스의미메타버스플랫폼비대면비대면교육비대면수업비대면영어로비즈니스영어비즈니스영어회화비즈니스용어비즈니스회화생활기초영어회화생활영어회화성인영어회화언택트영어회화영어회화공부영어회화과외영어회화독학영어회화후기원어민강사원어민대화원어민영어원어민영어공부원어민영어과외원어민영어단어원어민영어대화원어민영어표현원어민영어회화원어민영어회화표현원어민전화영어원어민튜터원어민화상영어원어민회화원어민회화추천일대일영어회화일상영어회화전화영어전화영어가격전화영어독학전화영어비교전화영어사이트전화영어추천전화영어회화전화영어후기직장인영어회화페이스북페이스북메타버스화상영어화상영어가격화상영어공부화상영어공부법화상영어비교화상영어사이트화상영어추천화상영어회화화상영어후기화상회의 \\n\\n\\n\\n\\n공유하기:\\n \\n\\n연관 포스트\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n엔구에 대하여\\n수업 교재\\n강사진\\nFAQs\\n제휴문의\\n무료 체험하기\\n\\n\\n\\n\\n\\n    © 2025 DMM.com LLC. 모든 권리 보유.  \\n\\n대표전화: 1670-8819\\n주소: 서울특별시 중구 통일로2길 16 AIA타워 4층 Engoo Korea\\n\\n\\n\\n\\n사업자등록번호: 726-87-00137\\n통신판매업신고번호: 제 2015-서울중구-1007호\\n부가통신사업 신고번호: 제 2-01-17-0071호\\n원격평생교육시설 제 315호\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      프리미엄 수업    \\n\\n      무료로 체험하세요    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
              "  Document(metadata={'source': 'https://blog.naver.com/dy0655/222790723404?viewType=pc', 'title': '대양씨아이에스 : 네이버 블로그', 'language': 'ko'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n대양씨아이에스 : 네이버 블로그\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
              "  Document(metadata={'source': 'https://brunch.co.kr/@@3XFk/76', 'title': '메타버스에 대해서 알아보자', 'description': '메타버스의 정의 메타버스란 현실의 나를 대리하는 아바타를 통해 일상 활동과 경제생활을 영위하는 3D 기반의 가상세계이다. 여기서의 일상 활동과 경제생활은 현실과 분리된 것이 아닌, 현실의 연장선상에서 일어나는 행위가 포함된다. 현실 세계가 가상공간과 결합하여 마치 현실이 가상공간으로 확장된 것을 의미한다. 메타버스는 현실과 가상이 합쳐진 초월을 의미하는 메', 'language': 'ko'}, page_content='\\n\\n\\n\\n메타버스에 대해서 알아보자\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n메뉴\\n\\n브런치 스토리\\n\\n\\n\\n매거진\\n\\n웹3 크리에이터 이코노미\\n\\n\\n\\n\\n실행\\n\\n신고\\n\\n\\n\\n라이킷\\n5\\n\\n\\n댓글\\n\\n\\n\\n공유\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n닫기\\n\\n\\nYou can make anythingby writing\\nC.S.Lewis\\n브런치스토리 시작하기\\n\\n\\n\\n\\n브런치스토리 홈\\n\\n\\n브런치스토리 나우\\n\\n\\n브런치스토리 책방\\n\\n\\n\\n\\n\\n\\n\\n 계정을 잊어버리셨나요?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nkeyword\\n\\n\\n\\n                                    아바타\\n                                \\n\\n\\n\\n                                    가상현실\\n                                \\n\\n\\n\\n                                    메타버스\\n                                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    유훈식 교수\\n                \\n\\n\\n소속\\n서울미디어대학원\\n직업\\n교수\\n\\n\\n\\n\\n\\n\\n\\n인공지능을 활용한 디자인을 통해 보다 창의적으로 혁신적인 디자인 결과를 소비자에게 전달하고, 기업에게는 보다 효율적인 디자인 시스템을 만들 수 있는 연구와 교육을 진행하고 있습니다\\n\\n\\n\\n\\n\\n구독자\\n755\\n\\n\\n\\n\\n                            제안하기\\n                        \\n\\n\\n구독\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                             매거진의 이전글\\n                                                            \\n블록체인에 대해서 알아보자\\n\\n\\n크리에이터 이코노미에 대해서 알아보자\\n\\n                                                                        매거진의 다음글\\n                                                            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n브런치는 최신 브라우저에 최적화 되어있습니다.\\nIE\\nchrome\\nsafari\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = graph.invoke({'question': ''})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4C0YX4crDMi"
      },
      "source": [
        "전체 결과가 잘 실행되었지만, 중간 결과가 보고 싶다면 어떻게 해야 할까요?   \n",
        "이후에 배울 `LangSmith`를 통해 트래킹할 수도 있고, 아래의 코드로 각 단계를 스트리밍할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39uRgYljrDMk",
        "outputId": "c495e7c0-089e-4709-eb29-cdd5130289c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'get_query': {'query': 'Stanford Multi-Agent STORM'}}\n",
            "{'tavily_search': {'context': [Document(metadata={'source': 'https://medium.com/@cognidownunder/stanford-storm-revolutionizing-ai-powered-knowledge-curation-35ce51996c19', 'title': 'Stanford STORM: Revolutionizing AI-Powered Knowledge Curation | by Cogni Down Under | Medium', 'description': 'In the ever-evolving landscape of artificial intelligence, a new player has emerged that promises to reshape how we approach knowledge curation and content generation. Enter Stanford STORM…', 'language': 'en'}, page_content='Stanford STORM: Revolutionizing AI-Powered Knowledge Curation | by Cogni Down Under | MediumSitemapOpen in appSign upSign inMedium LogoWriteSign upSign inStanford STORM: Revolutionizing AI-Powered Knowledge CurationCogni Down UnderFollow5 min read·Jul 23, 2024--3ListenSharenowledge CurationStanford STORM: Revolutionizing AI-Powered Knowledge CurationIn the ever-evolving landscape of artificial intelligence, a new player has emerged that promises to reshape how we approach knowledge curation and content generation. Enter Stanford STORM (Structured Task-Oriented Research Machine), an innovative large language model (LLM) system that’s making waves in the AI community. Developed by the brilliant minds at Stanford’s OVAL team, STORM is not just another chatbot — it’s a sophisticated research assistant capable of producing Wikipedia-style articles from scratch.The STORM Approach: A Perfect Knowledge TempestHarnessing the Power of Multiple AgentsAt its core, STORM employs a multi-agent system that simulates a team of experts collaborating on a research project. This isn’t your run-of-the-mill LLM; it’s a carefully orchestrated symphony of AI agents, each playing a crucial role in the content creation process.The Research Phase: Laying the GroundworkSTORM kicks things off by diving deep into the digital archives of Wikipedia and other reputable sources. It’s like sending out a fleet of highly efficient librarians, each tasked with gathering relevant information on the topic at hand. But STORM doesn’t just copy-paste — it analyzes, extracts, and synthesizes this information into a coherent structure.Outline Creation: The Blueprint for KnowledgeWith its digital arms full of raw data, STORM then puts on its architect hat. It crafts a detailed outline that serves as the skeleton for the final article. This isn’t just a bullet point list; it’s a carefully considered framework that ensures comprehensive coverage of the subject matter.The Art of AI ConversationHere’s where things get really interesting. STORM doesn’t just write — it talks to itself. Or rather, it simulates conversations between multiple AI agents, each representing different perspectives on the topic. It’s like eavesdropping on a roundtable discussion between experts, except all the experts are artificial intelligences.This conversational approach allows STORM to:Challenge its own assumptionsExplore different angles of the topicRefine and improve the outlineThe result? A more nuanced, well-rounded article that benefits from multiple “viewpoints.”From Outline to Article: STORM’s Writing ProcessWith its outline polished and its virtual experts consulted, STORM rolls up its digital sleeves and gets to work on the actual writing. But this isn’t a simple matter of generating text — STORM approaches each section methodically, ensuring that the final product is coherent, informative, and academically rigorous.Citation is KingOne of STORM’s standout features is its emphasis on proper citation. In an era where misinformation runs rampant, STORM takes a stand for accuracy. Each claim made in a STORM-generated article is backed by a citation, allowing readers to verify the information themselves.This commitment to citation isn’t just lip service. STORM boasts impressive citation recall and precision rates:Citation recall: 84.83%Citation precision: 85.18%These numbers speak volumes about STORM’s ability to produce well-supported, verifiable content.Beyond Retrieval: STORM vs. Traditional RAG SystemsWhile many LLMs rely on retrieval-augmented generation (RAG) to produce content, STORM takes things a step further. Its structured approach and multi-agent system allow for a level of organization and coverage that traditional RAG systems simply can’t match.The result? Articles that aren’t just informative, but also well-organized and comprehensive. It’s the difference between a hastily assembled collage and a carefully curated museum exhibit.Ensuring Accuracy: STORM’s Quality Control MeasuresIn the world of AI-generated content, accuracy is paramount. STORM doesn’t just aim for factual correctness — it’s built from the ground up with quality assurance in mind.Multiple Layers of VerificationResearch and Retrieval: STORM starts with a foundation of verified information from reputable sources.Multi-Agent Conversations: The simulated expert discussions help catch and correct potential errors.Iterative Drafting: The writing process includes multiple rounds of refinement.Citation and Attribution: Every claim is backed by a source, reducing the risk of hallucinations.Quality Assurance Mechanisms: STORM employs debiasing techniques and checks for narrative consistency.Human Review: While STORM is highly autonomous, human oversight remains a crucial final step.The Future of AI-Assisted ResearchAs we look to the horizon, STORM represents more than just a clever piece of software — it’s a glimpse into the future of how we interact with and generate knowledge. The implications for education, research, and content creation are profound.Imagine a world where:Students have access to dynamically generated, fully cited research papers on any topic.Researchers can quickly generate comprehensive literature reviews, freeing up time for original work.Content creators can produce in-depth, factually accurate articles at unprecedented speeds.STORM is more than just a tool — it’s a paradigm shift in how we approach knowledge curation and dissemination.Conclusion: The Dawn of a New Era in AI-Assisted KnowledgeStanford STORM represents a significant leap forward in the field of AI-powered content generation. By combining rigorous research methodologies with innovative LLM technologies, STORM offers a glimpse into a future where high-quality, citation-supported articles can be generated with unprecedented speed and accuracy.As the project continues to evolve and improve, we can expect to see STORM and similar systems play an increasingly important role in education, research, and content creation. The storm of knowledge is gathering, and it promises to reshape the landscape of information as we know it.FAQ SectionQ: How does STORM differ from other large language models? A: STORM uses a multi-agent system that simulates expert discussions, focuses on structured research and outline creation, and emphasizes proper citation and fact-checking.Q: Can STORM replace human researchers and writers? A: While STORM is a powerful tool, it’s designed to assist and augment human efforts, not replace them entirely. Human oversight and expertise remain crucial.Q: How accurate is the information generated by STORM? A: STORM achieves high citation recall (84.83%) and precision (85.18%) rates, indicating strong alignment between generated content and sources. However, human verification is still recommended.Q: Is STORM available for public use? A: As of July 2024, STORM is an open-source project. Check the Stanford OVAL team’s GitHub repository for the latest updates on availability and usage.Q: How does STORM handle potential biases in its generated content? A: STORM employs debiasing techniques and uses multi-perspective conversations to minimize biases. However, like all AI systems, it’s not entirely free from potential biases.#StanfordSTORM #AIResearch #MachineLearning #KnowledgeCuration #AIWriting #FutureOfEducation #OpenSourceAI #LLMInnovation #AIAssistant #TechRevolutionAI-powered Wikipedia article generationMulti-agent LLM systems for researchAutomated knowledge curation with citationsStanford OVAL team AI innovationsImproving AI content accuracy and factualityNext-generation retrieval-augmented generationAI-assisted academic research toolsOpen-source large language models for educationSimulated expert discussions in AI writingStructured approach to AI content creationStorm LlmStanfordStanford UniversityStanford ResearchLlm----3FollowWritten by Cogni Down Under315 followers·3 followingExploring the intersection of technology and artificial intelligenceFollowResponses (3)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://blog.stackademic.com/storm-stanfords-revolutionary-research-tool-harnessing-the-power-of-agents-and-agentic-workflows-a2fa0e1a7fe3', 'title': 'STORM: Stanford‚Äôs Revolutionary Research Tool Harnessing the Power of Agents and Agentic Workflows | by Lakshmi narayana .U | Stackademic', 'description': 'In the rapidly evolving field of artificial intelligence, Stanford University has unveiled a groundbreaking project that promises to revolutionize the way we conduct research, synthesize information‚Ä¶', 'language': 'en'}, page_content='STORM: Stanford‚Äôs Revolutionary Research Tool Harnessing the Power of Agents and Agentic Workflows | by Lakshmi narayana .U | StackademicSitemapOpen in appSign upSign inMedium LogoWriteSign upSign inStackademic¬∑Follow publicationStackademic is a learning hub for programmers, devs, coders, and engineers. Our goal is to democratize free coding education for the world.Follow publicationSTORM: Stanford‚Äôs Revolutionary Research Tool Harnessing the Power of Agents and Agentic WorkflowsLakshmi narayana .UFollow9 min read¬∑Jul 28, 2024--4ListenShareimage generated by author and DALL.E-3In the rapidly evolving field of artificial intelligence, Stanford University has unveiled a groundbreaking project that promises to revolutionize the way we conduct research, synthesize information, and create well-structured content. STORM, which stands for Synthesis of Topic Outlines through Retrieval and Multiperspective question asking, is being hailed as one of the most effective AI research and writing tools to date.What is STORM?STORM is an open-source AI system designed to create comprehensive, Wikipedia-style pages on any given topic. What sets STORM apart from other AI tools is its ability to not only compile information but also to reference the sources it uses, providing a level of transparency and credibility that is crucial in today‚Äôs information landscape.Source: ‚ÄòAssisting in Writing Wikipedia-like Articles From Scratch with LLMs‚Äô paperSTORM is an agentic system that assists in generating topic outlines for writing Wikipedia-like articles. It aims to automate the pre-writing stage by leveraging large language models (LLMs) and simulating conversations between writers and topic experts. This approach enhances the pre-writing stage, resulting in well-structured and comprehensive articles that rival those found on Wikipedia.Key Features:Comprehensive Content Creation: STORM generates detailed, well-structured articles on a wide range of topics.Local Runtime Capability: Users can run STORM on their local machines, ensuring privacy and control over the research process.Source Referencing: Each piece of information is linked back to its original source, allowing for easy fact-checking and further exploration.Multi-Agent Research: STORM utilizes a team of AI agents to conduct thorough research on the given topic.Open-Source Availability: As an open-source project, STORM is accessible to developers and researchers worldwide, fostering collaboration and continuous improvement.Top-Down Writing Approach: STORM employs a top-down approach, nailing down the outline before writing content, which is crucial for effectively conveying information to readers.Diverse Perspective Discovery: STORM discovers and incorporates diverse perspectives in researching a given topic, leading to more comprehensive and informative articles.Multi-Perspective Question Asking: The system simulates conversations where writers with different perspectives pose questions to a topic expert, allowing for deeper exploration of the subject matter.Understanding Agentic SystemsTo fully appreciate STORM‚Äôs capabilities, it‚Äôs important to understand the concept of agentic systems, which forms the foundation of STORM‚Äôs functionality.Agentic Systems and WorkflowsAgentic systems are AI-powered frameworks designed to perform tasks with a degree of autonomy and intelligence reminiscent of human agents. These systems are characterized by their ability to:Perceive their environment: They can gather and process information from various sources.Make decisions: Based on the information gathered, they can decide on the best course of action.Take action: They can execute tasks or provide outputs based on their decisions.Learn and adapt: Many agentic systems have the capability to improve their performance over time.Exploring Agentic Workflows in AI: A Practical Approach with CrewAI, OpeRouter.ai and OpenHermesAgentic Workflows: A Step Forward Towards AGIblog.stackademic.comAgentic workflows refer to the series of steps or processes that these systems follow to complete tasks. In the case of STORM, the agentic workflow includes the retrieval of information, multi-perspective question asking, and synthesis of content.AI AgentsAI agents are the individual components or entities within an agentic system that perform specific tasks. In STORM, multiple AI agents work together to create a comprehensive research and writing tool. These agents may include:Research Agents: Responsible for gathering information from various sources on the internet.Question-Asking Agents: Simulate different perspectives to generate insightful questions about the topic.Expert Agents: Provide answers to the questions posed by the question-asking agents.Synthesis Agents: Compile and organize the gathered information into a coherent article structure.The use of multiple agents allows STORM to approach tasks from various angles, much like a team of human researchers and writers would collaborate on a complex project.STORM as an Agentic SystemSTORM leverages the power of agentic systems to automate and enhance the research and writing process. By employing multiple AI agents in a coordinated workflow, STORM can:Conduct thorough and multi-faceted research on a given topic.Generate diverse perspectives and questions that a human researcher might overlook.Synthesize information in a structured and coherent manner.Adapt its approach based on the specific requirements of each topic or task.This agentic approach enables STORM to produce comprehensive, well-structured content that rivals human-written articles in breadth and depth.How STORM WorksSource: ‚ÄòAssisting in Writing Wikipedia-like Articles From Scratch with LLMs‚Äô paperThe STORM process can be broken down into three main steps: retrieval, multi-perspective question asking, and synthesis.Retrieval: When given a topic, STORM springs into action, deploying its team of AI agents to scour the internet for relevant information. This step involves gathering a wide range of data from various sources.Multi-Perspective Question Asking: STORM simulates conversations where writers carrying different perspectives pose questions to a topic expert. This allows for a deeper exploration of the topic and the formulation of in-depth questions through iterative research. By considering multiple viewpoints, STORM helps writers develop a well-rounded understanding of the subject matter.Synthesis: Finally, STORM synthesizes the gathered data into a coherent, well-organized article. It creates a logical outline and then fills in the content, ensuring that the information is presented in a structured and easy-to-follow manner.For instance, when asked about Karma Yoga, STORM produced a comprehensive wiki covering various aspects such as indian spiritual texts, historical context, etymology, practices and techniques, and others.Benefits of STORM‚Äôs ApproachSTORM‚Äôs approach to content creation offers several key benefits:Well-Structured Content: By using a top-down approach and creating outlines before writing, STORM ensures that the resulting articles are logically organized and easy to navigate.Comprehensive Coverage: The multi-perspective question asking feature allows for a thorough exploration of topics, resulting in articles with comparable breadth and depth to Wikipedia pages.Diverse Viewpoints: By actively seeking out and incorporating diverse perspectives, STORM helps create more balanced and informative content.Time-Saving: Automating the pre-writing stage can significantly reduce the time and effort required to research and structure complex topics.Consistency: STORM‚Äôs systematic approach ensures a consistent level of quality across different topics and articles.Accessing STORMCurrently the easiest way to access is at https://storm.genie.stanford.edu/Just select ‚ÄòNew Session‚Äô and enter the topic to get started.Check out the brainstorming ProcessSource: https://storm.genie.stanford.edu/Generated articles, with TOC and Floating References are saved in ‚ÄòMy Library‚ÄôSource: https://storm.genie.stanford.edu/Setting Up STORMOption 1:For those interested in deploying STORM, the setup process involves several steps:Cloning the GitHub repositoryCreating a Conda environment with Python 3.11Activating the environmentInstalling required dependenciesConfiguring API keys in a secrets.toml fileSTORM requires two API keys to function:An OpenAI API keyA You.com search API key (a free trial is available at https://api.you.com/)Users can run STORM either through a command-line interface or via a user-friendly Streamlit-based UI.Detailed instructions are avaiable at the STORM github page.GitHub - stanford-oval/storm at NAACL-2024-code-backupAn LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations. ‚Ä¶github.comOption 2: Using Google ColabThis provides an opportunity to examine some of the code and understand the workings of STORM.Using OpenAI1. Setting up the Environment:First, we need to install the required packages. The `knowledge-storm` package is essential for using STORM:!pip install knowledge-storm2. Importing Required Libraries:After installation, we import the necessary modules:import osfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigsfrom knowledge_storm.lm import OpenAIModelfrom knowledge_storm.rm import YouRM3. Setting up API Keys and Configurations:os.environ[\"OPENAI_API_KEY\"]=\"your_api_key_here\"os.environ[\"YDC_API_KEY\"]=\"your_YDC_api_key_here\"lm_configs = STORMWikiLMConfigs()openai_kwargs = { \\'api_key\\': os.getenv(\"OPENAI_API_KEY\"), \\'temperature\\': 1.0, \\'top_p\\': 0.9,}4. Configuring Language Models:We set up different models for various STORM components:gpt_35 = OpenAIModel(model=\\'gpt-4o-mini\\', max_tokens=500, **openai_kwargs)gpt_4 = OpenAIModel(model=\\'gpt-4o-mini\\', max_tokens=3000, **openai_kwargs)lm_configs.set_conv_simulator_lm(gpt_35)lm_configs.set_question_asker_lm(gpt_35)lm_configs.set_outline_gen_lm(gpt_4)lm_configs.set_article_gen_lm(gpt_4)lm_configs.set_article_polish_lm(gpt_4)5. Setting up the STORM Runner:We initialize the STORM runner with our configurations:engine_args = STORMWikiRunnerArguments(output_dir=\\'output\\')rm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)runner = STORMWikiRunner(engine_args, lm_configs, rm)6. Running STORM:Finally, we run STORM to generate an article on a given topic:topic = input(\\'Topic: \\')runner.run( topic=topic, do_research=True, do_generate_outline=True, do_generate_article=True, do_polish_article=True,)runner.post_run()runner.summary()Using Claude AI1. Installing Required Packages:!pip install anthropic!pip install knowledge-storm2. Importing Required Libraries:We import the required modules, including Claude-specific ones:import osfrom argparse import ArgumentParserfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigsfrom knowledge_storm.lm import ClaudeModelfrom knowledge_storm.rm import YouRM, BingSearchfrom knowledge_storm.utils import load_api_key3. Setting up Environment Variables:os.environ[\"ANTHROPIC_API_KEY\"] = \"your_anthropic_key_here\"os.environ[\"YDC_API_KEY\"] = \"your_YDC_api_key_here\"4. Configuring STORM with Claude Models:We set up STORM to use various Claude models for different components:lm_configs = STORMWikiLMConfigs()claude_kwargs = { \\'api_key\\': os.getenv(\"ANTHROPIC_API_KEY\"), \\'temperature\\': 1.0, \\'top_p\\': 0.9}conv_simulator_lm = ClaudeModel(model=\\'claude-3-haiku-20240307\\', max_tokens=500, **claude_kwargs)question_asker_lm = ClaudeModel(model=\\'claude-3-sonnet-20240229\\', max_tokens=500, **claude_kwargs)outline_gen_lm = ClaudeModel(model=\\'claude-3-opus-20240229\\', max_tokens=400, **claude_kwargs)article_gen_lm = ClaudeModel(model=\\'claude-3‚Äì5-sonnet-20240620\\', max_tokens=700, **claude_kwargs)article_polish_lm = ClaudeModel(model=\\'claude-3‚Äì5-sonnet-20240620\\', max_tokens=4000, **claude_kwargs)lm_configs.set_conv_simulator_lm(conv_simulator_lm)lm_configs.set_question_asker_lm(question_asker_lm)lm_configs.set_outline_gen_lm(outline_gen_lm)lm_configs.set_article_gen_lm(article_gen_lm)lm_configs.set_article_polish_lm(article_polish_lm)5. Setting up STORM Runner Arguments:We configure the STORM runner arguments:engine_args = STORMWikiRunnerArguments( output_dir=args.output_dir, max_conv_turn=args.max_conv_turn, max_perspective=args.max_perspective, search_top_k=args.search_top_k, max_thread_num=args.max_thread_num,)6. Choosing the Retrieval Model:We set up the retrieval model, either Bing Search or You.com:if args.retriever == \\'bing\\': rm = BingSearch(bing_search_api=os.getenv(\\'BING_SEARCH_API_KEY\\'), k=engine_args.search_top_k)elif args.retriever == \\'you\\': rm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)7. Initializing and Running STORM:Finally, we initialize the STORM runner and execute it:runner = STORMWikiRunner(engine_args, lm_configs, rm)topic = input(\\'Topic: \\')runner.run( topic=topic, do_research=args.do_research, do_generate_outline=args.do_generate_outline, do_generate_article=args.do_generate_article, do_polish_article=args.do_polish_article,)runner.post_run()runner.summary()The above demonstrate different ways to set up and run STORM, one using OpenAI‚Äôs GPT models and another using Anthropic‚Äôs Claude models. Both approaches follow the same general structure but differ in the specific models and configurations used.Output from each is a set of 9 files as under.conversation_log.json direct_gen_outline.txt llm_call_history.jsonl raw_search_results.json run_config.json storm_gen_article.txt storm_gen_article_polished.txt storm_gen_outline.txt url_to_info.jsonNote: ‚Äòstorm_gen_article_polished.txt‚Äô can be taken as the final file with markdown text that displays all the content, but the references do not work.In addition to the above, STORM can access personal datasets using Qdrant but I was unable to get it working.Here are the two files from above in my github repository that utilize the build on examples in STORM Github and a sample set of output files.Medium_Articles/STORM_Stanford_Revolutionary_Research_Tool_Harnessing_the_Power_of_Agents_and_Agenti‚Ä¶All code related to medium articles. Contribute to Laksh-star/Medium_Articles development by creating an account on‚Ä¶github.comFlexibility and Future DevelopmentOne of STORM‚Äôs strengths is its flexibility. While it can utilize OpenAI‚Äôs powerful language models, it‚Äôs not dependent on them. Local setup options are available using VLM with Mistral, and Ollama integration for local models is round the corner.The project has gained significant traction in the developer community, amassing nearly 62,000 stars on GitHub shortly after its release. This popularity is likely to drive further improvements and expansions of STORM‚Äôs capabilities.As STORM continues to evolve, its developers are working on exciting new features. One such feature in the pipeline is a ‚Äúhuman-AI collaboration mode,‚Äù which promises to further enhance the tool‚Äôs utility and user interaction. This could potentially allow for even more nuanced and tailored content creation, combining the strengths of AI with human insight and creativity.ConclusionSTORM represents an important step forward in AI-assisted agentic research, content creation, and writing. By combining the power of multiple AI agents, comprehensive web scraping, coherent content synthesis, and innovative features like multi-perspective question asking, all while maintaining source transparency, STORM has the potential to become an dependable tool for researchers, writers, and knowledge seekers across various fields.The system‚Äôs ability to automate the pre-writing stage, discover diverse perspectives, and create well-structured outlines addresses many of the challenges faced in producing high-quality, comprehensive content. As the project continues to develop and improve, it may well redefine how we approach information gathering, synthesis, and content creation in the digital age, setting new standards for AI-assisted writing and research tools.References[2402.14207] Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models (arxiv.org)GitHub ‚Äî stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.Stackademic \\uf8ffüéìThank you for reading until the end. Before you go:Please consider clapping and following the writer! \\uf8ffüëèFollow us X | LinkedIn | YouTube | DiscordVisit our other platforms: In Plain English | CoFeed | DifferMore content at Stackademic.comAgentsArtificial IntelligencePythonLlmStanford----4FollowPublished in Stackademic40K followers¬∑Last published¬†22 hours agoStackademic is a learning hub for programmers, devs, coders, and engineers. Our goal is to democratize free coding education for the world.FollowFollowWritten by Lakshmi narayana .U461 followers¬∑15 followingAuthor- \\'Directing Business\\' | AI ConsultantFollowResponses (4)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://blog.acer.com/en/discussion/2218/storm-by-stanford-university-the-ai-model-for-academic-and-research-purposes', 'title': 'STORM by Stanford University: The AI Model for Academic and Research Purposes — Acer Corner', 'description': 'Artificial intelligence is a swiftly evolving beast.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\nSTORM by Stanford University: The AI Model for Academic and Research Purposes — Acer Corner\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome› English› AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX Post\\n\\neMail\\n\\n\\n\\n\\nSTORM by Stanford University: The AI Model for Academic and Research Purposes\\n\\n\\n  \\n\\nEdmund_McGowan \\n\\n\\n\\n\\n\\nNovember 2024 \\n edited January 15   in AI \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial intelligence is a swiftly evolving beast. From novel chatbots that come with the dust and are gone with the wind to behemoths like ChatGPT, AI is on the march. STORM by Stanford University is an innovative AI-powered research tool currently making waves in the global academic community and beyond.Since early 2024, this open-source research project has helped many academics, students, and content creators craft articles from scratch. “Articles from scratch?” We hear you ask. Yes, in a nutshell, it can be used to create Wikipedia-style papers, complete with citations in a matter of minutes. Whether you’re interested in AI for schoolwork, or even AI for grad school level writing, STORM can help you on your path to a PhD.Get set, because we’re headed for the eye of the storm to discover the origins of STORM, and the humans behind it. We’ll also go on to discuss its performance and steer you in the direction of the STORM website so you can try it out for yourself.The nature of the STORM?Short for “Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking”, STORM Stanford AI research project is an AI tool that can create Wikipedia style entries faster than you can make a cup of coffee. Let’s be clear, STORM is not your average B- chatbot, it is an A+ gifted-class knowledge creator and research assistant that’s ready to back up its statements and provide citations galore.While AI is often a faceless, authorless corporate beast, the team behind STORM are actually Stanford students and faculty. STORM is created by human members of Stanford’s OVAL team, namely: Yijia Shao, Yucheng Jiang, Theodore A. Kanell, Peter Xu, Omar Khattab, and Monica S. Lam.LLMs (large language models) may be useful for a layman’s general research. But for academics and content creators, they tend to fall short in several areas. Accuracy is king in academia, and LLMs have well publicized limitations in veracity, as well as specificity, and understanding of complex academic topics. What’s more, LLMs are renowned for producing confident, yet incorrect answers that lack citations.The final nail in the coffin for academic use of LLMs is plagiarism. Rapid generation of text comes with the risk that the LLM is simply replicating existing academic sources. While the majority of LLMs create content via retrieval-augmented generation (RAG), STORM takes content creation several steps further to craft accurate, organized answers. Now let’s find out more about the multi-agent conversations behind every STORM search.The multi-agent STORMversation\\n\\n\\n\\n\\n\\nAt time of writing, STORM is powered by Bing Search and Azure OpenAI GPT-4o-mini. This recent upgrade featuring the latest technologies enables STORM to break down the barrier between the excess of accessible information out there, and what an individual is able to assimilate. The “knowledge curation agent” explored in STORM (remember, it is still a research project) aims to provide a solid foundation for knowledge discovery, making in-depth learning possible without the stress of laborious research.Where many LLMs are a letdown, STORM is a success. This is in no small part thanks to STORM’s multi-perspective question asking. Multiple AI agents cooperate in an agentic system, where individual AI agents perform the tasks of content retrieval, multi-perspective question asking, and finally, synthesis of content. Similar in many ways to how a human team would collaborate to research and write an ambitious project, STORM approaches complex tasks from multiple angles to create comprehensive written content that can give human-created articles a run for their money.Various processesSTORM provides users with the option of STORM AI autonomous or Co-STORM (Human-AI collaboration), as well as search engine choices. After inputting your topic to STORM, the platform generally takes a minute or two to generate your article. Once an article is completed, a “See BrainSTORMing Process” option appears above the summary of your article. This neat feature allows users to see the AI agents (editors) and the steps they have taken to contribute to the final article.If you do try STORM, do the good folks at Stanford a favor and provide feedback using the handy feedback box on the web demo. This information, as well as your purpose for writing the article will be securely stored, and not combined with your Google account info.Who can STORM help?\\n\\n\\n\\n\\n\\nIf you’re looking for an AI tool to assist your academic writing, or just AI for school in general, then STORM is certainly worth a try. Here are a few different user groups that may find STORM more useful than regular old LLMs.Academics and researchers can both benefit from using STORM, as it can create structured outlines on complex academic topics that can be used as educational resources. The verification and citation features of STORM are particularly attractive for this cohort.Students today may lack the time to conduct their own research. With STORM, students of all levels can quickly get well-organized notes and summaries in easy to understand Wikipedia style articles, likely a form that they are already familiar with.Content creators with deadlines to meet or day jobs to attend to can rapidly research and organize data on STORM. Verified, fact-based outlines that offer multiple perspectives can be quickly crafted, and updated by users as topics evolve.A STORM in a teacup?As with all AI platforms, STORM is not without its limitations. If you’ve read this far, chances are you’re not plotting to misuse STORM to graduate from school or college. But just in case you were wondering, STORM is not (yet) an AI writing tool that can knock out a 10,000 word college-level dissertation for you. Try out STORM and you will quickly discover that the “research preview” excels in generating Wikipedia-style articles.Similar to Wikipedia, STORM is very good at providing a comprehensive outline of a topic. The Wikipedia-esque sections are useful as foundations to build out from, but may lack specific or detailed information that some users require. This is presumably an aspect of the platform that will be improved, time will tell.\\n\\n\\n\\n\\n\\nAnother issue that may deter or, indeed, attract some users is STORM’s limited safety measures. The potential to generate offensive content is certainly present on STORM, and on behalf of the Stanford Open Virtual Assistant Lab team, we remind you to follow STORM’s guidelines. As with other AI content generators, mistakes are still a likelihood, so double check your info before going to print!Become a rider on the STORM?We trust that you have enjoyed learning about STORM today. Whatever field you work or study in, we believe that STORM is definitely worth a try. If you’re keen to join the STORMversation, simply head over to the STORM homepage. Here you’ll be able to login via your Google account, and experience the research-tool that academics from Glasgow to Gaborone are talking about.Recommended Products\\n\\n\\n\\n\\n\\nSwift 14 AI (Intel Ultra)Buy Now\\n\\n\\n\\n\\n\\nSwift 14 AI (AMD Ryzen)Buy Now \\nEdmund is an English copywriter based in New Taipei City, Taiwan. He is a widely published writer and translator with two decades of experience in the field of bridging linguistic and cultural gaps between Chinese and English.0  \\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\nSocials\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \\nCategories\\n\\nAll Categories106 AI\\n440 PC Tech\\n556 Gaming\\n197 Lifestyle\\n135 Business\\n42 Education\\n48 Green\\n\\n\\n\\n\\nRecent Announcements \\n\\n\\nHands-On with the Predator Triton 14 (2025): Acer’s Compact Gaming Beast\\nWelcome back to an extra-special edition of Acer Corner. Today we’re dialing the number of the beast - the compact gaming beast that is the Acer Predator Triton 14! Unveiled at Computex 2025, the Predator Triton 14 is a next-gen AI PC ready to tackle all of your most demanding creativity tasks while also delivering…\\n\\n\\nSwift Edge 14 (2025) Preview: What’s New in Acer’s Ultralight Laptop for 2025\\nThe Swift Edge 14 is Acer’s brand-new ultralight laptop for 2025 and is perfect for users who crave maximum productivity on the go. This versatile AI laptop is suitable for working from home, hybrid work settings, or downtime, letting users easily achieve a work-life balance. With added features to protect against virtual…\\n\\n\\nWhat is COMPUTEX and What to Expect from Acer at COMPUTEX 2025?\\nIt’s that time of year again, the season of…COMPUTEX! Whether you’re a seasoned computer expo vet, or a newbie bound for the green shores of Formosa to visit COMPUTEX 2025, you’re in the right place. Asia’s leading exhibition of AIoT and startups is back, and ready to showcase the latest, greatest technological innovations…\\n\\n\\n\\n\\nStay Up to Date\\nGet the latest news by subscribing to Acer Corner in Google News.\\n\\n\\nFollow\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://wp.wwu.edu/ajbarse/2025/02/07/an-oncoming-storm-for-ai-academic-writing-stanford-storm/', 'title': 'An Oncoming STORM for AI Academic Writing | Stanford STORM – AJ Barse : Digital Alchemy', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\n\\nAn Oncoming STORM for AI Academic Writing | Stanford STORM – AJ Barse : Digital Alchemy\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAJ Barse : Digital Alchemy\\n\\n\\n\\n\\n\\n\\n\\nAJAbout the AlchemistWWU Learning Systems PhotographyResearchGateBlogEdTech & ResearchAIInstructional DesignPodcastAdobe Podcast (beta)Analog Explorer PodcastBellingham PodcastMaster Diver\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAn Oncoming STORM for AI Academic Writing | Stanford STORM\\n\\n\\n\\nFeb 7, 2025\\n—\\nby\\nAJ\\nin Tech Research\\n\\n\\n\\n\\n\\n\\n“Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking” is a bit of a mouthful, but STORM is a Stanford AI research project that is a “writing system focusing on the\\xa0pre-writing stage\\xa0to generate long, grounded, Wikipedia-like article for a given topic from scratch.” In a single prompt, that is only 20 words or less. \\n\\n\\nEmpty Calorie or Academic-ish writing?\\nMuch like I alluded to two years ago with the idea that AI could help remix or generate Open Educational Resources (OERs), STORM makes me wonder if we will see AI find a place in creating OER? The idea of an AI combined with previously published OERs and connected to Creative Commons and Public Domain resources seems prime for innovation. STORM come close, as it leans toward a more structured way of enhancing and creating Wikipedia articles, while possibly providing a launchpad for aspiring academic writers as well.\\nhttps://storm-project.stanford.edu/research/storm\\nIn widely used AI tools like ChatGPT, long-form writing is often built through iterative prompting, a back-and-forth that refines responses. This alone doesn’t typically make the most accurate results, and often writers might leverage  retrieval-augmented generation (RAG), where external materials ground the AI’s output. Add in tweaks like “no yapping” to cut fluff, and the result is something that resembles an academic writing, but not necessarily is academic writing. As many technologists, instructional designers, or educators will point out, these AI-generated responses often feel like what I like to refer to as empty calorie writing. Writing that while it is technically correct, sometimes well-structured, it often still lacks a lot of the breath and depth that makes human academic writing. Things like DeepSeek, as I’ve mentioned recently, shakes this up slightly with their R1 (or Reason button in ChatGPT) to have the AI show their work or show how their thinking-aloud on the prompt it was given. But again it is still often reads flat or full of empty calorie writing. \\n\\n“STORM models the pre-writing stage by (1) Discovering diverse perspectives in researching the given topic. \\n(2) Simulating conversations where writers carrying different perspectives pose questions to a topic expert grounded on trusted Internet sources.\\n3) Curating the collected information to create an outline.” \\nhttps://storm-project.stanford.edu/research/storm/\\nWrite me an ‘article’ from a 20 word prompt or less?\\nSTORM integrates a multiple AI agent approach. I centers this automated slef-itterating conversation into a structured outline that then becomes a  Wikipedia-style format article without any back-and-forth with the user. What this means is that the AI engages in self-dialogue, using specialized “editor” agents to simulate the reasoning process, through its own think aloud similar to DeepSeek R1  or Reason in ChatGPT. But then it follows a “Perspective-Guided Question Asking” phase, mining diverse viewpoints from relevant Wikipedia articles and more academic style resources, then conducts internal follow-up conversations using a retrieval-augmented question-answering process. In short it researches, asks itself what it just researched, then poses why it is important and then synthesizes. This part removes the writer altogether from correcting or asking more questions as most are used to in something like ChatGPT. STORM calls this method it’s “BrainSTORMing Process,” which allows users to trace the AI’s thought process to see it’s rational and process to create its output. \\nIt is clear that Stanford is trying to design this project for complex, multi-faceted topics and support the Wikipedia community. But in the hands of a time crunched undergrad, or a graduate student not knowing what to research; it could provide some structure as a jumping off point for their writing, STORM appears to be a compelling project, and could devlop into an interesting academic writing tool complete with citations, references, and weblinks with its writing. Providing another avenue for a strong foundation for someone to start academic writing; or a wrong-turn of misuse in academic dishonesty. Although it’s references that I’ve seen it use in my test prompts are much more academic in background, I haven’t seen it (nor do I know if it can) pull from actual academic journal or peer-reviewed articles. Which again in the hands of someone who is trying to learn and exercise academic writing is counter productive. \\nThe resulting output, however, is pretty compelling and much closer to what academic writing is than what I see typically out of a pure ChatGPT output. It generates the generated article in-browser, or can be exported as a multipage PDF with a linked table of contents. Again, a system like this could be the making of a practical tool for preliminary research and pre-writing (if cited and permitted by the guidelines of an academic institution’s academic honesty policy), but I wouldn’t risk a final dissertation grade on its output. \\nSample “Article” \\nBased on the 20 word prompt, you can be the judge of STORM’s output. I purposely chose the topic of neurological connections and the juxtaposition of pop culture references to see what sources it pulled from in its “brainstorming.”\\n \\n\\n\\n\\n\\nLoading…\\n\\n\\n\\n\\n\\nTaking too long?\\n\\n\\n\\n Reload document\\t\\t\\t\\t\\t\\n|\\n\\n Open in new tab\\t\\t\\t\\t\\t\\n\\n\\n\\n\\nCO-STORM\\nThe other half of their platform is CO-STORM, which looks to be a more roundtable conversation model of STORM. However, at the time of writing, that part of the system is currently down. \\n\\n\\n\\n\\n\\n\\n\\n\\n←Previous:  Call into your own personal show about your notes | Google Notebook LM\\nNext:  An Accessibility Odyssey: Preparing Faculty for WCAG Compliance Before 2026→\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAJ Barse : Digital Alchemy\\nal·che·mist /ˈalkəməst/ : \"a person who seeks the power to transform things for the better…real or imagined \"\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\nTLT | Learning SystemsTLCo-Op\\n\\n\\nSocial\\nLinkedInInstagramAnalog Explorer\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tType your email…\\t\\t\\t\\t\\t\\t\\t\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\t\\t\\t\\t\\t\\t\\t\\tSubscribe\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\nCreatively designed in the ❤️ PNW\\n\\n\\n\\n\\n\\n\\n \\n\\n\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLoading Comments...\\n\\n\\n\\n\\xa0\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tYou must be logged in to post a comment.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
            "                               Document(metadata={'source': 'https://github.com/stanford-oval/storm', 'title': 'GitHub - stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.', 'description': 'An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations. - stanford-oval/storm', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub - stanford-oval/storm: An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            GitHub Copilot\\n          \\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            GitHub Models\\n              \\n                New\\n              \\n\\n        Manage and compare prompts\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            GitHub Advanced Security\\n          \\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Actions\\n          \\n        Automate any workflow\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Codespaces\\n          \\n        Instant dev environments\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Issues\\n          \\n        Plan and track work\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Code Review\\n          \\n        Manage code changes\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Discussions\\n          \\n        Collaborate outside of code\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Code Search\\n          \\n        Find more, search less\\n      \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Why GitHub\\n\\n    \\n\\n\\n\\n      All features\\n\\n    \\n\\n\\n\\n      Documentation\\n\\n    \\n\\n\\n\\n\\n\\n      GitHub Skills\\n\\n    \\n\\n\\n\\n\\n\\n      Blog\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Solutions\\n        \\n\\n\\n\\n\\n\\n\\nBy company size\\n\\n\\n\\n      Enterprises\\n\\n    \\n\\n\\n\\n      Small and medium teams\\n\\n    \\n\\n\\n\\n      Startups\\n\\n    \\n\\n\\n\\n      Nonprofits\\n\\n    \\n\\n\\n\\n\\nBy use case\\n\\n\\n\\n      DevSecOps\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      CI/CD\\n\\n    \\n\\n\\n\\n      View all use cases\\n\\n    \\n\\n\\n\\n\\n\\n\\nBy industry\\n\\n\\n\\n      Healthcare\\n\\n    \\n\\n\\n\\n      Financial services\\n\\n    \\n\\n\\n\\n      Manufacturing\\n\\n    \\n\\n\\n\\n      Government\\n\\n    \\n\\n\\n\\n      View all industries\\n\\n    \\n\\n\\n\\n\\n\\n\\n              View all solutions\\n              \\n\\n\\n \\n\\n\\n\\n\\n        Resources\\n        \\n\\n\\n\\n\\n\\n\\nTopics\\n\\n\\n\\n      AI\\n\\n    \\n\\n\\n\\n      DevOps\\n\\n    \\n\\n\\n\\n      Security\\n\\n    \\n\\n\\n\\n      Software Development\\n\\n    \\n\\n\\n\\n      View all\\n\\n    \\n\\n\\n\\n\\n\\n\\nExplore\\n\\n\\n\\n      Learning Pathways\\n\\n    \\n\\n\\n\\n\\n\\n      Events & Webinars\\n\\n    \\n\\n\\n\\n\\n\\n      Ebooks & Whitepapers\\n\\n    \\n\\n\\n\\n      Customer Stories\\n\\n    \\n\\n\\n\\n      Partners\\n\\n    \\n\\n\\n\\n\\n\\n      Executive Insights\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n        Open Source\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            GitHub Sponsors\\n          \\n        Fund open source developers\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            The ReadME Project\\n          \\n        GitHub community articles\\n      \\n\\n\\n\\n\\nRepositories\\n\\n\\n\\n      Topics\\n\\n    \\n\\n\\n\\n      Trending\\n\\n    \\n\\n\\n\\n      Collections\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n        Enterprise\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Enterprise platform\\n          \\n        AI-powered developer platform\\n      \\n\\n\\n\\n\\nAvailable add-ons\\n\\n\\n\\n\\n\\n\\n\\n\\n            GitHub Advanced Security\\n          \\n        Enterprise-grade security features\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Copilot for business\\n          \\n        Enterprise-grade AI features\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n            Premium Support\\n          \\n        Enterprise-grade 24/7 support\\n      \\n\\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch or jump to...\\n\\n\\n\\n\\n\\n\\n\\nSearch code, repositories, users, issues, pull requests...\\n\\n \\n\\n\\n\\n\\n        Search\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClear\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nSearch syntax tips \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Provide feedback\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nWe read every piece of feedback, and take your input very seriously.\\n\\n\\nInclude my email address so I can be contacted\\n\\n\\n     Cancel\\n\\n    Submit feedback\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Saved searches\\n      \\nUse saved searches to filter your results more quickly\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nName\\n\\n\\n\\n\\n\\n\\nQuery\\n\\n\\n\\n            To see all available qualifiers, see our documentation.\\n          \\n \\n\\n\\n\\n\\n\\n     Cancel\\n\\n    Create saved search\\n\\n\\n\\n\\n\\n\\n\\n\\n                Sign in\\n              \\n\\n\\n                Sign up\\n              \\n\\n\\n \\n\\n\\nAppearance settings\\n\\n\\n\\nReseting focus\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\n \\n\\n\\nDismiss alert\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        stanford-oval\\n \\n/\\n\\nstorm\\n\\nPublic\\n\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n \\n\\nFork\\n    2.2k\\n\\n\\n\\n\\n \\n\\n\\n          Star\\n 24.3k\\n\\n\\n\\n\\n\\n\\n\\n\\n        An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n      \\n\\n\\n\\n\\n\\nstorm.genie.stanford.edu\\n\\n\\nLicense\\n\\n\\n\\n\\n\\n     MIT license\\n    \\n\\n\\n\\n\\n\\n\\n24.3k\\n          stars\\n \\n\\n\\n\\n2.2k\\n          forks\\n \\n\\n\\n\\nBranches\\n \\n\\n\\n\\nTags\\n \\n\\n\\n\\nActivity\\n \\n\\n\\n\\n \\n\\n\\n          Star\\n\\n\\n\\n\\n \\n\\nNotifications\\n You must be signed in to change notification settings\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCode\\n\\n\\n\\n\\n\\n\\n\\nIssues\\n45\\n\\n\\n\\n\\n\\n\\nPull requests\\n23\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\n\\n\\n\\n\\n\\nProjects\\n0\\n\\n\\n\\n\\n\\n\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\nInsights\\n\\n\\n\\n \\n\\n \\n\\n\\nAdditional navigation options\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Code\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Issues\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Pull requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Actions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Projects\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Security\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Insights\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nstanford-oval/storm\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   ¬†mainBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit¬†History236 Commits.github.github¬†¬†assetsassets¬†¬†examplesexamples¬†¬†frontend/demo_lightfrontend/demo_light¬†¬†knowledge_stormknowledge_storm¬†¬†.gitignore.gitignore¬†¬†.pre-commit-config.yaml.pre-commit-config.yaml¬†¬†CONTRIBUTING.mdCONTRIBUTING.md¬†¬†LICENSELICENSE¬†¬†README.mdREADME.md¬†¬†requirements.txtrequirements.txt¬†¬†setup.pysetup.py¬†¬†View all filesRepository files navigationREADMEMIT license\\n\\n\\nSTORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking\\n\\n| Research preview | STORM Paper| Co-STORM Paper  | Website |\\n\\n**Latest News** \\uf8ffüî•\\n\\n\\n[2025/01] We add litellm integration for language models and embedding models in knowledge-storm v1.1.0.\\n\\n\\n[2024/09] Co-STORM codebase is now released and integrated into knowledge-storm python package v1.0.0. Run pip install knowledge-storm --upgrade to check it out.\\n\\n\\n[2024/09] We introduce collaborative STORM (Co-STORM) to support human-AI collaborative knowledge curation! Co-STORM Paper has been accepted to EMNLP 2024 main conference.\\n\\n\\n[2024/07] You can now install our package with pip install knowledge-storm!\\n\\n\\n[2024/07] We add VectorRM to support grounding on user-provided documents, complementing existing support of search engines (YouRM, BingSearch). (check out #58)\\n\\n\\n[2024/07] We release demo light for developers a minimal user interface built with streamlit framework in Python, handy for local development and demo hosting (checkout #54)\\n\\n\\n[2024/06] We will present STORM at NAACL 2024! Find us at Poster Session 2 on June 17 or check our presentation material.\\n\\n\\n[2024/05] We add Bing Search support in rm.py. Test STORM with GPT-4o - we now configure the article generation part in our demo using GPT-4o model.\\n\\n\\n[2024/04] We release refactored version of STORM codebase! We define interface for STORM pipeline and reimplement STORM-wiki (check out src/storm_wiki) to demonstrate how to instantiate the pipeline. We provide API to support customization of different language models and retrieval/search integration.\\n\\n\\n\\nOverview (Try STORM now!)\\n\\n\\n\\nSTORM is a LLM system that writes Wikipedia-like articles from scratch based on Internet search. Co-STORM further enhanced its feature by enabling human to collaborative LLM system to support more aligned and preferred information seeking and knowledge curation.\\nWhile the system cannot produce publication-ready articles that often require a significant number of edits, experienced Wikipedia editors have found it helpful in their pre-writing stage.\\nMore than 70,000 people have tried our live research preview. Try it out to see how STORM can help your knowledge exploration journey and please provide feedback to help us improve the system \\uf8ffüôè!\\nHow STORM & Co-STORM works\\nSTORM\\nSTORM breaks down generating long articles with citations into two steps:\\n\\nPre-writing stage: The system conducts Internet-based research to collect references and generates an outline.\\nWriting stage: The system uses the outline and references to generate the full-length article with citations.\\n\\n\\n\\n\\nSTORM identifies the core of automating the research process as automatically coming up with good questions to ask. Directly prompting the language model to ask questions does not work well. To improve the depth and breadth of the questions, STORM adopts two strategies:\\n\\nPerspective-Guided Question Asking: Given the input topic, STORM discovers different perspectives by surveying existing articles from similar topics and uses them to control the question-asking process.\\nSimulated Conversation: STORM simulates a conversation between a Wikipedia writer and a topic expert grounded in Internet sources to enable the language model to update its understanding of the topic and ask follow-up questions.\\n\\nCO-STORM\\nCo-STORM proposes a collaborative discourse protocol which implements a turn management policy to support smooth collaboration among\\n\\nCo-STORM LLM experts: This type of agent generates answers grounded on external knowledge sources and/or raises follow-up questions based on the discourse history.\\nModerator: This agent generates thought-provoking questions inspired by information discovered by the retriever but not directly used in previous turns. Question generation can also be grounded!\\nHuman user: The human user will take the initiative to either (1) observe the discourse to gain deeper understanding of the topic, or (2) actively engage in the conversation by injecting utterances to steer the discussion focus.\\n\\n\\n\\n\\nCo-STORM also maintains a dynamic updated mind map, which organize collected information into a hierarchical concept structure, aiming to build a shared conceptual space between the human user and the system. The mind map has been proven to help reduce the mental load when the discourse goes long and in-depth.\\nBoth STORM and Co-STORM are implemented in a highly modular way using dspy.\\nInstallation\\nTo install the knowledge storm library, use pip install knowledge-storm.\\nYou could also install the source code which allows you to modify the behavior of STORM engine directly.\\n\\n\\nClone the git repository.\\ngit clone https://github.com/stanford-oval/storm.git\\ncd storm\\n\\n\\nInstall the required packages.\\nconda create -n storm python=3.11\\nconda activate storm\\npip install -r requirements.txt\\n\\n\\nAPI\\nCurrently, our package support:\\n\\nLanguage model components: All language models supported by litellm as listed here\\nEmbedding model components: All embedding models supported by litellm as listed here\\nretrieval module components: YouRM, BingSearch, VectorRM, SerperRM, BraveRM, SearXNG, DuckDuckGoSearchRM, TavilySearchRM, GoogleSearch, and AzureAISearch as\\n\\n\\uf8ffüåü PRs for integrating more search engines/retrievers into knowledge_storm/rm.py are highly appreciated!\\nBoth STORM and Co-STORM are working in the information curation layer, you need to set up the information retrieval module and language model module to create their Runner classes respectively.\\nSTORM\\nThe STORM knowledge curation engine is defined as a simple Python STORMWikiRunner class. Here is an example of using You.com search engine and OpenAI models.\\nimport os\\nfrom knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs\\nfrom knowledge_storm.lm import LitellmModel\\nfrom knowledge_storm.rm import YouRM\\n\\nlm_configs = STORMWikiLMConfigs()\\nopenai_kwargs = {\\n    \\'api_key\\': os.getenv(\"OPENAI_API_KEY\"),\\n    \\'temperature\\': 1.0,\\n    \\'top_p\\': 0.9,\\n}\\n# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.\\n# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.\\n# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.\\ngpt_35 = LitellmModel(model=\\'gpt-3.5-turbo\\', max_tokens=500, **openai_kwargs)\\ngpt_4 = LitellmModel(model=\\'gpt-4o\\', max_tokens=3000, **openai_kwargs)\\nlm_configs.set_conv_simulator_lm(gpt_35)\\nlm_configs.set_question_asker_lm(gpt_35)\\nlm_configs.set_outline_gen_lm(gpt_4)\\nlm_configs.set_article_gen_lm(gpt_4)\\nlm_configs.set_article_polish_lm(gpt_4)\\n# Check out the STORMWikiRunnerArguments class for more configurations.\\nengine_args = STORMWikiRunnerArguments(...)\\nrm = YouRM(ydc_api_key=os.getenv(\\'YDC_API_KEY\\'), k=engine_args.search_top_k)\\nrunner = STORMWikiRunner(engine_args, lm_configs, rm)\\nThe STORMWikiRunner instance can be evoked with the simple run method:\\ntopic = input(\\'Topic: \\')\\nrunner.run(\\n    topic=topic,\\n    do_research=True,\\n    do_generate_outline=True,\\n    do_generate_article=True,\\n    do_polish_article=True,\\n)\\nrunner.post_run()\\nrunner.summary()\\n\\ndo_research: if True, simulate conversations with difference perspectives to collect information about the topic; otherwise, load the results.\\ndo_generate_outline: if True, generate an outline for the topic; otherwise, load the results.\\ndo_generate_article: if True, generate an article for the topic based on the outline and the collected information; otherwise, load the results.\\ndo_polish_article: if True, polish the article by adding a summarization section and (optionally) removing duplicate content; otherwise, load the results.\\n\\nCo-STORM\\nThe Co-STORM knowledge curation engine is defined as a simple Python CoStormRunner class. Here is an example of using Bing search engine and OpenAI models.\\nfrom knowledge_storm.collaborative_storm.engine import CollaborativeStormLMConfigs, RunnerArgument, CoStormRunner\\nfrom knowledge_storm.lm import LitellmModel\\nfrom knowledge_storm.logging_wrapper import LoggingWrapper\\nfrom knowledge_storm.rm import BingSearch\\n\\n# Co-STORM adopts the same multi LM system paradigm as STORM \\nlm_config: CollaborativeStormLMConfigs = CollaborativeStormLMConfigs()\\nopenai_kwargs = {\\n    \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\\n    \"api_provider\": \"openai\",\\n    \"temperature\": 1.0,\\n    \"top_p\": 0.9,\\n    \"api_base\": None,\\n} \\nquestion_answering_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)\\ndiscourse_manage_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)\\nutterance_polishing_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=2000, **openai_kwargs)\\nwarmstart_outline_gen_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)\\nquestion_asking_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=300, **openai_kwargs)\\nknowledge_base_lm = LitellmModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)\\n\\nlm_config.set_question_answering_lm(question_answering_lm)\\nlm_config.set_discourse_manage_lm(discourse_manage_lm)\\nlm_config.set_utterance_polishing_lm(utterance_polishing_lm)\\nlm_config.set_warmstart_outline_gen_lm(warmstart_outline_gen_lm)\\nlm_config.set_question_asking_lm(question_asking_lm)\\nlm_config.set_knowledge_base_lm(knowledge_base_lm)\\n\\n# Check out the Co-STORM\\'s RunnerArguments class for more configurations.\\ntopic = input(\\'Topic: \\')\\nrunner_argument = RunnerArgument(topic=topic, ...)\\nlogging_wrapper = LoggingWrapper(lm_config)\\nbing_rm = BingSearch(bing_search_api_key=os.environ.get(\"BING_SEARCH_API_KEY\"),\\n                     k=runner_argument.retrieve_top_k)\\ncostorm_runner = CoStormRunner(lm_config=lm_config,\\n                               runner_argument=runner_argument,\\n                               logging_wrapper=logging_wrapper,\\n                               rm=bing_rm)\\nThe CoStormRunner instance can be evoked with the warmstart() and step(...) methods.\\n# Warm start the system to build shared conceptual space between Co-STORM and users\\ncostorm_runner.warm_start()\\n\\n# Step through the collaborative discourse \\n# Run either of the code snippets below in any order, as many times as you\\'d like\\n# To observe the conversation:\\nconv_turn = costorm_runner.step()\\n# To inject your utterance to actively steer the conversation:\\ncostorm_runner.step(user_utterance=\"YOUR UTTERANCE HERE\")\\n\\n# Generate report based on the collaborative discourse\\ncostorm_runner.knowledge_base.reorganize()\\narticle = costorm_runner.generate_report()\\nprint(article)\\nQuick Start with Example Scripts\\nWe provide scripts in our examples folder as a quick start to run STORM and Co-STORM with different configurations.\\nWe suggest using secrets.toml to set up the API keys. Create a file secrets.toml under the root directory and add the following content:\\n# ============ language model configurations ============ \\n# Set up OpenAI API key.\\nOPENAI_API_KEY=\"your_openai_api_key\"\\n# If you are using the API service provided by OpenAI, include the following line:\\nOPENAI_API_TYPE=\"openai\"\\n# If you are using the API service provided by Microsoft Azure, include the following lines:\\nOPENAI_API_TYPE=\"azure\"\\nAZURE_API_BASE=\"your_azure_api_base_url\"\\nAZURE_API_VERSION=\"your_azure_api_version\"\\n# ============ retriever configurations ============ \\nBING_SEARCH_API_KEY=\"your_bing_search_api_key\" # if using bing search\\n# ============ encoder configurations ============ \\nENCODER_API_TYPE=\"openai\" # if using openai encoder\\nSTORM examples\\nTo run STORM with gpt family models with default configurations:\\nRun the following command.\\npython examples/storm_examples/run_storm_wiki_gpt.py \\\\\\n    --output-dir $OUTPUT_DIR \\\\\\n    --retriever bing \\\\\\n    --do-research \\\\\\n    --do-generate-outline \\\\\\n    --do-generate-article \\\\\\n    --do-polish-article\\nTo run STORM using your favorite language models or grounding on your own corpus: Check out examples/storm_examples/README.md.\\nCo-STORM examples\\nTo run Co-STORM with gpt family models with default configurations,\\n\\nAdd BING_SEARCH_API_KEY=\"xxx\" and ENCODER_API_TYPE=\"xxx\" to secrets.toml\\nRun the following command\\n\\npython examples/costorm_examples/run_costorm_gpt.py \\\\\\n    --output-dir $OUTPUT_DIR \\\\\\n    --retriever bing\\nCustomization of the Pipeline\\nSTORM\\nIf you have installed the source code, you can customize STORM based on your own use case. STORM engine consists of 4 modules:\\n\\nKnowledge Curation Module: Collects a broad coverage of information about the given topic.\\nOutline Generation Module: Organizes the collected information by generating a hierarchical outline for the curated knowledge.\\nArticle Generation Module: Populates the generated outline with the collected information.\\nArticle Polishing Module: Refines and enhances the written article for better presentation.\\n\\nThe interface for each module is defined in knowledge_storm/interface.py, while their implementations are instantiated in knowledge_storm/storm_wiki/modules/*. These modules can be customized according to your specific requirements (e.g., generating sections in bullet point format instead of full paragraphs).\\nCo-STORM\\nIf you have installed the source code, you can customize Co-STORM based on your own use case\\n\\nCo-STORM introduces multiple LLM agent types (i.e. Co-STORM experts and Moderator). LLM agent interface is defined in knowledge_storm/interface.py , while its implementation is instantiated in knowledge_storm/collaborative_storm/modules/co_storm_agents.py. Different LLM agent policies can be customized.\\nCo-STORM introduces a collaborative discourse protocol, with its core function centered on turn policy management. We provide an example implementation of turn policy management through DiscourseManager in knowledge_storm/collaborative_storm/engine.py. It can be customized and further improved.\\n\\nDatasets\\nTo facilitate the study of automatic knowledge curation and complex information seeking, our project releases the following datasets:\\nFreshWiki\\nThe FreshWiki Dataset is a collection of 100 high-quality Wikipedia articles focusing on the most-edited pages from February 2022 to September 2023. See Section 2.1 in STORM paper for more details.\\nYou can download the dataset from huggingface directly. To ease the data contamination issue, we archive the source code for the data construction pipeline that can be repeated at future dates.\\nWildSeek\\nTo study users‚Äô interests in complex information seeking tasks in the wild, we utilized data collected from the web research preview to create the WildSeek dataset. We downsampled the data to ensure the diversity of the topics and the quality of the data. Each data point is a pair comprising a topic and the user‚Äôs goal for conducting deep search on the topic.  For more details, please refer to Section 2.2 and Appendix A of Co-STORM paper.\\nThe WildSeek dataset is available here.\\nReplicate STORM & Co-STORM paper result\\nFor STORM paper experiments, please switch to the branch NAACL-2024-code-backup here.\\nFor Co-STORM paper experiments, please switch to the branch EMNLP-2024-code-backup (placeholder for now, will be updated soon).\\nRoadmap & Contributions\\nOur team is actively working on:\\n\\nHuman-in-the-Loop Functionalities: Supporting user participation in the knowledge curation process.\\nInformation Abstraction: Developing abstractions for curated information to support presentation formats beyond the Wikipedia-style report.\\n\\nIf you have any questions or suggestions, please feel free to open an issue or pull request. We welcome contributions to improve the system and the codebase!\\nContact person: Yijia Shao and Yucheng Jiang\\nAcknowledgement\\nWe would like to thank Wikipedia for its excellent open-source content. The FreshWiki dataset is sourced from Wikipedia, licensed under the Creative Commons Attribution-ShareAlike (CC BY-SA) license.\\nWe are very grateful to Michelle Lam for designing the logo for this project and Dekun Ma for leading the UI development.\\nThanks to Vercel for their support of open-source software\\nCitation\\nPlease cite our paper if you use this code or part of it in your work:\\n@inproceedings{jiang-etal-2024-unknown,\\n    title = \"Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations\",\\n    author = \"Jiang, Yucheng  and\\n      Shao, Yijia  and\\n      Ma, Dekun  and\\n      Semnani, Sina  and\\n      Lam, Monica\",\\n    editor = \"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\",\\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2024\",\\n    address = \"Miami, Florida, USA\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.emnlp-main.554/\",\\n    doi = \"10.18653/v1/2024.emnlp-main.554\",\\n    pages = \"9917--9955\",\\n}\\n\\n@inproceedings{shao-etal-2024-assisting,\\n    title = \"Assisting in Writing {W}ikipedia-like Articles From Scratch with Large Language Models\",\\n    author = \"Shao, Yijia  and\\n      Jiang, Yucheng  and\\n      Kanell, Theodore  and\\n      Xu, Peter  and\\n      Khattab, Omar  and\\n      Lam, Monica\",\\n    editor = \"Duh, Kevin  and\\n      Gomez, Helena  and\\n      Bethard, Steven\",\\n    booktitle = \"Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\\n    month = jun,\\n    year = \"2024\",\\n    address = \"Mexico City, Mexico\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.naacl-long.347/\",\\n    doi = \"10.18653/v1/2024.naacl-long.347\",\\n    pages = \"6252--6278\",\\n}\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n        An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.\\n      \\n\\n\\n\\n\\n\\nstorm.genie.stanford.edu\\n\\n\\nTopics\\n\\n\\n\\n  nlp\\n\\n\\n  naacl\\n\\n\\n  report-generation\\n\\n\\n  knowledge-curation\\n\\n\\n  large-language-models\\n\\n\\n  retrieval-augmented-generation\\n\\n\\n  agentic-rag\\n\\n\\n  emnlp2024\\n\\n\\n  deep-research\\n\\n\\n\\nResources\\n\\n\\n\\n\\n\\n        Readme\\n \\nLicense\\n\\n\\n\\n\\n\\n     MIT license\\n    \\n\\n\\n\\n\\n\\n\\n\\nActivity \\n\\n\\n\\n\\nCustom properties \\nStars\\n\\n\\n\\n\\n24.3k\\n      stars \\nWatchers\\n\\n\\n\\n\\n176\\n      watching \\nForks\\n\\n\\n\\n\\n2.2k\\n      forks \\n\\n\\n          Report repository\\n \\n\\n\\n\\n\\n\\n\\nReleases\\n      6\\n\\n\\n\\n\\n\\n\\nv1.1.0 Compatible with LiteLLM API\\n\\n          Latest\\n \\nJan 23, 2025\\n\\n \\n+ 5 releases\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContributors\\n      24\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n+ 10 contributors\\n\\n\\n\\n\\nLanguages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPython\\n100.0%\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\n\\n\\n\\n\\n\\n\\n        © 2025 GitHub,\\xa0Inc.\\n      \\n\\n\\nFooter navigation\\n\\n\\nTerms\\n\\n\\nPrivacy\\n\\n\\nSecurity\\n\\n\\nStatus\\n\\n\\nDocs\\n\\n\\nContact\\n\\n\\n\\n\\n      Manage cookies\\n    \\n\\n\\n\\n\\n\\n      Do not share my personal information\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    You can‚Äôt perform that action at this time.\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]}}\n",
            "{'answer_question': {'answer': '스탠포드 STORM은 여러 AI 에이전트가 협력하여 콘텐츠 검색, 다각적인 질문, '\n",
            "                               '콘텐츠 종합 등의 작업을 수행하는 멀티 에이전트 시스템을 사용합니다.'}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "# Streaming 참고\n",
        "# https://langchain-ai.github.io/langgraph/concepts/streaming/#streaming-graph-outputs-stream-and-astream\n",
        "\n",
        "for data in graph.stream({'question': '스탠포드의 멀티 에이전트 STORM 구조가 뭐야?'},\n",
        "                         stream_mode='updates'):\n",
        "    pprint.pprint(data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
