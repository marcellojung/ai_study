{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZFUS8xlsVLX"
      },
      "source": [
        "# 1장 OpenAI API 키 설정 및 기본 사용법\n",
        "이 장에서는 OpenAI API 키를 설정하고 간단한 텍스트 생성을 수행하는 방법에 대해 설명합니다. 이 과정은 Python 환경에서 OpenAI의 GPT 모델을 활용하기 위한 기본적인 설정입니다.\n",
        "\n",
        "## 1. 라이브러리 설치 및 API 키 설정\n",
        "OpenAI API를 사용하기 위해 필요한 라이브러리를 설치하고 API 키를 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMMwes3lakP"
      },
      "source": [
        "💡 1. 무엇을 하고 싶은가?\n",
        "\n",
        "우리는 **OpenAI의 인공지능(GPT 모델)**에게 질문을 던지고, 거기에 대한 자연스러운 답변을 생성받고자 합니다. 마치 스마트폰의 챗봇이나 Siri에게 질문하듯, \"아침에 일어나서 뭐해?\"라고 물으면 AI가 문장을 만들어주는 구조입니다.\n",
        "\n",
        "\n",
        "🧰 2. 어떻게 작동하는가? (과정 흐름)\n",
        "OpenAI 라이브러리 설치\n",
        "→ GPT 모델을 쓸 수 있게 컴퓨터에 도구 설치\n",
        "\n",
        "API 키 입력\n",
        "→ OpenAI와 통신할 수 있도록 열쇠(API Key)를 입력함\n",
        "\n",
        "모델에게 질문(prompt)을 보냄\n",
        "→ 예: \"배고플 때 먹는 것은?\" 같은 문장을 보냄\n",
        "\n",
        "모델이 답변을 생성\n",
        "→ 예: \"라면을 먹어요\"와 같은 문장을 AI가 만들어 줌\n",
        "\n",
        "결과 출력\n",
        "→ 모델이 만든 문장을 우리가 화면에서 볼 수 있음\n",
        "\n",
        "\n",
        "🧠 3. 무엇을 실험하고 있나? (파라미터의 개념 실험)\n",
        "AI의 답변을 더 길게, 창의적으로, 덜 반복되게 만들기 위해 다양한 설정값들을 실험하고 있습니다.\n",
        "\n",
        "temperature: 창의성 조절 (0이면 진지, 1이면 창의적)\n",
        "\n",
        "max_tokens: 답변 길이 제한\n",
        "\n",
        "stop: 특정 단어가 나오면 답변 멈추기\n",
        "\n",
        "top_p: 확률 기준으로 단어 선택\n",
        "\n",
        "frequency_penalty: 단어 반복 억제\n",
        "\n",
        "presence_penalty: 똑같은 문장/단어 피하기\n",
        "\n",
        "이런 조합을 바꾸며 모델이 어떻게 반응하는지 실험하는 것이 핵심입니다.\n",
        "\n",
        "🎯 4. 왜 이것을 배우는가?\n",
        "챗봇 만들기\n",
        "\n",
        "자동 글쓰기 도구 만들기\n",
        "\n",
        "대화형 인터페이스 구현하기\n",
        "\n",
        "AI와 협업하는 앱 개발\n",
        "\n",
        "이 실습은 위처럼 현실 세계에서 쓰이는 AI 활용법의 가장 첫걸음입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSBWJt_qsVLY",
        "outputId": "72e386da-36eb-45a0-9de2-c328c22ec729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.1\n",
            "    Uninstalling openai-1.78.1:\n",
            "      Successfully uninstalled openai-1.78.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install openai==0.28 tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvqyqGTisVLZ"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈 불러오기\n",
        "import openai  # [포인트] OpenAI의 GPT 모델을 사용하기 위한 공식 라이브러리입니다.\n",
        "import os      # [포인트] 환경 변수 설정을 위해 사용하는 파이썬 내장 모듈입니다. API 키를 숨길 수 있어 보안상 유리합니다.\n",
        "\n",
        "# API 키를 환경 변수에 저장하여 보안 강화\n",
        "# [예시] 자물쇠로 잠긴 금고에 API 키를 보관하는 느낌입니다. 키를 코드에 직접 쓰지 않아 보안이 향상됩니다.\n",
        "# os.environ['OPENAI_API_KEY'] = \"\"  # [포인트] 실제 API 키를 환경 변수 OPENAI_API_KEY에 저장합니다.\n",
        "# openai.api_key = os.getenv('OPENAI_API_KEY')  # [포인트] 환경 변수에서 API 키를 불러와 openai 모듈에 등록합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOVWPB6nsVLZ",
        "outputId": "dbaa9869-a569-4a5e-802d-29ab1e862bc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저는 일어나서 일주일 계획을 세우고, 하루에 할 일 목록을 작성합니다. 그리고 먼저 일어나서 운동을 하고 샤워를 합니다. 그 다음으로 아침 식사를 하고, 뉴스나 이메일을 확인합니다. 그리고 출근 준비를 하고 집을 나서서 출근합니다. 출근해서 업무를 시작하기 전에 일주일 계획을 다시 한번 확인하고, 오늘의 우\n"
          ]
        }
      ],
      "source": [
        "# OpenAI 모델을 사용해 텍스트 생성하기\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # [포인트] 사용할 모델 이름 지정. 대화형은 아니고, 단일 지시문에 응답하는 모델입니다.\n",
        "    prompt=\"아침에 일어나서 하는 일에 대해 설명해 주세요.\",  # [포인트] 모델에게 요청할 질문 또는 명령문입니다. 이 내용을 기반으로 AI가 답변을 생성합니다.\n",
        "    temperature=0.7,  # [포인트] 창의성 조절 값. 0에 가까울수록 정해진 답변, 1에 가까울수록 창의적인 답변이 나옵니다.\n",
        "    max_tokens=150  # [포인트] 생성할 텍스트의 최대 길이. 토큰은 단어 조각(띄어쓰기 포함)이며, 150이면 꽤 긴 문장 생성 가능.\n",
        ")\n",
        "\n",
        "# 생성된 응답 출력하기\n",
        "print(response.choices[0].text.strip())  # [포인트] 응답 결과의 텍스트 부분을 꺼내고, 앞뒤 공백을 제거해서 출력합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GACY3PhscP6"
      },
      "source": [
        "# OpenAI 모델 사용법 및 기본 개념\n",
        "OpenAI의 모델들은 `Completion`과 `Chat` 두 가지 주요 유형으로 나뉩니다. 각각의 모델을 어떻게 사용하는지에 대해 알아보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_0jRAnYsfhb"
      },
      "source": [
        "\n",
        "## 모델 선택 및 API 기본 설정\n",
        "OpenAI의 LLM 모델은 크게 두 가지로 구분됩니다: `Completion` 모델과 `Chat` 모델입니다. 이 모델들은 각각의 특성과 사용 방법에 따라 선택됩니다.\n",
        "\n",
        "- **Completion 모델**: `gpt-3.5-turbo-instruct` (4,096 tokens context window)\n",
        "- **Chat 모델**: `gpt-3.5-turbo-0125` (16,385 tokens context window)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF7zJIIwP3xz"
      },
      "source": [
        "## Chat 모델과 Completion 모델의 차이\n",
        "\n",
        "1.인터페이스:\n",
        "Completion 모델: 입력이 하나의 자유 형식 텍스트 문자열(프롬프트)로 제공됩니다. 모델은 이 프롬프트를 기반으로 응답을 생성합니다.\n",
        "Chat 모델: 입력이 메시지 목록으로 제공됩니다. 각 메시지는 역할(role)과 내용(content)으로 구성되며, 주로 사용자(user)와 어시스턴트(assistant) 간의 대화를 모방합니다.\n",
        "\n",
        "2.응답 포맷:\n",
        "Completion 모델: 단순한 텍스트 형식의 응답을 반환합니다.\n",
        "Chat 모델: 대화의 맥락을 유지하기 위해 역할과 내용이 포함된 메시지 형식의 응답을 반환합니다.\n",
        "사용 사례:\n",
        "\n",
        "3.Completion 모델: 단일 작업, 코드 삽입, 텍스트 생성 등 특정 프롬프트에 대한 응답 생성에 적합합니다.\n",
        "Chat 모델: 대화형 AI, 연속적인 질문과 응답을 필요로 하는 시나리오에 적합합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dotkCczlsVLa"
      },
      "source": [
        "# Completion 모델 사용 예제\n",
        "Completion 모델은 주어진 프롬프트에 대해 텍스트를 생성하는 방식입니다. 예시로 간단한 프롬프트를 사용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYOtGkQusVLa"
      },
      "outputs": [],
      "source": [
        "### API 키 설정\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# 환경 변수로 API 키 설정\n",
        "# os.environ['OPENAI_API_KEY'] = \"xxxxx\"\n",
        "# openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GamunWD1sVLa",
        "outputId": "4af0403c-5058-4ef1-9fa5-aff1230d4d86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저는 주말 아침에 가장 먼저 하는 일은 일어나서 창문을 열고 신선한 공기를 마시는 것입니다. 그 후에는 머리를 씻고 얼굴을 씻거나 간단한 스트레칭을 하고 천천히 옷을 입습니다. 그리고 아침 식사를 준비하고 식탁을 차려놓습니다. 이때 가족들과 함께 식사를 하면서 이번\n"
          ]
        }
      ],
      "source": [
        "# 프롬프트 준비: 모델에게 전달할 질문이나 요청을 작성합니다.\n",
        "# 여기서는 주말 아침에 일어나서 가장 먼저 하는 일에 대해 설명해달라는 프롬프트를 설정합니다.\n",
        "prompt = \"주말 아침에 일어나서 가장 먼저 하는 일에 대해 설명해 주세요.\"\n",
        "\n",
        "# Completion 모델을 사용하여 텍스트를 생성합니다.\n",
        "# GPT-3.5-turbo-instruct라는 모델을 사용해 프롬프트에 따른 답변을 생성합니다.\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # 사용할 OpenAI 모델을 지정합니다. (이 경우 GPT-3.5-turbo-instruct)\n",
        "    prompt=prompt,  # 모델에게 전달할 프롬프트(질문이나 요청)를 입력합니다.\n",
        "    temperature=0.7,  # 창의성의 정도를 조절합니다. 0은 보수적이고, 1은 매우 창의적인 출력을 의미합니다.\n",
        "    max_tokens=150  # 생성할 텍스트의 최대 길이(토큰 수)를 지정합니다. 토큰은 단어 조각이나 글자입니다.\n",
        ")\n",
        "\n",
        "# 결과 출력: 생성된 텍스트를 가져와서 앞뒤 공백을 제거한 후 출력합니다.\n",
        "# 모델이 생성한 답변(response)을 가져와서 필요 없는 공백을 제거한 후 콘솔에 출력합니다.\n",
        "print(response.choices[0].text.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTynKy8asVLa"
      },
      "source": [
        "# Chat 모델 사용 예제\n",
        "Chat 모델은 대화 형식으로 상호작용할 수 있는 모델입니다. 이는 여러 번의 대화 턴을 처리할 수 있는 구조로 설계되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2Iqsm3wsVLa",
        "outputId": "659eae7b-305f-4780-f629-984d73fc1f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "한국은 동아시아에 위치한 나라로, 공식적으로는 \"대한민국\"이라 불립니다. 한반도의 남부를 차지하고 있으며, 북쪽으로는 북한과 접하고 있습니다. 서쪽으로는 황해, 동쪽으로는 동해, 남쪽으로는 남해와 맞닿아 있습니다. 수도는 서울이며, 서울은 대한민국의 정치, 경제, 문화 중심지 중 하나입니다.\n",
            "\n",
            "대한민국은 현대 역사에서 급속한 경제 성장과 발전을 이루어 '한강의 기적'이라고 불리는 경제 기적의 사례로 자주 언급됩니다. 주요 산업으로는 전자제품, 자동차, 조선업, 반도체 등이 있으며, 삼성, 현대, LG와 같은 글로벌 기업들이 있습니다.\n",
            "\n",
            "문화적으로는 전통적인 한국 문화와 현대의 대중문화가 조화를 이루고 있습니다. 한국 가수, 드라마, 영화는 케이팝(K-pop)과 한국 드라마(K-Drama)를 통해 전 세계에 큰 인기를 끌고 있습니다. 예로는 BTS, 블랙핑크 같은 아이돌 그룹과 드라마 \"오징어 게임\" 등이 있습니다.\n",
            "\n",
            "한국은 또한 풍부한 역사와 전통을 가지고 있습니다. 조선시대의 고궁, 전통 한복, 한글 등 한국의 고유한 전통과 문화를 자랑합니다. 한국 음식 역시 전 세계적으로 사랑받고 있으며, 김치, 불고기, 비빔밥 등이 유명합니다.\n",
            "\n",
            "정치 체제는 민주공화국이며, 대통령 중심제로 운영됩니다. 한국은 국제 사회에서 중요한 역할을 하고 있으며, 특히 IT와 과학기술, 문화 분야에서 활발히 활동하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# Chat 모델을 사용한 간단한 대화 예제\n",
        "\n",
        "# OpenAI의 ChatCompletion을 사용해 대화 생성\n",
        "# ChatCompletion API는 대화를 시뮬레이션하여 질문에 대한 답변을 생성합니다.\n",
        "chat_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4o\",  # 사용할 모델을 지정합니다. (여기서는 gpt-3.5-turbo-0125)\n",
        "    messages=[\n",
        "        # 시스템 메시지: 모델에게 전반적인 역할을 지시하는 부분입니다.\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # 모델에게 \"친절한 어시스턴트\"로 동작하라고 지시합니다.\n",
        "\n",
        "        # 사용자 메시지: 실제로 사용자가 모델에게 질문하거나 요청하는 내용을 전달합니다.\n",
        "        {\"role\": \"user\", \"content\": \"한국에 대해 설명해줘!\"},  # 사용자가 모델에게 한국에 대해 설명해 달라고 요청합니다.\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 모델의 응답(assistant)을 출력\n",
        "# 모델이 생성한 응답 중 첫 번째 결과를 가져와서 앞뒤 공백을 제거한 후 출력합니다.\n",
        "print(chat_response.choices[0].message['content'].strip())  # 모델이 응답한 내용을 화면에 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlUwDZCDR00l",
        "outputId": "c77ead6e-150c-4685-befb-e6a6c59525c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7fa8d82eae10> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1733945430,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734034239,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-1106-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698957206,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-3\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698785189,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-2\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698798177,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727389042,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037777,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-small\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705948997,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634615,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1687882411,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1671217299,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"chatgpt-4o-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1723515131,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387424,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727460443,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648865,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387380,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734112601,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-nano\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744321707,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1694122472,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-search-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741391161,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-nano-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744321025,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-16k\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1683758102,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727659998,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634301,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698959748,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-search-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741388720,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692901427,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677610602,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o3-mini-2025-01-31\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1738010200,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-search-preview-2025-03-11\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741390858,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0125-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037612,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-11-20\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1739331543,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-05-13\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715368132,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-large\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705953180,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734326976,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734375816,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648897,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1686588896,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725649008,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-tts\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742403959,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-pro\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742251791,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-transcribe\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742068463,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.5-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1740623059,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-pro-2025-03-19\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742251504,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.5-preview-2025-02-27\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1740623304,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-search-preview-2025-03-11\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741388170,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-2024-09-26\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1732734466,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-image-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1745517030,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648979,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699046015,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715367049,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053533,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-08-06\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1722814719,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-2024-07-18\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172717,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744318173,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172741,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734115920,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-0125\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706048358,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712361441,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1681940951,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-2024-04-09\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712601677,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053241,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727131766,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-transcribe\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742068596,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"computer-use-preview-2025-03-11\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741377021,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-mini-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744317547,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o3-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1737146383,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"computer-use-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734655677,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744316542,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677532384,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744315746,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1731689265,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o4-mini-2025-04-16\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744133506,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o4-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744225351,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"codex-mini-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1746673257,\n",
              "      \"owned_by\": \"system\"\n",
              "    }\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 선택과 사용 가능한 모든 모델은 `openai.Model.list()`로 확인할 수 있습니다.\n",
        "openai.Model.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUDLI64lu7rv"
      },
      "source": [
        "\n",
        "chat모델에서의 role은 대화에서 각 메시지의 역할을 지정하는 속성으로, 주로 세 가지가 있습니다:\n",
        "\n",
        "system (시스템): 모델의 행동을 설정합니다. 예를 들어, \"친절한 어시스턴트가 되어라\"와 같은 지시를 줍니다.\n",
        "\n",
        "user (사용자): 사람이 모델에게 하는 질문이나 요청을 나타냅니다. 예: \"오늘 날씨가 어때?\"\n",
        "\n",
        "assistant (어시스턴트): 모델이 사용자에게 주는 응답을 나타냅니다. 예: \"오늘 날씨는 맑아요.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7J1M3S2u82X"
      },
      "source": [
        "연속적으로 대화하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElaC35gpuUxz",
        "outputId": "75fd4237-ba7b-4a6e-e6a5-32532b25ef60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "하지만 해일은 더욱 강해지고 있었고, 인류의 기술력은 이에 대응하기에 한계에 도달했다. 모든 노력과 대가를 치르더라도 여러 지역은 이미 침수되어 막대한 피해가 발생했다.\n"
          ]
        }
      ],
      "source": [
        "# OpenAI API를 사용하여 GPT 모델과 연속적인 대화를 이어가는 예제입니다.\n",
        "\n",
        "# 초기 대화 히스토리 설정\n",
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"이야기를 번갈아가며 작성합니다.\"},  # 시스템 메시지: 대화의 기본 규칙을 설정합니다.\n",
        "    {\"role\": \"user\", \"content\": \"먼 미래, 인류는 새로운 위협에 직면하게 되었다.\"},  # 사용자 메시지: 이야기를 시작하는 내용입니다.\n",
        "    {\"role\": \"assistant\", \"content\": \"그 위협은 예상치 못한 곳에서 나타났다. 바다 깊은 곳에서 일어난 지진으로 인해 거대한 해일이 몰려오기 시작했다.\"},  # AI가 첫 번째로 이어가는 스토리.\n",
        "    {\"role\": \"user\", \"content\": \"세계 각국은 이에 대응하기 위해 긴급 재난 구조 팀을 파견했다.\"},  # 사용자 메시지: 스토리를 계속 진행합니다.\n",
        "]\n",
        "\n",
        "# 연속적인 대화를 위한 반복문 (4번의 대화를 반복)\n",
        "for _ in range(4):\n",
        "    # GPT 모델을 사용하여 AI의 응답 생성\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # 사용할 GPT 모델을 지정합니다.\n",
        "        messages=conversation_history  # 대화 히스토리를 모델에 전달합니다.\n",
        "    )\n",
        "\n",
        "    # 모델의 응답을 가져와 출력하고, 대화 히스토리에 저장\n",
        "    assistant_message = response.choices[0].message.content  # AI가 생성한 응답 메시지를 가져옵니다.\n",
        "    print(assistant_message)  # AI의 응답을 화면에 출력합니다.\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    user_message = input(\"사용자: \")  # 사용자로부터 새로운 메시지를 입력받습니다.\n",
        "\n",
        "    # 대화 히스토리에 AI와 사용자의 메시지를 추가\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})  # AI의 응답을 대화 히스토리에 추가합니다.\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_message})  # 사용자의 응답을 대화 히스토리에 추가합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bQYhH0NvQUV"
      },
      "source": [
        "#파라미터 알아보기!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZym9WxSv4H"
      },
      "source": [
        "model\n",
        "설명: 사용할 모델을 지정합니다. 예: \"gpt-3.5-turbo-instruct\".\n",
        "용도: 사용하려는 모델의 종류를 지정합니다.\n",
        "\n",
        "prompt\n",
        "설명: 모델에 입력할 텍스트입니다. 이 텍스트를 기반으로 모델이 응답을 생성합니다.\n",
        "용도: 생성할 텍스트의 맥락이나 주제를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7890TJAR8I3"
      },
      "source": [
        "### temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RnJLvkKTELR"
      },
      "source": [
        "temperature\n",
        "설명: 출력의 창의성 정도를 제어합니다.0.0은 매우 보수적인 출력을 생성하고, 1.0에 가까울수록 더 창의적이고 예상치 못한 출력을 생성합니다.\n",
        "\n",
        "용도: 생성된 응답의 다양성과 창의성을 조절합니다.\n",
        "\n",
        "\n",
        "n\n",
        "설명: 생성할 응답의 수를 지정합니다.\n",
        "용도: 여러 개의 응답을 생성하고 비교하고 싶을 때 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKG56ca3SOtg"
      },
      "outputs": [],
      "source": [
        "prompt = '배고플때 먹는 것은?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORryHFiQSQvs",
        "outputId": "18b7cb78-8523-4aca-b4ff-88e6c12254a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "음식을 먹는 것이 가장 일반적\n",
            "음식을 먹는 것이 가장 일반적\n",
            "음식을 먹는 것이 가장 일반적\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",\n",
        "    prompt = prompt,\n",
        "    temperature =  0.0, # 자유분방한 출력을 조절: (0-1) 0에 가까울수록 정해진 답변을 수행\n",
        "    n=3,  # 'n'은 생성할 문장의 수를 지정합니다. 여기서는 3개의 문장을 생성하도록 설정했습니다.\n",
        "    seed= 8673\n",
        ")\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifeQki6BR7T6",
        "outputId": "1141ab8a-a5c3-469c-f082-ae6a99c5f31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "음식, 과자, 빵, 삼\n",
            "식사나 간식 중 어떤 것을\n",
            "그때마다 다를 수 있겠지만, 대\n",
            "먹고 싶은 음식을 먹는\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",\n",
        "    prompt = prompt,\n",
        "    temperature =  0.9, # 자유분방한 출력을 조절: (0-1) 0에 가까울수록 정해진 답변을 수행\n",
        "    n=4,  # 'n'은 생성할 문장의 수를 지정합니다. 여기서는 3개의 문장을 생성하도록 설정했습니다.\n",
        "    seed= 8673\n",
        ")\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLxan5eDSSaH"
      },
      "source": [
        "# maxtokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4VNhj7CTJtv"
      },
      "source": [
        "설명: 생성할 응답의 최대 길이를 설정합니다. token은 단어의 일부분일 수 있으며, 응답의 길이를 제한하는 데 사용됩니다.\n",
        "용도: 응답의 최대 길이를 제한하여 짧거나 긴 응답을 조절합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hvkFxslST2j",
        "outputId": "30863d9d-eb45-4683-efb3-2afb68b5c4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "음식이나 간식을\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",\n",
        "    prompt = prompt,\n",
        "    temperature =  0.7, #\n",
        "    max_tokens=10,  # 'max_tokens'는 생성할 수 있는 최대 토큰(단어) 수를 지정합니다.\n",
        "    n=1,  # 'n'은 생성할 문장의 수를 지정합니다. 여기서는 3개의 문장을 생성하도록 설정했습니다.\n",
        "    seed= 8673\n",
        ")\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0u_koldSVWq",
        "outputId": "8cdffac6-236f-484b-f3e1-4def65fa18fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "음식이나 간식을 먹는 것이 일반적입니다. 그 중에서도 인기있는 것은 피자, 치킨, 햄버거, 라면, 떡볶이, 김밥, 샌드위치 등 다양한 종류의 음식이 있습니다. 또한 달콤한 간식으로는 아이스크림, 초콜릿, 과일, 쿠키 등도 좋은 선택입니다. 간단하게 먹을 수 있는 라면이나 샌드위치는 배달음식으로도 쉽게 주문할 수 있어서 인기가 많습니다.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",\n",
        "    prompt = prompt,\n",
        "    temperature =  0.7, #\n",
        "    max_tokens=200,  # 'max_tokens'는 생성할 수 있는 최대 토큰(단어) 수를 지정합니다.\n",
        "    n=1,  # 'n'은 생성할 문장의 수를 지정합니다. 여기서는 3개의 문장을 생성하도록 설정했습니다.\n",
        "    seed= 8673\n",
        ")\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNticpFBSbKJ"
      },
      "source": [
        "#(참고) 토큰(token) 수 구하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpWPBWH8Se4v",
        "outputId": "fdeafabc-8fda-4070-de39-badc4e6d56ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "import tiktoken  # [포인트] tiktoken 라이브러리: 텍스트를 \"토큰\"이라는 단위로 변환하는 기능을 제공.\n",
        "                 # 토큰은 AI 모델이 텍스트를 이해하고 처리하는 최소 단위입니다. (예: 단어의 일부 또는 전체)\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\" 문자열을 주어진 인코딩 방식으로 변환하여, 총 토큰 수를 계산해 반환하는 함수 \"\"\"\n",
        "\n",
        "    encoding = tiktoken.get_encoding(encoding_name)  # [포인트] 인코딩 객체를 가져옴.\n",
        "                                                      # 예: 'cl100k_base'는 GPT-4, GPT-3.5-turbo에서 사용하는 대표 인코딩.\n",
        "                                                      # 이 인코딩 규칙에 따라 텍스트를 토큰으로 나눕니다.\n",
        "\n",
        "    num_tokens = len(encoding.encode(string))  # [핵심] 문자열을 토큰으로 변환한 뒤, 토큰 수를 셉니다.\n",
        "                                               # 예: \"고양이\"는 1~2개의 토큰으로 변환될 수 있음 (언어와 문맥에 따라 다름)\n",
        "\n",
        "    return num_tokens  # [결과 반환] 계산된 토큰 수를 반환합니다.\n",
        "                       # 모델에 보낼 텍스트의 \"용량\"을 측정할 때 매우 중요함!\n",
        "\n",
        "# [예제] 아래는 실제 텍스트의 토큰 수를 계산해보는 예시입니다.\n",
        "question = \"내가 좋아하는 애완동물 종류는?\"  # [입력1] 질문: 사용자가 입력한 예시 텍스트입니다.\n",
        "document = \"내가 가장 좋아하는 애완동물은 고양이이다.\"  # [입력2] 문서: 비교할 또 다른 텍스트입니다.\n",
        "\n",
        "# [포인트] 실제로 함수 호출: 질문 문자열을 cl100k_base 인코딩 방식으로 분석하여 토큰 수를 계산\n",
        "num_tokens = num_tokens_from_string(question, \"cl100k_base\")\n",
        "\n",
        "print(num_tokens)  # [출력] 계산된 토큰 수 출력.\n",
        "                   # 예: 결과가 10이라면, 이 질문은 AI 모델 입장에서 10개의 \"단어 조각\"으로 구성되었다는 의미입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRYgrKOmTawj"
      },
      "source": [
        "#Stop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5uv45OvTVdK"
      },
      "source": [
        " stop\n",
        "설명: 특정 문자열이 생성될 때 출력을 중지하도록 설정합니다. 예를 들어, [\"\\n\"]를 지정하면 줄바꿈이 나오면 응답을 멈춥니다.\n",
        "용도: 응답이 특정 패턴에서 중단되도록 제어합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwdpdzTmTZxR",
        "outputId": "1bb78a4f-420e-487a-fcef-44234a3f9448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "축구는 총 2팀으로 이루어진 경기로서, 각 팀은 11\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "prompt = '축구규칙을 설명해줘'\n",
        "response =  openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",\n",
        "    prompt = prompt,\n",
        "    temperature = 0.7,\n",
        "    stop=\"명\",\n",
        "    max_tokens=100 # 'max_tokens'는 생성할 수 있는 최대 토큰(단어) 수를 지정합니다.\n",
        ")\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfxpt4ZqUAoW"
      },
      "source": [
        "# top_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-is2matCT--D"
      },
      "source": [
        "아래 코드는 OpenAI의 GPT 모델에게 \"축구 규칙을 설명해줘\"라는 지시문(prompt)을 전달하고 응답을 생성하는 예제입니다.  \n",
        "이 코드에서 가장 주목할 부분은 `top_p`입니다. `top_p = 0.9`는 모델이 단어를 고를 때 **확률 상위 90%에 해당하는 후보들만 고려하겠다**는 뜻입니다.  \n",
        "예를 들어, 확률이 높은 단어부터 차례로 담아 상위 90% 확률에 도달하는 단어들만 남긴 뒤, 그 중에서 무작위로 하나를 선택합니다.  \n",
        "이 방식은 **응답의 다양성을 확보하면서도 너무 엉뚱한 말은 피하게 해주는 역할**을 합니다.  \n",
        "즉, `top_p`는 창의성과 안정성 사이의 균형을 조절하는 중요한 도구입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXEert9XUDzU",
        "outputId": "42fe4efa-47eb-49bd-d4de-b2a1194e0cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "축구는 총 2팀이 서로 경기를 하며, 각 팀은 11\n"
          ]
        }
      ],
      "source": [
        "import openai  # OpenAI API 라이브러리 불러오기\n",
        "\n",
        "prompt = '축구규칙을 설명해줘'  # 모델에게 요청할 프롬프트 정의\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",  # 지시문 기반 응답을 잘 생성하는 instruct 계열 모델 사용\n",
        "    prompt = prompt,\n",
        "    temperature = 0.7,  # 창의성 정도 (0 = 정직함, 1 = 창의적임)\n",
        "\n",
        "    # [포인트 설명] top_p는 '응답 후보를 얼마나 넓게 볼 것인가'를 정하는 매개변수입니다.\n",
        "    # 확률 분포의 상위 p 누적 확률에 해당하는 단어 후보군에서만 출력을 선택합니다.\n",
        "    # 예: top_p = 0.9 → 전체 후보 중 상위 90% 확률을 가진 단어만 사용\n",
        "    # ✅ 비유: 확률 높은 단어부터 차곡차곡 담아 \"상위 90%짜리 바구니\"를 만들고, 그 안에서 무작위 선택\n",
        "    top_p = 0.9,\n",
        "\n",
        "    stop = \"명\",  # \"명\"이라는 단어가 생성되면 출력을 멈춤\n",
        "    max_tokens = 100  # 최대 출력 길이 제한\n",
        ")\n",
        "\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())  # 결과 출력 (공백 제거)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_DkaGgDUI7r"
      },
      "source": [
        "#frequency_penalty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTJMOg2KUHqs"
      },
      "source": [
        "설명: 과도한 반복이 되지 않도록(동일한 문장이 자주 반복되지 않도록) 페널티를 부과합니다. 값이 클수록 반복이 줄어듭니다.\n",
        "\n",
        "\n",
        "용도:  같은 단어가 많이 나오면 벌점\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6OOL9UbURvf",
        "outputId": "d48e92f8-7183-4c4b-ba8c-ffb2737f0820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "축구는 두 팀이 90분 동안 경기를 진행하여 골을 넣어 점수를 얻는 스포츠 게임입니다. 각 팀은 11명의 선수로 이루어져 있으며, 경기장은 표준 크기인 100m x 64m의 사각형 모양\n",
            "축구는 경기장에서 두 팀이 각각 11명으로 나누어 경기를 벌이는 스포츠입니다. 경기장은 풀로 된 잔디가 놓인 평면이며, 길이는 90-120m, 폭은 45-90m입니다. 경기는 2개의 45분으로 나\n",
            "축구는 다음과 같은 규칙이 있습니다.\n",
            "\n",
            "1. 선발과 교체\n",
            "\n",
            "축구에서는 경기 시작 전에 각 팀은 최대 11명의 선수를 선발합니다. 경기 중에는 선발된 선수들이 경기를 진행하며, 교체 선수를 사용할 수 있\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# 생성할 텍스트의 프롬프트를 설정합니다.\n",
        "prompt = '축구규칙을 설명해줘'  # 모델에게 축구 규칙을 설명하도록 요청하는 프롬프트입니다.\n",
        "\n",
        "# OpenAI Completion API 호출\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",  # 사용할 모델을 지정합니다. 여기서는 \"gpt-3.5-turbo-instruct\" 모델을 사용합니다.\n",
        "    prompt = prompt,  # 모델에게 전달할 입력 프롬프트입니다. 이 프롬프트를 기반으로 모델이 응답을 생성합니다.\n",
        "    temperature = 0.7,  # 생성되는 텍스트의 창의성을 조절합니다. 0.7은 적당한 창의성과 예측 가능성 사이의 균형을 의미합니다.\n",
        "    max_tokens=100,  # 모델이 생성할 응답의 최대 길이(토큰 수)를 지정합니다. 여기서는 최대 100개의 토큰을 생성하도록 설정했습니다.\n",
        "    n=3,  # 응답의 개수를 설정합니다. 여기서는 3개의 응답을 생성하도록 설정되어 있습니다.\n",
        "    frequency_penalty=0.0,  # 동일한 문구나 단어의 반복을 줄이기 위한 페널티를 설정합니다. 0.0은 반복을 허용하지만, 값이 커질수록 반복이 줄어듭니다.\n",
        "    # presence_penalty=0.5  # 이미 언급된 단어나 문장을 피하도록 설정하는 페널티입니다. 값이 클수록 새로운 내용을 생성합니다.\n",
        ")\n",
        "\n",
        "# 생성된 응답을 출력합니다.\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())  # 모델이 생성한 응답 중 불필요한 공백을 제거하고 출력합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojgrEhmZUmQ1",
        "outputId": "e7dc118d-9d02-4158-a759-8a6b2c7ee425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "축구는 총 11명으로 이루어진 두 팀이 경기하는 스포츠입니다. 경기장은 사각형 형태로, 길이는 최소 90m, 최대 120m, 너비는 최소 45m, 최대 90m로 정해져 있습니다. 각 팀은 공격과 수비를\n",
            "축구는 여러 명이서 공을 차고 무대 가운데에 있는 골대(네모난 문)에 넣는 게임입니다. \n",
            "공은 주로 발로 차지만, 손으로 잡거나 몸으로 막거나 넘겨줄 수도 있습니다. \n",
            "몸으로 막을 때는 팔과 손을 사용할\n",
            "축구는 공과 2개의 팀으로 이루어진 경기로, 목적은 상대편 골대에 공을 넣는 것입니다. 각 팀은 11명의 선수로 구성되어 있으며, 경기 시간은 총 90분으로 나누어져 있습니다. 전반전과 후반전으로 나\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# 생성할 텍스트의 프롬프트를 설정합니다.\n",
        "prompt = '축구규칙을 설명해줘'\n",
        "\n",
        "# OpenAI Completion API 호출\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",  # 사용할 모델을 지정합니다. 예: \"gpt-3.5-turbo-instruct\"\n",
        "    prompt = prompt,  # 모델에 입력할 텍스트입니다. 이 텍스트를 기반으로 모델이 응답을 생성합니다.\n",
        "    temperature = 0.7,  # 출력의 창의성 정도를 제어합니다. 0.0은 매우 보수적인 출력을 생성하고, 1.0에 가까울수록 더 창의적이고 예상치 못한 출력을 생성합니다.\n",
        "\n",
        "    max_tokens=100,  # 생성할 응답의 최대 길이를 설정합니다. 여기서는 최대 100개의 토큰(단어)을 생성하도록 설정했습니다.\n",
        "    n=3,  # 생성할 응답의 수를 지정합니다. 여기서는 3개의 응답을 생성하도록 설정했습니다.\n",
        "    frequency_penalty=1.0,  # 동일한 문구나 단어의 반복을 줄이기 위해 페널티를 부과합니다. 값이 클수록 반복이 줄어듭니다.\n",
        "    # presence_penalty=0.5  # 이미 생성된 단어나 문장이 다시 등장하지 않도록 페널티를 부과합니다.\n",
        ")\n",
        "\n",
        "# 생성된 응답을 출력합니다.\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mAG3RKXUL53"
      },
      "source": [
        "#presence_penalty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTxvYTuQUNy7"
      },
      "source": [
        "presence_penalty: 한 번이라도 나온 단어는 다시 안 나오게 유도\n",
        "\n",
        "용도: 이미 언급된 주제나 단어가 다시 등장하는 것을 방지합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOa1VmgfUdJm",
        "outputId": "ec7655c7-bb7e-40ee-9c99-8b84621239b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "축구규칙은 크게 경기장,\n",
            "축구는 두 팀이 경기장에서\n",
            "서 고마워\n",
            "\n",
            "축구는 2개의\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# 생성할 텍스트의 프롬프트를 설정합니다.\n",
        "prompt = '축구규칙을 설명해줘'\n",
        "\n",
        "# OpenAI Completion API 호출\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",  # 사용할 모델을 지정합니다. 예: \"gpt-3.5-turbo-instruct\"\n",
        "    prompt = prompt,  # 모델에 입력할 텍스트입니다. 이 텍스트를 기반으로 모델이 응답을 생성합니다.\n",
        "    temperature = 0.7,  # 출력의 창의성 정도를 제어합니다. 0.0은 매우 보수적인 출력을 생성하고, 1.0에 가까울수록 더 창의적이고 예상치 못한 출력을 생성합니다.\n",
        "    n=3,  # 생성할 응답의 수를 지정합니다. 여기서는 3개의 응답을 생성하도록 설정했습니다.\n",
        "    #frequency_penalty=0.5,  # 동일한 문구나 단어의 반복을 줄이기 위해 페널티를 부과합니다. 값이 클수록 반복이 줄어듭니다.\n",
        "    presence_penalty=0.1  # 이미 생성된 단어나 문장이 다시 등장하지 않도록 페널티를 부과합니다.\n",
        ")\n",
        "\n",
        "# 생성된 응답을 출력합니다.\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndzo2DZJUtpj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# 생성할 텍스트의 프롬프트를 설정합니다.\n",
        "prompt = '축구규칙을 설명해줘'\n",
        "\n",
        "# OpenAI Completion API 호출\n",
        "response = openai.Completion.create(\n",
        "    model = \"gpt-3.5-turbo-instruct\",  # 사용할 모델을 지정합니다. 예: \"gpt-3.5-turbo-instruct\"\n",
        "    prompt = prompt,  # 모델에 입력할 텍스트입니다. 이 텍스트를 기반으로 모델이 응답을 생성합니다.\n",
        "    temperature = 0.7,  # 출력의 창의성 정도를 제어합니다. 0.0은 매우 보수적인 출력을 생성하고, 1.0에 가까울수록 더 창의적이고 예상치 못한 출력을 생성합니다.\n",
        "    stop=\"명\",  # 특정 문자열이 생성될 때 출력을 중지하도록 설정합니다. 여기서는 \"명\"이 생성되면 중지하도록 설정했습니다.\n",
        "    n=3,  # 생성할 응답의 수를 지정합니다. 여기서는 3개의 응답을 생성하도록 설정했습니다.\n",
        "    #frequency_penalty=0.5,  # 동일한 문구나 단어의 반복을 줄이기 위해 페널티를 부과합니다. 값이 클수록 반복이 줄어듭니다.\n",
        "    presence_penalty=0.5  # 이미 생성된 단어나 문장이 다시 등장하지 않도록 페널티를 부과합니다.\n",
        ")\n",
        "\n",
        "# 생성된 응답을 출력합니다.\n",
        "for choice in response.choices:\n",
        "    print(choice.text.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seigEOWaJKzi"
      },
      "source": [
        "📌 Prompt: \"나의 취미는 무엇일까요?\"\n",
        "\n",
        "\n",
        "① frequency_penalty=1.0\n",
        "출력:\n",
        "\"저는 독서를 좋아해요. 독서를 하면서 시간을 보내는 걸 즐깁니다. 독서는 저에게 큰 즐거움이에요.\"\n",
        "\n",
        "설명: \"독서\"라는 단어가 너무 자주 나오니, 점수를 깎아서 덜 쓰게 만듭니다.\n",
        "\n",
        "\n",
        "\n",
        "② presence_penalty=1.0\n",
        "출력:\n",
        "\"저는 독서를 좋아해요. 그림 그리기나 산책도 자주 합니다.\"\n",
        "\n",
        "설명: \"독서\"는 이미 나왔으니, 다른 새로운 단어들(그림, 산책 등)을 더 말하게 유도합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyEe8RDGVZH-"
      },
      "source": [
        "## ✅ 간단한 실습 과제 (복습용)\n",
        "\n",
        "아래 과제들은 강의에서 배운 내용을 복습하며 직접 코드를 실행해보는 연습입니다. 복잡한 응용보다는 **기본기 익히기**에 집중해주세요!\n",
        "\n",
        "---\n",
        "\n",
        "### 과제 1 - Completion 모델로 텍스트 생성하기\n",
        "- 모델: `gpt-3.5-turbo-instruct`\n",
        "- 프롬프트: `\"내가 좋아하는 계절에 대해 이야기해줘.\"`\n",
        "- temperature: 0.5\n",
        "- max_tokens: 100  \n",
        "📌 출력 결과를 보고 어떤 스타일로 생성되었는지 확인해보세요.\n",
        "\n",
        "---\n",
        "\n",
        "### 과제 2 - Chat 모델 사용해보기\n",
        "- 모델: `gpt-3.5-turbo`\n",
        "- system 역할: `\"당신은 유쾌하고 친근한 조언가입니다.\"`\n",
        "- 사용자 메시지: `\"오늘 하루 기분 좋게 시작하려면 뭘 해야 할까?\"`  \n",
        "📌 출력된 응답이 시스템 역할에 맞는지 관찰해보세요.\n",
        "\n",
        "---\n",
        "\n",
        "### 과제 3 - temperature 조절 실험\n",
        "- 프롬프트: `\"혼자 여행을 간다면 어떤 나라가 좋을까?\"`\n",
        "- temperature: **0.2 / 0.9** 로 각각 실험  \n",
        "📌 두 값의 차이에 따라 응답이 얼마나 다른지 비교해보세요.\n",
        "\n",
        "---\n",
        "\n",
        "### 과제 4 - stop 파라미터 실습\n",
        "- 프롬프트: `\"아침에 일어났을 때 해야 할 일들을 알려줘\"`\n",
        "- stop 파라미터: `\"일\"`\n",
        "- max_tokens: 100  \n",
        "📌 결과가 어디서 멈추는지, 왜 그런지 관찰해보세요.\n",
        "\n",
        "---\n",
        "\n",
        "### 과제 5 - 반복 억제 파라미터 실험\n",
        "- 프롬프트: `\"AI 시대의 장단점에 대해 말해줘\"`\n",
        "- frequency_penalty: 0.0 / 1.0\n",
        "- presence_penalty: 0.0 / 1.0  \n",
        "📌 각 파라미터를 조절해보며 응답 내 반복 문장이 줄어드는지 확인해보세요.\n",
        "\n",
        "---\n",
        "\n",
        "✔️ 실습이 끝난 후, 마음에 드는 결과나 흥미로운 차이점을 간단히 정리해보면 더 효과적인 복습이 됩니다!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
