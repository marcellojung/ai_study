{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJrjiEjCdoL9"
   },
   "source": [
    "# ë²¡í„°ë°ì´í„° ê¸°ë°˜ RAG ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4JMyYuhn9eG"
   },
   "source": [
    "ğŸš€ ëª©í‘œëŠ” ë­˜ê¹Œ?\n",
    "RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ë§Œë“¤ê¸° ìœ„í•œ ì‹¤ìŠµì…ë‹ˆë‹¤.\n",
    "ì¦‰, ì›¹ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  â†’ ê·¸ ë‚´ìš©ì„ ê¸°ì–µí•˜ë„ë¡ ì •ë¦¬(ë²¡í„°í™”)í•œ ë‹¤ìŒ â†’ ì‚¬ìš©ì ì§ˆë¬¸ì— ê·¸ ì •ë³´ë¥¼ í™œìš©í•´ ë˜‘ë˜‘í•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” AI ì±—ë´‡ì„ ë§Œë“œëŠ” ê²ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ“¦ ì „ì²´ íë¦„ ìš”ì•½\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1.ì›¹ í˜ì´ì§€ì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "ë§ˆì¹˜ êµ¬ê¸€ì—ì„œ ì›¹ë¬¸ì„œë¥¼ ë³µì‚¬í•´ì˜¤ëŠ” ê²ƒì²˜ëŸ¼, ì›¹ì—ì„œ í•„ìš”í•œ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ê¸ì–´ì˜µë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "2.ë¬¸ì„œë¥¼ ì˜ê²Œ ë‚˜ëˆ„ê¸° (í…ìŠ¤íŠ¸ ë¶„í• )\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "ë¬¸ì„œë¥¼ í•œ ë©ì–´ë¦¬ë¡œ ë‘ë©´ AIê°€ ì´í•´í•˜ê¸° ì–´ë ¤ìš°ë‹ˆê¹Œ, ë¬¸ì¥ì„ ì¼ì • í¬ê¸°ë¡œ ìŠ¬ë¼ì´ìŠ¤í•´ì¤ë‹ˆë‹¤.\n",
    "---\n",
    "3.ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í•˜ê¸°\n",
    "---\n",
    "ì˜ë¼ë‚¸ ë¬¸ì¥ë“¤ì„ ìˆ«ìë¡œ ë°”ê¿” ê¸°ì–µí•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¦‰, ë¬¸ì¥ì„ **ë²¡í„°(ìˆ«ì ë¦¬ìŠ¤íŠ¸)**ë¡œ ë°”ê¿” ì €ì¥ì†Œì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "---\n",
    "4.ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ê´€ë ¨ ë¬¸ì¥ ì°¾ê¸°\n",
    "---\n",
    "ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë˜ì§€ë©´, ì•„ê¹Œ ì €ì¥í•œ ë²¡í„° ì¤‘ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì¥ì„ ì°¾ì•„ì˜µë‹ˆë‹¤.\n",
    "---\n",
    "5.ì°¾ì•„ì˜¨ ë¬¸ì¥ + ì§ˆë¬¸ì„ í•¨ê»˜ LLM(GPT)ì— ì „ë‹¬í•˜ê¸°\n",
    "---\n",
    "\"ì´ ë¬¸ì¥ë“¤ì„ ì°¸ê³ í•´ì„œ ì´ ì§ˆë¬¸ì— ë‹µí•´ì¤˜!\" í•˜ê³  GPTì—ê²Œ ê±´ë„¤ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤.\n",
    "---\n",
    "6.GPTê°€ ì •ë‹µì„ ë§Œë“¤ì–´ëƒ„\n",
    "---\n",
    "ìµœì¢…ì ìœ¼ë¡œ AIê°€ ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§§ê³  ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¯ ì‰½ê²Œ ë¹„ìœ í•˜ìë©´...\n",
    "\n",
    " ğŸ” ì›¹ ë¬¸ì„œëŠ” ì±…ì¥ì— ê½‚íŒ ì±…ì´ê³ \n",
    "\n",
    " âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í• ì€ ì±…ì„ ì±•í„°ë³„ë¡œ ìë¥´ëŠ” ì‘ì—…ì´ê³ \n",
    "\n",
    " ğŸ§  ë²¡í„°í™”ëŠ” ì±•í„°ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê¸°ì–µì‹œí‚¤ëŠ” ê²ƒì´ê³ \n",
    "\n",
    " â“ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ AIì—ê²Œ \"ì´ ì±…ì—ì„œ ~~ë‚´ìš© ì•Œë ¤ì¤˜\" í•˜ëŠ” ê²ƒ\n",
    "\n",
    " ğŸ¤– GPTëŠ” ì±…ì„ ë’¤ì ¸ì„œ ì •í™•í•œ ë‹µì„ ë§í•´ì£¼ëŠ” ë˜‘ë˜‘í•œ ì‚¬ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë‹¨ê³„\tì„¤ëª…\n",
    "---\n",
    "1ë‹¨ê³„\tì›¹ ë¬¸ì„œ ê¸ì–´ì˜¤ê¸°\n",
    "---\n",
    "2ë‹¨ê³„\tí…ìŠ¤íŠ¸ ìŠ¬ë¼ì´ìŠ¤(1000ìì”© ìë¥´ê¸°)\n",
    "---\n",
    "3ë‹¨ê³„\tì˜ë¦° í…ìŠ¤íŠ¸ â†’ ìˆ«ì(ë²¡í„°)ë¡œ ë°”ê¿” ì €ì¥\n",
    "---\n",
    "4ë‹¨ê³„\tì§ˆë¬¸ â†’ ê´€ë ¨ëœ í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
    "---\n",
    "5ë‹¨ê³„\tì§ˆë¬¸ + ë¬¸ë§¥ â†’ GPTì— ì „ë‹¬\n",
    "---\n",
    "6ë‹¨ê³„\tGPT â†’ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "---\n",
    "\n",
    "ğŸ’¡ ì´ëŸ° ê±¸ ì™œ ì“°ë‚˜ìš”?\n",
    "ë‹¨ìˆœíˆ GPTì—ê²Œ ì§ˆë¬¸í•˜ë©´ ëª¨ë¥´ëŠ” ì²™í•˜ê±°ë‚˜ í—›ì†Œë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "RAGëŠ” GPTê°€ ì‹¤ì œ ìë£Œë¥¼ ì°¸ê³ í•´ì„œ ë‹µí•˜ê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ì¦‰, GPTë¥¼ ì§€ì‹ ê¸°ë°˜ AIë¡œ í•œ ë‹¨ê³„ ì—…ê·¸ë ˆì´ë“œì‹œí‚¤ëŠ” ë°©ë²•ì…ë‹ˆë‹¤!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEXZHs6GdsA3"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# í¬ì¸íŠ¸: ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ GPTì™€ ì™¸ë¶€ ë°ì´í„°ë¥¼ ì—°ê²°í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ë° ê¼­ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "!pip install --upgrade openai langchain langchain-openai langchain-community beautifulsoup4 langchainhub -q\n",
    "!pip install chromadb tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1728648965637,
     "user": {
      "displayName": "ì´ì§„ê·œ",
      "userId": "17496981203379941373"
     },
     "user_tz": -540
    },
    "id": "x13Lo_xEg4W6",
    "outputId": "97f98bb5-9671-4211-b366-69ad559efc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API í‚¤ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# openai ëª¨ë“ˆê³¼ os ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. (osëŠ” í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì— í•„ìš”)\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# OpenAI API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.\n",
    "# í¬ì¸íŠ¸: ì´ë ‡ê²Œ í•˜ë©´ ì½”ë“œì— í‚¤ê°€ ë…¸ì¶œë˜ì§€ ì•Šê³  ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# OpenAI APIì™€ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "client = openai.OpenAI()\n",
    "print(\"API í‚¤ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5382,
     "status": "ok",
     "timestamp": 1728648971016,
     "user": {
      "displayName": "ì´ì§„ê·œ",
      "userId": "17496981203379941373"
     },
     "user_tz": -540
    },
    "id": "gKsItoP-yNHO",
    "outputId": "82dcd3fe-dc88-4c6a-86c6-c406138a0ce7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# LangChainê³¼ BeautifulSoup ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # ë¬¸ì„œ ìë¥¼ ë•Œ ì‚¬ìš©\n",
    "from langchain_community.document_loaders import WebBaseLoader  # ì›¹ ë¬¸ì„œ ë¡œë“œ\n",
    "from langchain_community.vectorstores import Chroma  # ë²¡í„° DB ì €ì¥ì†Œ\n",
    "from langchain_core.output_parsers import StrOutputParser  # ì¶œë ¥ í˜•ì‹ ë³€í™˜ê¸°\n",
    "from langchain_core.runnables import RunnablePassthrough  # ì…ë ¥ ê·¸ëŒ€ë¡œ ë„˜ê²¨ì£¼ëŠ” ëª¨ë“ˆ\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # GPT ëª¨ë¸ ë° ì„ë² ë”© ìƒì„±\n",
    "import bs4\n",
    "\n",
    "# ì›¹ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” WebBaseLoaderë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "# í¬ì¸íŠ¸: ì§€ì •í•œ ì›¹ URLì—ì„œ íŠ¹ì • HTML í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë³¸ë¬¸ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://mlrx.tistory.com/entry/%EC%B1%97%EB%B4%87-PDF-QA-%EC%B1%97%EB%B4%87-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-1\",),\n",
    "\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(class_=\"article_view\")  # ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1728648971016,
     "user": {
      "displayName": "ì´ì§„ê·œ",
      "userId": "17496981203379941373"
     },
     "user_tz": -540
    },
    "id": "ElMJhCjdgjMN",
    "outputId": "523818f4-584a-4f12-9b5c-08c05d0b8d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://mlrx.tistory.com/entry/%EC%B1%97%EB%B4%87-PDF-QA-%EC%B1%97%EB%B4%87-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-1'}, page_content='\\n\\n\\nëª©ì \\nPDF ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆì˜ì‘ë‹µ(QA)ë¥¼ í•  ìˆ˜ ìˆëŠ” ì¸íŠ¸ë¼ë„·ì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•œ ì±—ë´‡ ê°œë°œ\\n\\xa0\\nì¤€ë¹„ë¬¼\\npython\\nlangchain\\nopenai api key\\n\\xa0\\nê³¼ì •\\nì „ì²´ì ì¸ í”Œë¡œìš°\\n\\n\\n1. PDF ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ê¸°\\nlangchainì—ì„œ ì œê³µí•˜ëŠ” pdf loaderë¥¼ ì´ìš©í•´ pdfì—ì„œ textë¥¼ ì¶”ì¶œí•œë‹¤.\\nlangchainì—ì„œëŠ” ë‹¤ì–‘í•œ ë°©ë²•ì„ ì œê³µí•˜ë¯€ë¡œ ê°ì ìƒí™©ì— ë§ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ë„ë¡ í•œë‹¤.\\n(í˜„ì¬ ê¸€ì“´ì´ë„ ì ì ˆí•œ ë°©ë²•ì„ ëª¨ìƒ‰í•˜ê³  ìˆë‹¤.)\\nfrom langchain.document_loaders import UnstructuredPDFLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\nloader = UnstructuredPDFLoader(\\'../ì•½ê´€.pdf\\')\\ndata = loader.load()\\n\\nprint(f\"{len(data)}ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\")\\nprint(f\"ë¬¸ì„œì— {len(data[0].page_content)}ê°œì˜ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\")\\n1ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\në¬¸ì„œì— 281012ê°œì˜ ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\n\\xa0\\n2. í…ìŠ¤íŠ¸ë¥¼ chunkë¡œ ë‚˜ëˆ„ê¸°\\nembeddingì„ ë§Œë“¤ê¸° ìœ„í•´ì„  embeddingì´ ëª¨ë¸ì´ ì†Œí™”í•  ìˆ˜ ìˆëŠ” ì–‘ë§Œí¼ì˜ ì…ë ¥ë§Œ ë„£ì–´ì¤˜ì•¼ í•œë‹¤. ê·¸ëŸ¬ê¸°ì— 281012ê°œì˜ ë‹¨ì–´ë¥¼ ê°€ì§„ ê°’ì„ í†µì±„ë¡œ ë„£ì–´ì¤„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ë„£ì–´ì£¼ì.\\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\ntexts = text_splitter.split_documents(data)\\nprint(f\"ë¬¸ì„œì— {len(texts)}ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\")\\në¬¸ì„œì— 286ê°œì˜ ë¬¸ì„œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\nì´ ë•Œ 1000ê°œì”© ìª¼ê² ê¸°ì— 282ê°œì˜ textsê°€ ìƒì„± ë  ê²ƒì´ë¼ ê¸°ëŒ€ë˜ì—ˆìœ¼ë‚˜ ì‹¤ì œë¡œëŠ” 286ê°œì˜ textsê°€ ìƒì„±ë˜ì—ˆë‹¤.\\xa0\\nì‹¤ì œë¡œ textsì˜ ì›ì†Œë“¤ì˜ ê¸¸ì´ë¥¼ ì¶œë ¥í•´ë³´ë©´\\xa0\\n983, 991, 952, 988, 979, 959, 944, 972...\\nì™€ ê°™ì€ë° ê·¸ ì´ìœ ëŠ” RecursiveCharacterTextSplitterëŠ” ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ì—°ê´€ì„±ì´ ê°•í•œ í…ìŠ¤íŠ¸ ì¡°ê°ìœ¼ë¡œ ë³´ì´ëŠ” ë¬¸ì¥, ë‹¨ì–´ë¥¼ ê°€ì¥ ê¸¸ê²Œ ìœ ì§€í•˜ê³ ì í•˜ê¸° ë–„ë¬¸ì´ë‹¤.\\n\\xa0\\n3. Vector Store ë§Œë“¤ê¸°\\nì´ì œ textsë¥¼ embeddingìœ¼ë¡œ ë§Œë“¤ì–´ storeë¥¼ êµ¬ì„±í•˜ë„ë¡ í•˜ì.\\nvector storeë¥¼ ë§Œë“œëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ì–‘í•˜ë‚˜(pinecone ë“±)\\xa0 ì—¬ê¸°ì„  Facebookì—ì„œ ê°œë°œí•œ faissë¥¼ ì‚¬ìš©í•œë‹¤.\\nì´ë•Œ embedding ëª¨ë¸ì€ openaiì˜ text-embedding-ada-002(default)ë¥¼ ì‚¬ìš©í•œë‹¤.\\nfrom langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.vectorstores import FAISS\\nimport faiss\\n\\nprint(f\\'ì˜ˆìƒë˜ëŠ” í† í° ìˆ˜ {num_tokens_from_string(data[0].page_content, \"cl100k_base\")}\\')\\n\\n# Create the vector store\\nstore = FAISS.from_texts([text.page_content for text in texts], OpenAIEmbeddings(openai_api_key=openai_api_key))\\nì˜ˆìƒë˜ëŠ” í† í° ìˆ˜ 258751\\nopenai apië¥¼ íƒœìš°ê¸°ì „ ì˜ˆìƒ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•´ë³´ê³ , ì‹¤ì œ íƒœìš´ í›„ í† í° ìˆ˜ë¥¼ í™•ì¸í•´ë³¸ë‹¤.\\nì˜¤ì „ 7:30ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ì‹¤ì œ ë°œìƒ í† í°\\n\\në°œìƒ ë¹„ìš©\\n\\n\\n139ê°œì˜ í† í° ìˆ˜ê°€ ì°¨ì´ ìˆìŒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.\\n\\xa0\\nimport pickle\\nfaiss.write_index(store.index, \"docs.index\")\\nwith open(\"faiss_store.pkl\", \"wb\") as f:\\n    pickle.dump(store, f)\\n\\xa0\\nì´í›„ ë§Œë“¤ì–´ì§„ ê°’ì„ ë¡œì»¬ ë””ìŠ¤í¬ì— ì €ì¥í•˜ë„ë¡ í•œë‹¤.\\n\\xa0\\n4. ì‚¬ìš©ì ì…ë ¥ ë°›ì•„ ê²°ê³¼ ìƒì„±í•˜ê¸°\\nquery = \"ë³´ìƒí•˜ì§€ ì•ŠëŠ” ì†í•´ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\\ndocs = store.similarity_search(query, k = 4)\\n\\xa0\\nìœ„ì™€ ê°™ì´ ë³´ì¥í•˜ì§€ ì•ŠëŠ” ì†í•´ì— ëŒ€í•´ ì§ˆë¬¸í•œë‹¤ëŠ” ê°€ì •í•˜ì—, ê¸° ë§Œë“  vector storeì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 4ê°œë¥¼ ì¶”ì¶œí•´ì˜¨ë‹¤.\\n(docsë¥¼ ì¶œë ¥í•˜ë©´ ë¬¸ì„œ ë‚´ìš©ì´\\x08 ì¶œë ¥ë˜ë‚˜ ê·¸ ë‚´ìš© ì¤‘ ì¼ë¶€ë§Œ ê³µê°œí•œë‹¤.)\\n[Document(page_content=\\'ìœ„  â€˜â‘¡  â—¯1 ì—ë„  ë¶ˆêµ¬í•˜ê³   ë‹¤ìŒì˜  ì†í•´ëŠ”  ë³´ìƒí•˜ì§€  ì•ŠìŠµë‹ˆë‹¤\\\\n\\\\nâ€™\\\\n\\\\n.\\\\n\\\\n1)\\\\n\\\\n2)\\\\n\\\\n3)\\\\n\\\\n4)\\\\n\\\\nì–‘ë„ëœ  í”¼ë³´í—˜ìë™ì°¨ê°€  ì–‘ìˆ˜ì¸  ëª…ì˜ë¡œ  ...\\', metadata={}),\\n Document(page_content=\\')\\\\n\\\\nì œ ì¡° ë³´ìƒí•˜ì§€  ì•ŠëŠ”  ì†í•´\\\\n\\\\nâ‘ \\\\n\\\\n8\\\\n\\\\në‹¤ìŒ  ì¤‘  ì–´ëŠ  í•˜ë‚˜ì—  í•´ë‹¹í•˜ëŠ”  ì†í•´ëŠ”  ëŒ€ì¸ë°°ìƒ ì™€  ëŒ€ë¬¼ë°°ìƒì—ì„œ  ë³´ìƒí•˜ì§€  ì•ŠìŠµë‹ˆë‹¤....\\', metadata={}),\\n Document(page_content=\\'ë„ë¡œêµí†µë²• ì—ì„œ  ì •í•œ  ì‚¬ê³ ë°œìƒ  ì‹œì˜  ì¡°ì¹˜ë¥¼  í•˜ì§€  ì•Šì€  ê²½ìš°ë¥¼  ë§í•©ë‹ˆë‹¤ ë‹¤ë§Œ ì£¼ ì •ì°¨ëœ\\\\n\\\\nì°¨ë§Œ  ì†ê´´í•œ  ê²ƒì´  ë¶„ëª…í•œ  ê²½ìš°ì—  í”¼í•´ìì—ê²Œ  ì¸ì ì‚¬í•­ì„  ì œê³µí•˜ì§€  ì•„ë‹ˆí•œ  ê²½ìš°ëŠ”\\', metadata={}),\\n Document(page_content=\\'ì†í•´ë°°ìƒë³´ì¥ë²•ë ¹ì—ì„œ  ì •í•œ  ê¸ˆì•¡ì„  í•œë„...\\', metadata={})]\\n\\xa0\\nìœ„ ì²˜ëŸ¼ ê²°ê³¼ê°€ ì¶œë ¥ë¨ì„ í™•ì¸í•˜ì˜€ìœ¼ë¯€ë¡œ langchainì˜ load_qa_chainì„ í†µí•´ ë¬¸ì„œì™€ queryë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPTë¡œ ë¶€í„° ê²°ê³¼ë¥¼ ì–»ì–´ì˜¨ë‹¤.\\nfrom langchain.chains.question_answering import load_qa_chain\\nfrom langchain import OpenAI\\nchain = load_qa_chain(OpenAI(model_name=\\'gpt-3.5-turbo\\', temperature=0, max_tokens=100, openai_api_key=openai_api_key), chain_type=\"map_reduce\")\\nresult_qa_chain = []\\nfor doc in docs:\\n    result_qa_chain.append(chain.run(input_documents=[doc], question=query))\\nresult_qa_chain\\nì œëŒ€ë¡œ ì¶œë ¥ì´ ì•ˆë¨ì„ ë³¼ ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œ ê¸° ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ë˜ì–´ ì´ëŠ” load_qa_chainì„ ì¨ì„œ ê·¸ëŸ° ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤.\\n[\"I\\'m sorry, I cannot provide a final answer as the given content is not in a language that I am programmed to understand.\",\\n \\'ëŒ€ì¸ë°°ìƒ ì™€ ëŒ€ë¬¼ë°°ìƒì—ì„œëŠ” ë³´ìƒí•˜ì§€ ì•ŠëŠ” ì†í•´ë¡œ, ë³´í—˜ê³„ì•½ìë‚˜ ê¸°ëª…í”¼ë³´í—˜ìì˜ ê³ ì˜ë¡œ ì¸í•œ ì†í•´ì™€ ê¸°ëª…í”¼ë³´í—˜ì ì´ì™¸ì˜ í”¼ë³´í—˜ìì˜ ê³ ì˜ë¡œ ì¸í•œ ì†í•´ê°€ ìˆë‹¤.\\',\\n \\'There is no information provided about damages that are not covered by insurance.\\',\\n \"I\\'m sorry, I cannot provide a final answer as the given content is in Korean and I am not programmed to translate languages.\"]\\n\\xa0\\nì•ìœ¼ë¡œ ê³ ì‹¬í•  ì¼ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\\n\\n\\nìœ„ ë¬¸ì œë¥¼ í•˜ë‚˜í•˜ë‚˜ í•´ê²°í•´ë‚˜ê°€ë©° ê¸€ì„ ì‘ì„±í•˜ë„ë¡ í•˜ê² ë‹¤.\\níŠ¹íˆ ì¸íŠ¸ë¼ë„·ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼í•˜ë¯€ë¡œ openaiì˜ ì˜ì¡´ì„±ì€ ì™„ì „íˆ ì—†ì• ì„œ ì™„ì„±ë„ë¥¼ ë†’ì—¬ì•¼ í•  ê²ƒì´ë‹¤. ë˜í•œ, ë¹„ìƒì—…ìš© ëª¨ë¸ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìƒì—…ì ìœ¼ë¡œ ì‚¬ìš©ê°€ëŠ¥í•œ dolly ë¡œ ëŒ€ì²´í•  ê²ƒì´ë‹¤.\\n\\xa0\\n\\xa0\\nì°¸ê³ \\nhttps://www.youtube.com/watch?v=2xxziIWmaSA\\xa0\\nhttps://www.youtube.com/watch?v=h0DHDp1FbmQ\\xa0\\nhttps://www.youtube.com/watch?v=ih9PBGVVOO4\\xa0\\n\\n\\n\\n\\nê³µìœ í•˜ê¸°\\n\\nê²Œì‹œê¸€ ê´€ë¦¬\\n\\n\\nì²œì²œíˆì°¬ì°¬íˆ \\n\\n\\n\\n')]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "docs  # ì›¹ì—ì„œ ê°€ì ¸ì˜¨ ë¬¸ì„œ ê°ì²´ í™•ì¸\n",
    "\n",
    "print(docs)  # ë¬¸ì„œ ë‚´ìš© ì¶œë ¥\n",
    "print(type(docs))  # ë¬¸ì„œì˜ ë°ì´í„° íƒ€ì… í™•ì¸ (ë¬¸ì„œ ë¶„í•  ì „ì— ë°ì´í„° í˜•íƒœ ì ê²€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP5QhygYx85J"
   },
   "outputs": [],
   "source": [
    "# âœ… 2ë‹¨ê³„: ë¬¸ì„œ í…ìŠ¤íŠ¸ ë¶„í• \n",
    "# ê¸´ ë¬¸ì„œë¥¼ ì¼ì • í¬ê¸°ë¡œ ì˜ë¼ì£¼ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. GPTê°€ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë¶„ëŸ‰ìœ¼ë¡œ ì¡°ê°ëƒ…ë‹ˆë‹¤.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# ì‹¤ì œë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤. -> splits ì—ëŠ” ì˜ë¦° ë¬¸ì¥ ë¸”ë¡ë“¤ì´ ë‹´ê¹ë‹ˆë‹¤.\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or_2lgF84-1B"
   },
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "If0vTVB_x85J"
   },
   "outputs": [],
   "source": [
    "# âœ… 3ë‹¨ê³„: í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©(ìˆ«ì ë²¡í„°)ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë²¡í„° DBì— ì €ì¥\n",
    "# í¬ì¸íŠ¸: GPTê°€ ë¬¸ì¥ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìˆ«ìë¡œ ë°”ê¾¸ê³ , ì €ì¥ì†Œì— ê¸°ì–µì‹œí‚¤ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# ì €ì¥ëœ ë²¡í„°ë¡œë¶€í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ ë§Œë“œëŠ” ë‹¨ê³„\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqHUgBJ6cD0o"
   },
   "outputs": [],
   "source": [
    "# âœ… 4ë‹¨ê³„: ì§ˆë¬¸ì„ ë˜ì§€ê³ , ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰\n",
    "documents = retriever.get_relevant_documents(\"ì±—ë´‡ì„ ê°œë°œí•˜ê¸° ìœ„í•œ ì¡°ê±´ì€?\")\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œë ¥\n",
    "for document in documents:\n",
    "    print(f\"ë¬¸ì„œ ë‚´ìš©: {document.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5bWz7nbdf4y"
   },
   "outputs": [],
   "source": [
    "# âœ… 5ë‹¨ê³„: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "# GPTê°€ ì‘ë‹µì„ ë§Œë“¤ ë•Œ ë”°ë¼ì•¼ í•  ì§€ì¹¨ì„ ì •í•´ì¤ë‹ˆë‹¤.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë³´ì¡°ìì…ë‹ˆë‹¤. \"\n",
    "        \"ë‹¤ìŒì— ì œê³µëœ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤. \"\n",
    "        \"ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì‹­ì‹œì˜¤. \"\n",
    "        \"ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ë‹µë³€í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\\n\"\n",
    "        \"ì§ˆë¬¸: {question}\\n\"\n",
    "        \"ë¬¸ë§¥: {context}\\n\"\n",
    "        \"ë‹µë³€:\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUFUhMPYx85K"
   },
   "outputs": [],
   "source": [
    "\n",
    "# âœ… 6ë‹¨ê³„: Hubì—ì„œ ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì„ íƒì‚¬í•­)\n",
    "# langchain hubì—ì„œ ë” ì •êµí•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "# # https://smith.langchain.com/hub ì—ì„œ ì›í•˜ëŠ” promptë¥¼ ë°›ì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ API í‚¤ ì„¤\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = \n",
    "\n",
    "# ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (ë” ì •êµí•œ ì§€ì‹œë¥¼ í¬í•¨)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728648976245,
     "user": {
      "displayName": "ì´ì§„ê·œ",
      "userId": "17496981203379941373"
     },
     "user_tz": -540
    },
    "id": "cT4N47h-hbVj",
    "outputId": "b84983af-7881-4254-e846-5383bccee6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ ë‚´ìš© ì¶œë ¥\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdj7pMVwzMH8"
   },
   "outputs": [],
   "source": [
    "# âœ… 7ë‹¨ê³„: LLM ì„¤ì • ë° ì²´ì¸ êµ¬ì„±\n",
    "# í¬ì¸íŠ¸: ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ GPTì— í•¨ê»˜ ì „ë‹¬í•˜ê³ , ì‘ë‹µì„ ë°›ëŠ” ì „ì²´ ì²˜ë¦¬ íë¦„ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.1)\n",
    "\n",
    "# í›„ì²˜ë¦¬ í•¨ìˆ˜: ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë¬¶ëŠ” ì—­í• \n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2488,
     "status": "ok",
     "timestamp": 1728648979114,
     "user": {
      "displayName": "ì´ì§„ê·œ",
      "userId": "17496981203379941373"
     },
     "user_tz": -540
    },
    "id": "nNjQkqqRx85K",
    "outputId": "f1bc1852-8dea-4e14-f822-031c923614f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë²¡í„° ì„ë² ë”©ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, OpenAIì˜ text-embedding-ada-002ì™€ ê°™ì€ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë³€í™˜ëœ ë²¡í„°ëŠ” FAISSì™€ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ êµ¬ì„±\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}  # ë¬¸ë§¥ì„ ê²€ìƒ‰í•˜ê³  ì§ˆë¬¸ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "    | prompt  # ë¬¸ë§¥ + ì§ˆë¬¸ â†’ GPTë¡œ ì „ë‹¬ë  í˜•íƒœë¡œ í¬ë§·\n",
    "    | llm  # GPTê°€ ì‘ë‹µ ìƒì„±\n",
    "    | StrOutputParser()  # ì¶œë ¥ëœ ì‘ë‹µì„ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬\n",
    ")\n",
    "\n",
    "# âœ… 8ë‹¨ê³„: ì§ˆë¬¸ì— ëŒ€í•´ ì‘ë‹µ ìƒì„±\n",
    "response = rag_chain.invoke(\"ë²¡í„° ì„ë² ë”©ì„ ë§Œë“¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\")\n",
    "print(response)  # GPTê°€ ìƒì„±í•œ ì‘ë‹µ ì¶œë ¥"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
