{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDgLTgesutN2"
      },
      "source": [
        "# 1. PythonREPLì„ ì´ìš©í•œ Code Writing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbeOsSHBjqsC"
      },
      "source": [
        "PythonÂ REPL(Read-Eval-PrintÂ Loop)ì‚¬ìš©ìê°€Â PythonÂ ì½”ë“œë¥¼Â ì…ë ¥í•˜ê³ Â ì‹¤í–‰í•˜ë©°Â ê²°ê³¼ë¥¼Â ì¦‰ì‹œÂ í™•ì¸í• Â ìˆ˜Â ìˆëŠ”Â ê¸°ëŠ¥ì„ì œê³µ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQaO43GPlBaT"
      },
      "source": [
        "Read-Eval-Print Loop(ì½ê¸°-í‰ê°€-ì¶œë ¥ ë£¨í”„)ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„¸ ê°€ì§€ ë‹¨ê³„ë¥¼ ë°˜ë³µí•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•©ë‹ˆë‹¤:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKeaQm7mlT2W"
      },
      "source": [
        "\n",
        "Read(ì½ê¸°): ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì½”ë“œë¥¼ ì½ê³  í•´ì„í•©ë‹ˆë‹¤.\n",
        "\n",
        "Eval(í‰ê°€): ì½ì–´ë“¤ì¸ ì½”ë“œë¥¼ ì‹¤í–‰(í‰ê°€)í•˜ì—¬ ê²°ê³¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "Print(ì¶œë ¥): í‰ê°€ëœ ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JupOD2wFSjYE"
      },
      "source": [
        "LangChain ê¸°ë°˜ ìë™ ì½”ë“œ ìƒì„± + ì‹¤í–‰ + ëª¨ë”ë ˆì´ì…˜ ì²´ê³„ ì„¤ëª…\n",
        "\n",
        "ğŸ§  ì „ì²´ ê°œìš”\n",
        "\n",
        "ì´ ì‹¤ìŠµì€ LangChain + OpenAI APIë¥¼ í™œìš©í•˜ì—¬:\n",
        "\n",
        "ì‚¬ìš©ìì˜ ë¬¸ì œë¥¼ ì½ê³ \n",
        "\n",
        "ê·¸ì— ë§ëŠ” Python ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•œ ë‹¤ìŒ\n",
        "\n",
        "ìƒì„±ëœ ì½”ë“œë¥¼ ì¦‰ì‹œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ë©°\n",
        "\n",
        "ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ëŠ” ìë™ìœ¼ë¡œ ì°¨ë‹¨í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œì„ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¦‰, ë§ˆì¹˜ \"AI ì½”ë”© ë¹„ì„œ\"ì²˜ëŸ¼ ë™ì‘í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤!\n",
        "\n",
        "ğŸ§© êµ¬ì„± ìš”ì†Œë³„ í° ê·¸ë¦¼ ì„¤ëª…\n",
        "\n",
        "ğŸ§± 1. ì‚¬ìš©ì ì…ë ¥ â†’ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
        "\n",
        "ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì§ˆë¬¸ì„ ë˜ì§€ë©´ (\"xê°€ 10ì¼ ë•Œ, y=5+3xëŠ”?\")\n",
        "\n",
        "ì´ê±¸ ë°”íƒ•ìœ¼ë¡œ AIê°€ ì½”ë“œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸(ì§€ì¹¨ ë¬¸ì¥)ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ‘‰ ì§ê´€ì ì¸ ë¹„ìœ : ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ \"ë¬¸ì œì§€\", í”„ë¡¬í”„íŠ¸ëŠ” \"ì„ ìƒë‹˜ì˜ ì§€ì‹œì‚¬í•­\"ì…ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ¤– 2. LLM(GPT)ì„ í†µí•´ ì½”ë“œ ìƒì„±\n",
        "GPT ëª¨ë¸(GPT-4ë‚˜ GPT-4o ë“±)ì´ ì§€ì¹¨ì— ë”°ë¼ íŒŒì´ì¬ ì½”ë“œë§Œ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "y = 5 + 3 * x ê°™ì€ ì‹ì„ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ‘‰ ë¹„ìœ : AIê°€ ë¬¸ì œë¥¼ ì½ê³ , ìŠ¤ìŠ¤ë¡œ íŒŒì´ì¬ ì½”ë“œë¥¼ ì†ìœ¼ë¡œ ì¨ë‚´ë ¤ ê°€ëŠ” ì…ˆì…ë‹ˆë‹¤.\n",
        "\n",
        "âš™ï¸ 3. ì½”ë“œ ì‹¤í–‰ (Python REPL)\n",
        "ë§Œë“¤ì–´ì§„ ì½”ë“œëŠ” ê³§ë°”ë¡œ íŒŒì´ì¬ ì‹¤í–‰ê¸°(Python REPL)ë¥¼ í†µí•´ ëŒë ¤ë´…ë‹ˆë‹¤.\n",
        "\n",
        "ê²°ê³¼ê°€ ë³€ìˆ˜ resultì— ë‹´ê¸°ê³  print(result)ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ‘‰ ë¹„ìœ : AIê°€ ì‘ì„±í•œ ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰í•´ë³´ë©°, \"ë‹µì´ ë§ëŠ”ì§€\" ì²´í¬í•˜ëŠ” ê²ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZcdLsf5lGBe"
      },
      "source": [
        "### Code Writing1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Z_rhroUqVw"
      },
      "source": [
        "# ğŸ“˜ LLMì„ í™œìš©í•œ íŒŒì´ì¬ ì½”ë“œ ìë™ ìƒì„± ë° ì‹¤í–‰ íë¦„ ì„¤ëª…\n",
        "\n",
        "ì´ ê°•ì˜ì—ì„œëŠ” ëŒ€í™”í˜• ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì¸ LLM(Language Model)ì„ í™œìš©í•´,  \n",
        "ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì…ë ¥í•œ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ íŒŒì´ì¬ ì½”ë“œë¡œ ë°”ê¾¸ê³ ,  \n",
        "ê·¸ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ê¹Œì§€ ì¶œë ¥í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.  \n",
        "ì²˜ìŒ ì ‘í•˜ëŠ” ë¶„ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° API í‚¤ ì„¤ì •\n",
        "\n",
        "ê°€ì¥ ë¨¼ì €, LangChainê³¼ OpenAI APIë¥¼ í™œìš©í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ë„êµ¬ë“¤ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.  \n",
        "ê·¸ë¦¬ê³  OpenAI ëª¨ë¸ì— ì ‘ì†í•˜ê¸° ìœ„í•œ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.  \n",
        "ì´ í‚¤ëŠ” \"ì´ ì‚¬ìš©ìì—ê²Œ ëª¨ë¸ ì‚¬ìš© ê¶Œí•œì´ ìˆë‹¤\"ëŠ” ì¼ì¢…ì˜ ì¸ì¦ ìˆ˜ë‹¨ì…ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. GPTì—ê²Œ ëª…í™•í•œ ì—­í•  ì§€ì‹œ: ì˜¤ì§ ì½”ë“œë§Œ ìƒì„±í•˜ë¼!\n",
        "\n",
        "GPTëŠ” ë§¤ìš° ìœ ì—°í•œ ì–¸ì–´ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´,  \n",
        "**ì •í™•í•œ ì§€ì‹œë¬¸(prompt)**ì´ í•„ìš”í•©ë‹ˆë‹¤.  \n",
        "ì—¬ê¸°ì„œëŠ” â€œë¬¸ì œ í•´ê²°ì„ ìœ„í•œ íŒŒì´ì¬ ì½”ë“œë§Œ ì‘ì„±í•˜ê³ , ê²°ê³¼ëŠ” print(result)ë¡œ ì¶œë ¥í•˜ë¼â€ëŠ” ëª…ë ¹ì„ ì¤ë‹ˆë‹¤.\n",
        "\n",
        "ì´ëŸ¬í•œ ì§€ì‹œë¬¸ì€ ëª¨ë¸ì—ê²Œ â€œë„ˆëŠ” ì§€ê¸ˆ ì½”ë“œë§Œ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•´â€ë¼ê³  ëª…í™•íˆ ì•Œë ¤ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ì„ ê²°í•©\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´ ì‚¬ìš©ìê°€ â€œxê°€ 10ì¼ ë•Œ, y = 5 + 3xëŠ” ì–¼ë§ˆì¸ê°€ìš”?â€ë¼ê³  ë¬»ëŠ”ë‹¤ë©´,  \n",
        "GPTëŠ” ìš°ë¦¬ê°€ ì„¤ì •í•œ ì§€ì‹œë¬¸ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì€ ì½”ë“œë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤:\n",
        "\n",
        "```python\n",
        "x = 10\n",
        "y = 5 + 3 * x\n",
        "result = y\n",
        "print(result)\n",
        " 4. ìƒì„±ëœ ì½”ë“œë¥¼ ì¦‰ì‹œ ì‹¤í–‰í•˜ê¸°\n",
        "ì´ì œ LangChainì˜ PythonREPL ê¸°ëŠ¥ì„ í™œìš©í•´ GPTê°€ ë§Œë“  ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "REPL(Read-Eval-Print-Loop)ì€ íŒŒì´ì¬ ì½”ë“œë¥¼ ì½ê³ , í‰ê°€í•˜ê³ , ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¦‰, ì‚¬ìš©ìëŠ” ì§ˆë¬¸ë§Œ í•˜ê³ ,\n",
        "GPTê°€ ì½”ë“œ ìƒì„± â†’ LangChainì´ ì‹¤í–‰ â†’ ê²°ê³¼ ì¶œë ¥\n",
        "ì´ ëª¨ë“  ê³¼ì •ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "5. ê³ ë„í™”ëœ ì²´ì¸ êµ¬ì„± (ì½”ë“œ ì¶”ì¶œ í¬í•¨)\n",
        "GPTëŠ” ë•Œë•Œë¡œ ì½”ë“œ ì™¸ì˜ ì„¤ëª…ì„ í•¨ê»˜ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ extract_code() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ë¸”ë¡ë§Œ ë¶„ë¦¬í•´ëƒ…ë‹ˆë‹¤.\n",
        "ì´í›„ ì´ ì½”ë“œë§Œì„ ì‹¤í–‰ê¸°ë¡œ ì „ë‹¬í•´ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë˜í•œ, ì´ ê³¼ì •ì—ì„œëŠ” ìµœì‹  ëª¨ë¸ì¸ GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê³  ì €ë ´í•œ ì²˜ë¦¬ë¥¼ ë„ì…í•©ë‹ˆë‹¤.\n",
        "\n",
        "6. ì˜ˆì‹œ: ì›ì£¼ìœ¨ì„ ì†Œìˆ˜ì  ì´í•˜ 30ìë¦¬ê¹Œì§€ êµ¬í•˜ê¸°\n",
        "ì‚¬ìš©ìê°€ \"ì›ì£¼ìœ¨ì„ ì†Œìˆ˜ì  ì´í•˜ 30ìë¦¬ê¹Œì§€ ì •í™•íˆ êµ¬í•´ ì£¼ì„¸ìš”\"ë¼ê³  ìš”ì²­í•˜ë©´,\n",
        "GPTëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³ ì • ì†Œìˆ˜ì  ê³„ì‚° ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n",
        "\n",
        "python\n",
        "ë³µì‚¬\n",
        "í¸ì§‘\n",
        "from decimal import Decimal, getcontext\n",
        "getcontext().prec = 35\n",
        "pi = Decimal(16)*Decimal('0.2').atan() - Decimal(4)*Decimal('0.5').atan()\n",
        "result = pi\n",
        "print(result)\n",
        "ì‹¤í–‰í•˜ë©´, ë§¤ìš° ì •í™•í•œ ì›ì£¼ìœ¨ ê°’ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "âœ… ìš”ì•½: ì™œ ì´ê²Œ ì¤‘ìš”í•œê°€ìš”?\n",
        "ì‚¬ìš©ì â†’ ìì—°ì–´ ì§ˆë¬¸\n",
        "\n",
        "GPT â†’ íŒŒì´ì¬ ì½”ë“œ ìë™ ìƒì„±\n",
        "\n",
        "LangChain â†’ ì½”ë“œ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "ì´ êµ¬ì¡° ë•ë¶„ì— í•˜ë“œì½”ë”© ì—†ì´ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„ì„ê³¼ ê³„ì‚°ì„ ìì—°ì–´ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì¦‰, ê°œë°œ ì§€ì‹ì´ ë¶€ì¡±í•´ë„ AIì˜ ë„ì›€ì„ ë°›ì•„ ììœ ë¡­ê²Œ í”„ë¡œê·¸ë˜ë° ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ ë§Œë“¤ì–´ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgBxBi0Cu2Nb",
        "outputId": "7f9e0611-4520-4f5d-e76d-60149e6bef32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m204.8/209.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/63.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ğŸ“Œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. LangChain ë° OpenAI ì—°ë™ì„ ìœ„í•œ í•µì‹¬ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n",
        "!pip install langchain langchain-experimental langchain-openai -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jBofuZ8gkRK5"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Œ os ëª¨ë“ˆì„ ì´ìš©í•´ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "# â–¶ï¸ í¬ì¸íŠ¸: OpenAI API í‚¤ëŠ” ì™¸ë¶€ì— ë…¸ì¶œë˜ë©´ ì•ˆ ë˜ë¯€ë¡œ ì½”ë“œì— ì§ì ‘ ì…ë ¥í•˜ê¸°ë³´ë‹¤ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9gOk5m7j4ae",
        "outputId": "90f8e589-6906-4c17-9125-3417ddd28c63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-851f7996425c>:21: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  model = ChatOpenAI(temperature=0, model_name=\"gpt-4\")  # temperature=0: í•­ìƒ ì¼ê´€ëœ ê²°ê³¼ ìƒì„±\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Œ í•„ìš”í•œ LangChain ì»´í¬ë„ŒíŠ¸ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
        "from langchain.chat_models import ChatOpenAI  # OpenAIì˜ ì±— ê¸°ë°˜ ëª¨ë¸ì„ ì‚¬ìš©\n",
        "from langchain.prompts import ChatPromptTemplate  # ì‚¬ìš©ì ì§ˆë¬¸ì„ GPTì— ë§ëŠ” í˜•íƒœë¡œ ë°”ê¿”ì£¼ëŠ” ì—­í• \n",
        "from langchain_core.output_parsers import StrOutputParser  # GPT ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±\n",
        "from langchain_experimental.utilities import PythonREPL  # ìƒì„±ëœ íŒŒì´ì¬ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ê¸°ëŠ¥ ì œê³µ\n",
        "\n",
        "# ğŸ“Œ GPT ëª¨ë¸ì—ê²Œ ì¤„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "# â–¶ï¸ í¬ì¸íŠ¸: ì•„ë˜ í…œí”Œë¦¿ì€ \"ì˜¤ì§ íŒŒì´ì¬ ì½”ë“œë§Œ ì¶œë ¥í•˜ê³ , ê²°ê³¼ëŠ” resultë¡œ ì¶œë ¥í•˜ë¼\"ê³  GPTì—ê²Œ ëª…ë ¹í•˜ëŠ” ì§€ì‹œë¬¸ì…ë‹ˆë‹¤.\n",
        "template = \"\"\"\n",
        "ì‚¬ìš©ìì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
        "ì‚¬ìš©ìê°€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì½”ë“œì˜ ëì— print(result)ë¥¼ í¬í•¨í•˜ì„¸ìš”.\n",
        "ì˜¤ì§ íŒŒì´ì¬ ì½”ë“œë§Œ ë°˜í™˜í•˜ì„¸ìš”. ê·¸ ì™¸ì˜ ê²ƒì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "# ğŸ“Œ ì‹¤ì œë¡œ ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ì •ì˜: ì‹œìŠ¤í…œ í…œí”Œë¦¿ + ì‚¬ìš©ì ì§ˆë¬¸\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", template), (\"human\", \"{question}\")]\n",
        ")\n",
        "\n",
        "# ğŸ“Œ GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•´ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "model = ChatOpenAI(temperature=0, model_name=\"gpt-4\")  # temperature=0: í•­ìƒ ì¼ê´€ëœ ê²°ê³¼ ìƒì„±\n",
        "\n",
        "# ğŸ“Œ ì²´ì¸1: ì§ˆë¬¸ â†’ í”„ë¡¬í”„íŠ¸ â†’ GPT â†’ ê²°ê³¼ íŒŒì‹±ê¹Œì§€\n",
        "PythonCode_chain = prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-XTnHUDAkU2T",
        "outputId": "565fc7af-ceec-4b3e-af8c-d7fae23a8f29"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x = 10\\ny = 5 + 3 * x\\nresult = y\\nprint(result)'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# â–¶ï¸ í¬ì¸íŠ¸: ì•„ë˜ëŠ” ì‹¤ì œë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ GPTê°€ ì½”ë“œë¥¼ ìƒì„±í•˜ê³ , ê²°ê³¼ë¥¼ ì‹¤í–‰í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
        "# ì‚¬ìš©ìê°€ ì§ˆë¬¸í•©ë‹ˆë‹¤: \"xê°€ 10ì¼ ë•Œ y = 5 + 3 * x ì´ë©´ yëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"\n",
        "PythonCode_chain.invoke({\"question\": \"y= 5 + 3 * x. If x is 10, what is y?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm8-2ZrYkvwt",
        "outputId": "e48e5eb4-63e0-497e-b70c-a4279b03aa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n"
          ]
        }
      ],
      "source": [
        "# âœ… GPTê°€ ìƒì„±í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì½”ë“œ ì˜ˆì‹œ:\n",
        "x = 10\n",
        "y = 5 + 3 * x\n",
        "result = y\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PwnWLcKckcqG",
        "outputId": "641525ce-580c-4cff-b57f-ed232eb58d3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'35\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# â–¶ï¸ GPTê°€ ìœ„ì™€ ë¹„ìŠ·í•œ ì½”ë“œë¥¼ ìë™ ìƒì„±í•˜ê³ , Python REPLì„ í†µí•´ ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "PythonCodeRun_chain.invoke({\"question\": \"y= 5 + 3 * x. If x is 10, what is y?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYakIDyElJqO"
      },
      "source": [
        "# 2.CodeWriting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHVEUcFOmhQa"
      },
      "source": [
        "CodeWriting2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u-jX0LpXo2D0"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Œ ìµœì‹  ë²„ì „ìœ¼ë¡œ langchain íŒ¨í‚¤ì§€ ì—…ê·¸ë ˆì´ë“œ\n",
        "!pip install --upgrade --quiet  langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Alvf1JvzutN4"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Œ í•„ìš”í•œ ëª¨ë“ˆ ì¬í˜¸ì¶œ\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI  # âœ… langchain-openaiì™€ langchain.chat_modelsëŠ” ë™ì¼ ëª©ì ì´ì§€ë§Œ ë¶„ë¦¬ëœ íŒ¨í‚¤ì§€\n",
        "\n",
        "# ğŸ“Œ ë‹¤ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í•„ìš” ì‹œ ì¬ì‹¤í–‰)\n",
        "\n",
        "# ğŸ“Œ ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ í…œí”Œë¦¿ì„ êµ¬ì„±í•©ë‹ˆë‹¤. ì½”ë“œ ë¸”ë¡ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "template = \"\"\"ì‚¬ìš©ìì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ Python ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
        "\n",
        "ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ Python ì½”ë“œë§Œ ë°˜í™˜í•˜ì„¸ìš”:\n",
        "\n",
        "```python\n",
        "....\n",
        "```\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q47Gx06albu-"
      },
      "outputs": [],
      "source": [
        "# ğŸ“Œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ êµ¬ì„±\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", template),\n",
        "     (\"human\", \"{input}\")])\n",
        "\n",
        "# ğŸ“Œ ë” ë¹ ë¥´ê³  ì €ë ´í•œ GPT-4o ëª¨ë¸ì„ ì‚¬ìš©\n",
        "llm = ChatOpenAI(model='gpt-4o', temperature=0, max_tokens=1024)\n",
        "\n",
        "# ğŸ“Œ GPT ì‘ë‹µì—ì„œ ì½”ë“œë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ ì •ì˜\n",
        "# â–¶ï¸ ì˜ˆ: GPTê°€ ì½”ë“œ ì™¸ì—ë„ ë¶€ê°€ ì„¤ëª…ì„ ë„£ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ```python ~ ``` ë¸”ë¡ ì•ˆì˜ ì½”ë“œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "def extract_code(text):\n",
        "    return text.split('```python')[1].split(\"```\")[0]  # ì½”ë“œë§Œ ê¹”ë”í•˜ê²Œ ë¶„ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CADRkuuFlc8j",
        "outputId": "755af081-40f4-4e55-c58c-b5da05cf4826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Œ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ë‹´ë‹¹í•˜ëŠ” íŒŒì„œ ëª¨ë“ˆ\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# ğŸ“Œ ì „ì²´ ì²´ì¸ êµ¬ì„±:\n",
        "# ì§ˆë¬¸ â†’ í”„ë¡¬í”„íŠ¸ â†’ GPT ì‘ë‹µ â†’ ì½”ë“œë§Œ ì¶”ì¶œ â†’ ì½”ë“œ ì‹¤í–‰(Python REPL)\n",
        "chain = prompt | llm | StrOutputParser() | extract_code | PythonREPL().run\n",
        "\n",
        "# âœ… ì‹¤ìŠµ ì˜ˆì‹œ: ì›ì£¼ìœ¨ì„ ì†Œìˆ˜ì  ì´í•˜ 30ìë¦¬ê¹Œì§€ êµ¬í•˜ëŠ” ì½”ë“œë¥¼ GPTê°€ ìƒì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "print(chain.invoke({'input': \"4 ê³±í•˜ê¸° 3ì„ êµ¬í•´ì£¼ì„¸ìš”\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypOZ21GUlqa2",
        "outputId": "dd250fc6-76b4-4af1-d834-13c8adab328b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "result = 4 * 3\n",
            "print(result)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“Œ ìœ„ì™€ ë™ì¼í•˜ì§€ë§Œ, 'ì½”ë“œ ìƒì„±'ê¹Œì§€ë§Œ ìˆ˜í–‰í•˜ëŠ” ë³„ë„ ì²´ì¸\n",
        "code_gen = prompt | llm | StrOutputParser() | extract_code\n",
        "\n",
        "# âœ… ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•´, ìƒì„±ëœ ì½”ë“œë§Œ ë³´ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œ\n",
        "print(code_gen.invoke({'input': \"4ê³±í•˜ê¸° 3ì„ êµ¬í•´ì£¼ì„¸ìš”\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCL4UKafutN5"
      },
      "source": [
        "# 2. Moderation ê¸°ëŠ¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3efEmdfmLJB"
      },
      "source": [
        "(ê³µì‹ë¬¸ì„œ)\n",
        "https://platform.openai.com/docs/guides/moderation/overview?lang=python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59Qo-SBhp7_E"
      },
      "source": [
        "# Moderation1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r41dm02Tp-7-"
      },
      "source": [
        "í˜ì˜¤ (hate): ì¸ì¢…, ì„±ë³„, ë¯¼ì¡±, ì¢…êµ, êµ­ì , ì„±ì  ì§€í–¥, ì¥ì•  ìƒíƒœ ë˜ëŠ” ì¹´ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ í˜ì˜¤ë¥¼ í‘œí˜„í•˜ê±°ë‚˜ ì„ ë™í•˜ê±°ë‚˜ ì¡°ì¥í•˜ëŠ” ì½˜í…ì¸ . ë³´í˜¸ë˜ì§€ ì•ŠëŠ” ê·¸ë£¹(ì˜ˆ: ì²´ìŠ¤ ì„ ìˆ˜)ì— ëŒ€í•œ í˜ì˜¤ ì½˜í…ì¸ ëŠ” ê´´ë¡­í˜ìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.\n",
        "\n",
        "í˜ì˜¤/ìœ„í˜‘ (hate/threatening): ì¸ì¢…, ì„±ë³„, ë¯¼ì¡±, ì¢…êµ, êµ­ì , ì„±ì  ì§€í–¥, ì¥ì•  ìƒíƒœ ë˜ëŠ” ì¹´ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ í•´ë‹¹ ê·¸ë£¹ì— ëŒ€í•œ í­ë ¥ ë˜ëŠ” ì‹¬ê°í•œ í”¼í•´ë¥¼ í¬í•¨í•˜ëŠ” í˜ì˜¤ ì½˜í…ì¸ .\n",
        "\n",
        "ê´´ë¡­í˜ (harassment): íŠ¹ì • ëŒ€ìƒì— ëŒ€í•œ ê´´ë¡­í˜ ì–¸ì–´ë¥¼ í‘œí˜„í•˜ê±°ë‚˜ ì„ ë™í•˜ê±°ë‚˜ ì¡°ì¥í•˜ëŠ” ì½˜í…ì¸ .\n",
        "\n",
        "ê´´ë¡­í˜/ìœ„í˜‘ (harassment/threatening): íŠ¹ì • ëŒ€ìƒì— ëŒ€í•œ í­ë ¥ ë˜ëŠ” ì‹¬ê°í•œ í”¼í•´ë¥¼ í¬í•¨í•˜ëŠ” ê´´ë¡­í˜ ì½˜í…ì¸ .\n",
        "\n",
        "ìí•´ (self-harm): ìì‚´, ìí•´(ë² ê¸°), ì„­ì‹ ì¥ì• ì™€ ê°™ì€ ìí•´ í–‰ìœ„ë¥¼ ì¡°ì¥í•˜ê±°ë‚˜ ê¶Œì¥í•˜ê±°ë‚˜ ë¬˜ì‚¬í•˜ëŠ” ì½˜í…ì¸ .\n",
        "\n",
        "ìí•´/ì˜ë„ (self-harm/intent): í™”ìê°€ ìì‚´, ìí•´(ë² ê¸°), ì„­ì‹ ì¥ì• ì™€ ê°™ì€ ìí•´ í–‰ìœ„ë¥¼ í•˜ê³  ìˆê±°ë‚˜ í•˜ë ¤ê³  í•œë‹¤ê³  í‘œí˜„í•˜ëŠ” ì½˜í…ì¸ .\n",
        "\n",
        "ìí•´/ë°©ë²• (self-harm/instructions): ìì‚´, ìí•´(ë² ê¸°), ì„­ì‹ ì¥ì• ì™€ ê°™ì€ ìí•´ í–‰ìœ„ë¥¼ í•˜ë„ë¡ ê¶Œì¥í•˜ê±°ë‚˜ ì´ëŸ¬í•œ í–‰ìœ„ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²• ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ì½˜í…ì¸ .\n",
        "\n",
        "ì„±ì ì¸ (sexual): ì„±ì  í¥ë¶„ì„ ìœ ë°œí•˜ë ¤ëŠ” ëª©ì ì„ ê°€ì§„ ì½˜í…ì¸ , ì„±ì  í™œë™ì„ ë¬˜ì‚¬í•˜ê±°ë‚˜ ì„±ì  ì„œë¹„ìŠ¤ë¥¼ í™ë³´í•˜ëŠ” ì½˜í…ì¸ (ì„± êµìœ¡ ë° ì›°ë‹ˆìŠ¤ ì œì™¸).\n",
        "\n",
        "ì„±ì ì¸/ë¯¸ì„±ë…„ì (sexual/minors): 18ì„¸ ë¯¸ë§Œì˜ ê°œì¸ì´ í¬í•¨ëœ ì„±ì  ì½˜í…ì¸ .\n",
        "\n",
        "í­ë ¥ (violence): ì£½ìŒ, í­ë ¥ ë˜ëŠ” ì‹ ì²´ì  ìƒí•´ë¥¼ ë¬˜ì‚¬í•˜ëŠ” ì½˜í…ì¸ .\n",
        "\n",
        "í­ë ¥/ìƒì„¸ (violence/graphic): ì£½ìŒ, í­ë ¥ ë˜ëŠ” ì‹ ì²´ì  ìƒí•´ë¥¼ ìƒì„¸íˆ ë¬˜ì‚¬í•˜ëŠ” ì½˜í…ì¸ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdyn6fP_q0A7"
      },
      "source": [
        " ê°’ì€ 0ê³¼ 1 ì‚¬ì´ì´ë©°, ê°’ì´ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì˜ í™•ì‹ ë„ê°€ ë†’ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-x-BoKeqE3k",
        "outputId": "6781ef64-b428-4d5a-d71e-785c0aa388e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'harassment': 0.00025651900796219707, 'harassment_threatening': 0.0017967631574720144, 'hate': 0.000131044042063877, 'hate_threatening': 3.330395702505484e-05, 'illicit': None, 'illicit_violent': None, 'self_harm': 0.10243354737758636, 'self_harm_instructions': 0.012842289172112942, 'self_harm_intent': 0.06416939944028854, 'sexual': 5.647746365866624e-05, 'sexual_minors': 8.965668712335173e-06, 'violence': 0.01611601747572422, 'violence_graphic': 0.00012667976261582226, 'self-harm': 0.10243354737758636, 'sexual/minors': 8.965668712335173e-06, 'hate/threatening': 3.330395702505484e-05, 'violence/graphic': 0.00012667976261582226, 'self-harm/intent': 0.06416939944028854, 'self-harm/instructions': 0.012842289172112942, 'harassment/threatening': 0.0017967631574720144}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-4e7e1e4456ca>:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  scores = response.category_scores.dict()\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "client = openai.OpenAI()\n",
        "\n",
        "# ë¶„ì„í•  í…ìŠ¤íŠ¸ ì •ì˜\n",
        "text = 'ìì‚´'\n",
        "\n",
        "# í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì½˜í…ì¸  ê²€í†  ìš”ì²­ì„ ìƒì„±í•˜ê³ , ì²« ë²ˆì§¸ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´\n",
        "response = client.moderations.create(input=text).results[0]\n",
        "\n",
        "# í…ìŠ¤íŠ¸ê°€ ë¶€ì ì ˆí•˜ê±°ë‚˜ ìœ í•´í•œ ë‚´ìš©ìœ¼ë¡œ í”Œë˜ê·¸ëœ ì—¬ë¶€ë¥¼ í™•ì¸\n",
        "flagged = response.flagged\n",
        "\n",
        "# í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
        "scores = response.category_scores.dict()\n",
        "\n",
        "# ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ë¥¼ ì¶œë ¥\n",
        "print(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Kojp4Zp8utN5"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "client = openai.OpenAI()\n",
        "\n",
        "# **Moderation í•¨ìˆ˜**\n",
        "# ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ê°€ ì»¤ë®¤ë‹ˆí‹° ê·œì•½ì„ ìœ„ë°˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ ì‘ë‹µì„ ê±°ë¶€í•©ë‹ˆë‹¤.\n",
        "def moderate(text):\n",
        "    # ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ëª¨ë”ë ˆì´ì…˜(ì½˜í…ì¸  ê²€í† ) ìš”ì²­ì„ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´\n",
        "    response = client.moderations.create(input=text).results[0]\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ê°€ í”Œë˜ê·¸ë˜ì—ˆëŠ”ì§€(ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œì§€) í™•ì¸\n",
        "    flagged = response.flagged\n",
        "\n",
        "    # ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
        "    scores = response.category_scores.dict()\n",
        "\n",
        "    # ìœ„ë°˜ ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ í•­ëª© ì°¾ê¸°\n",
        "    max_category = max(scores, key=scores.get)  # ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ ì´ë¦„\n",
        "    max_score = scores[max_category]  # ê·¸ ì¹´í…Œê³ ë¦¬ì˜ ì ìˆ˜\n",
        "\n",
        "    # ëª¨ë”ë ˆì´ì…˜ ê²°ê³¼ì— ë”°ë¼ ì‘ë‹µì„ ìƒì„±\n",
        "    if flagged or max_score > 0.000000001:\n",
        "        # í”Œë˜ê·¸ë˜ì—ˆê±°ë‚˜ íŠ¹ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì•˜ë‹¤ë©´ ì‘ë‹µì„ ì°¨ë‹¨\n",
        "        return {'blocked': True, 'reason': max_category, 'score': max_score}\n",
        "\n",
        "    # ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
        "    return {'blocked': False, 'text': text}\n",
        "\n",
        "# **LLM ì‘ë‹µ ì²˜ë¦¬ ì²´ì¸**\n",
        "# ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "def generate_response(prompt):\n",
        "    # ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë”ë ˆì´ì…˜ í•¨ìˆ˜ì— ì „ë‹¬í•˜ì—¬ ê²€í† \n",
        "    moderation_result = moderate(prompt)\n",
        "\n",
        "    # ëª¨ë”ë ˆì´ì…˜ ê²°ê³¼ì— ë”°ë¼ ì‘ë‹µì„ ê²°ì •\n",
        "    if moderation_result['blocked']:\n",
        "        print(\"ëª¨ë”ë ˆì´ì…˜ ì‹¤íŒ¨!\")  # ëª¨ë”ë ˆì´ì…˜ì—ì„œ ì°¨ë‹¨ëœ ê²½ìš°\n",
        "        return f\"ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ìœ í•´í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ì‚¬ìœ : {moderation_result['reason']}\"\n",
        "    else:\n",
        "        print(\"ëª¨ë”ë ˆì´ì…˜ í†µê³¼.\")  # ëª¨ë”ë ˆì´ì…˜ì„ í†µê³¼í•œ ê²½ìš°\n",
        "        # LLM ì‘ë‹µ ìƒì„± ë¡œì§ (ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ì¶œë ¥)\n",
        "        return f\"ì‚¬ìš©ì ì…ë ¥: {moderation_result['text']}\"\n",
        "\n",
        "# **Fallback ì²˜ë¦¬**\n",
        "# ê¸°ë³¸ ì‘ë‹µ ì²´ì¸ì´ ì‹¤íŒ¨í•  ê²½ìš° ì‹¤í–‰ë˜ëŠ” ëŒ€ì²´ ì‘ë‹µ ë¡œì§ì…ë‹ˆë‹¤.\n",
        "def fallback_response(fallback_msg):\n",
        "    print(\"Fallback ì‹¤í–‰ ì¤‘...\")\n",
        "    return \"ê·¸ëŸ° ëŒ€í™”ì—ëŠ” ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´ìš”.\"\n",
        "\n",
        "# **ìµœì¢… ì‘ë‹µ ì²´ì¸**\n",
        "# ê¸°ë³¸ ì‘ë‹µ ì²´ì¸ê³¼ Fallback ì²´ì¸ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
        "def respond(text):\n",
        "    try:\n",
        "        # ê¸°ë³¸ ì‘ë‹µ ìƒì„± ë¡œì§ ì‹¤í–‰\n",
        "        response = generate_response(text)\n",
        "    except Exception as e:\n",
        "        # ì˜¤ë¥˜ ë°œìƒ ì‹œ Fallback ì‘ë‹µ ìƒì„± ë¡œì§ ì‹¤í–‰\n",
        "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        response = fallback_response(text)\n",
        "\n",
        "    # ìµœì¢… ì‘ë‹µ ë°˜í™˜\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6VtaCS8wE8W",
        "outputId": "36b1f2d4-478c-4f82-eb38-8c966794b2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì˜¤ë¥˜ ë°œìƒ: '>' not supported between instances of 'NoneType' and 'float'\n",
            "Fallback ì‹¤í–‰ ì¤‘...\n",
            "ê·¸ëŸ° ëŒ€í™”ì—ëŠ” ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´ìš”.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-20f629999668>:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  scores = response.category_scores.dict()\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸: ì •ìƒì ì¸ ì…ë ¥ê³¼ ìœ„ë°˜ëœ ì…ë ¥ ì²˜ë¦¬\n",
        "print(respond(\"ì‹¤íŒ¨\"))           # ëª¨ë”ë ˆì´ì…˜ ì‹¤íŒ¨ ì˜ˆì‹œ\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
